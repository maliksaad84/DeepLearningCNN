{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "root_dir = 'D:/Confidential Reports/Deep learning class/assignment'\n",
    "default_directory = 'D:/Confidential Reports/Deep learning class/assignment/save_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
    "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to D:/Confidential Reports/Deep learning class/assignment\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66290958030741b086e2d27788ca8fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting D:/Confidential Reports/Deep learning class/assignment\\cifar-10-python.tar.gz to D:/Confidential Reports/Deep learning class/assignment\n"
     ]
    }
   ],
   "source": [
    "# automatically download\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
    "                                           num_workers=4)           # CPU loader number\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
    "                                          num_workers=4)            # CPU loader number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE ONLY CPU!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch\\cuda\\__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4,\n",
    "                                nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch_idx: 0 |  Loss: (2.6346) | Acc: (9.38%) (12/128)\n",
      "Epoch: 0 | Batch_idx: 10 |  Loss: (2.3526) | Acc: (14.77%) (208/1408)\n",
      "Epoch: 0 | Batch_idx: 20 |  Loss: (2.2697) | Acc: (17.15%) (461/2688)\n",
      "Epoch: 0 | Batch_idx: 30 |  Loss: (2.2028) | Acc: (19.08%) (757/3968)\n",
      "Epoch: 0 | Batch_idx: 40 |  Loss: (2.1595) | Acc: (20.18%) (1059/5248)\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (2.1190) | Acc: (22.32%) (1457/6528)\n",
      "Epoch: 0 | Batch_idx: 60 |  Loss: (2.0816) | Acc: (23.98%) (1872/7808)\n",
      "Epoch: 0 | Batch_idx: 70 |  Loss: (2.0565) | Acc: (24.78%) (2252/9088)\n",
      "Epoch: 0 | Batch_idx: 80 |  Loss: (2.0338) | Acc: (25.57%) (2651/10368)\n",
      "Epoch: 0 | Batch_idx: 90 |  Loss: (2.0127) | Acc: (26.30%) (3063/11648)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (1.9948) | Acc: (27.04%) (3496/12928)\n",
      "Epoch: 0 | Batch_idx: 110 |  Loss: (1.9780) | Acc: (27.69%) (3934/14208)\n",
      "Epoch: 0 | Batch_idx: 120 |  Loss: (1.9638) | Acc: (28.21%) (4369/15488)\n",
      "Epoch: 0 | Batch_idx: 130 |  Loss: (1.9460) | Acc: (28.88%) (4842/16768)\n",
      "Epoch: 0 | Batch_idx: 140 |  Loss: (1.9340) | Acc: (29.32%) (5292/18048)\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (1.9191) | Acc: (29.92%) (5783/19328)\n",
      "Epoch: 0 | Batch_idx: 160 |  Loss: (1.9069) | Acc: (30.38%) (6260/20608)\n",
      "Epoch: 0 | Batch_idx: 170 |  Loss: (1.8937) | Acc: (30.80%) (6742/21888)\n",
      "Epoch: 0 | Batch_idx: 180 |  Loss: (1.8823) | Acc: (31.33%) (7259/23168)\n",
      "Epoch: 0 | Batch_idx: 190 |  Loss: (1.8698) | Acc: (31.70%) (7751/24448)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (1.8598) | Acc: (31.98%) (8227/25728)\n",
      "Epoch: 0 | Batch_idx: 210 |  Loss: (1.8483) | Acc: (32.42%) (8755/27008)\n",
      "Epoch: 0 | Batch_idx: 220 |  Loss: (1.8364) | Acc: (32.91%) (9309/28288)\n",
      "Epoch: 0 | Batch_idx: 230 |  Loss: (1.8275) | Acc: (33.24%) (9827/29568)\n",
      "Epoch: 0 | Batch_idx: 240 |  Loss: (1.8177) | Acc: (33.55%) (10349/30848)\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (1.8086) | Acc: (33.87%) (10882/32128)\n",
      "Epoch: 0 | Batch_idx: 260 |  Loss: (1.7994) | Acc: (34.17%) (11416/33408)\n",
      "Epoch: 0 | Batch_idx: 270 |  Loss: (1.7910) | Acc: (34.47%) (11958/34688)\n",
      "Epoch: 0 | Batch_idx: 280 |  Loss: (1.7835) | Acc: (34.72%) (12489/35968)\n",
      "Epoch: 0 | Batch_idx: 290 |  Loss: (1.7754) | Acc: (35.01%) (13039/37248)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (1.7691) | Acc: (35.19%) (13557/38528)\n",
      "Epoch: 0 | Batch_idx: 310 |  Loss: (1.7612) | Acc: (35.51%) (14135/39808)\n",
      "Epoch: 0 | Batch_idx: 320 |  Loss: (1.7538) | Acc: (35.76%) (14695/41088)\n",
      "Epoch: 0 | Batch_idx: 330 |  Loss: (1.7469) | Acc: (36.01%) (15256/42368)\n",
      "Epoch: 0 | Batch_idx: 340 |  Loss: (1.7407) | Acc: (36.24%) (15819/43648)\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (1.7343) | Acc: (36.51%) (16404/44928)\n",
      "Epoch: 0 | Batch_idx: 360 |  Loss: (1.7273) | Acc: (36.77%) (16992/46208)\n",
      "Epoch: 0 | Batch_idx: 370 |  Loss: (1.7206) | Acc: (36.99%) (17564/47488)\n",
      "Epoch: 0 | Batch_idx: 380 |  Loss: (1.7149) | Acc: (37.20%) (18142/48768)\n",
      "Epoch: 0 | Batch_idx: 390 |  Loss: (1.7082) | Acc: (37.45%) (18724/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.4621) | Acc: (46.23%) (4623/10000)\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (1.4711) | Acc: (39.06%) (50/128)\n",
      "Epoch: 1 | Batch_idx: 10 |  Loss: (1.4856) | Acc: (46.02%) (648/1408)\n",
      "Epoch: 1 | Batch_idx: 20 |  Loss: (1.4656) | Acc: (45.68%) (1228/2688)\n",
      "Epoch: 1 | Batch_idx: 30 |  Loss: (1.4510) | Acc: (46.72%) (1854/3968)\n",
      "Epoch: 1 | Batch_idx: 40 |  Loss: (1.4503) | Acc: (46.93%) (2463/5248)\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (1.4491) | Acc: (47.00%) (3068/6528)\n",
      "Epoch: 1 | Batch_idx: 60 |  Loss: (1.4437) | Acc: (46.90%) (3662/7808)\n",
      "Epoch: 1 | Batch_idx: 70 |  Loss: (1.4454) | Acc: (46.76%) (4250/9088)\n",
      "Epoch: 1 | Batch_idx: 80 |  Loss: (1.4405) | Acc: (47.13%) (4886/10368)\n",
      "Epoch: 1 | Batch_idx: 90 |  Loss: (1.4388) | Acc: (47.23%) (5501/11648)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (1.4351) | Acc: (47.46%) (6136/12928)\n",
      "Epoch: 1 | Batch_idx: 110 |  Loss: (1.4317) | Acc: (47.70%) (6777/14208)\n",
      "Epoch: 1 | Batch_idx: 120 |  Loss: (1.4291) | Acc: (47.71%) (7389/15488)\n",
      "Epoch: 1 | Batch_idx: 130 |  Loss: (1.4250) | Acc: (47.73%) (8003/16768)\n",
      "Epoch: 1 | Batch_idx: 140 |  Loss: (1.4235) | Acc: (47.76%) (8620/18048)\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (1.4237) | Acc: (47.89%) (9256/19328)\n",
      "Epoch: 1 | Batch_idx: 160 |  Loss: (1.4243) | Acc: (47.84%) (9858/20608)\n",
      "Epoch: 1 | Batch_idx: 170 |  Loss: (1.4233) | Acc: (47.90%) (10485/21888)\n",
      "Epoch: 1 | Batch_idx: 180 |  Loss: (1.4211) | Acc: (47.96%) (11111/23168)\n",
      "Epoch: 1 | Batch_idx: 190 |  Loss: (1.4202) | Acc: (47.99%) (11732/24448)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (1.4193) | Acc: (48.09%) (12373/25728)\n",
      "Epoch: 1 | Batch_idx: 210 |  Loss: (1.4168) | Acc: (48.19%) (13015/27008)\n",
      "Epoch: 1 | Batch_idx: 220 |  Loss: (1.4139) | Acc: (48.31%) (13665/28288)\n",
      "Epoch: 1 | Batch_idx: 230 |  Loss: (1.4098) | Acc: (48.51%) (14344/29568)\n",
      "Epoch: 1 | Batch_idx: 240 |  Loss: (1.4084) | Acc: (48.56%) (14981/30848)\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (1.4070) | Acc: (48.72%) (15652/32128)\n",
      "Epoch: 1 | Batch_idx: 260 |  Loss: (1.4044) | Acc: (48.82%) (16309/33408)\n",
      "Epoch: 1 | Batch_idx: 270 |  Loss: (1.4024) | Acc: (48.86%) (16948/34688)\n",
      "Epoch: 1 | Batch_idx: 280 |  Loss: (1.3999) | Acc: (48.90%) (17588/35968)\n",
      "Epoch: 1 | Batch_idx: 290 |  Loss: (1.3983) | Acc: (48.96%) (18235/37248)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (1.3947) | Acc: (49.09%) (18915/38528)\n",
      "Epoch: 1 | Batch_idx: 310 |  Loss: (1.3927) | Acc: (49.11%) (19549/39808)\n",
      "Epoch: 1 | Batch_idx: 320 |  Loss: (1.3912) | Acc: (49.11%) (20180/41088)\n",
      "Epoch: 1 | Batch_idx: 330 |  Loss: (1.3877) | Acc: (49.25%) (20865/42368)\n",
      "Epoch: 1 | Batch_idx: 340 |  Loss: (1.3854) | Acc: (49.34%) (21534/43648)\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (1.3831) | Acc: (49.46%) (22221/44928)\n",
      "Epoch: 1 | Batch_idx: 360 |  Loss: (1.3804) | Acc: (49.57%) (22905/46208)\n",
      "Epoch: 1 | Batch_idx: 370 |  Loss: (1.3780) | Acc: (49.68%) (23591/47488)\n",
      "Epoch: 1 | Batch_idx: 380 |  Loss: (1.3754) | Acc: (49.78%) (24276/48768)\n",
      "Epoch: 1 | Batch_idx: 390 |  Loss: (1.3725) | Acc: (49.90%) (24948/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.3633) | Acc: (51.87%) (5187/10000)\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (1.2806) | Acc: (52.34%) (67/128)\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (1.2403) | Acc: (56.18%) (791/1408)\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (1.2433) | Acc: (55.13%) (1482/2688)\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (1.2467) | Acc: (54.76%) (2173/3968)\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (1.2422) | Acc: (54.88%) (2880/5248)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (1.2400) | Acc: (55.02%) (3592/6528)\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (1.2400) | Acc: (55.01%) (4295/7808)\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (1.2472) | Acc: (54.73%) (4974/9088)\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (1.2468) | Acc: (54.69%) (5670/10368)\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (1.2446) | Acc: (54.76%) (6378/11648)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (1.2440) | Acc: (54.86%) (7092/12928)\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (1.2465) | Acc: (54.89%) (7799/14208)\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (1.2450) | Acc: (54.88%) (8500/15488)\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (1.2493) | Acc: (54.69%) (9171/16768)\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (1.2488) | Acc: (54.71%) (9874/18048)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (1.2493) | Acc: (54.65%) (10563/19328)\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (1.2444) | Acc: (54.89%) (11312/20608)\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (1.2463) | Acc: (54.82%) (11999/21888)\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (1.2444) | Acc: (54.89%) (12716/23168)\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (1.2421) | Acc: (54.99%) (13443/24448)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (1.2435) | Acc: (54.92%) (14131/25728)\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (1.2427) | Acc: (55.01%) (14857/27008)\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (1.2433) | Acc: (54.92%) (15536/28288)\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (1.2420) | Acc: (55.03%) (16272/29568)\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (1.2414) | Acc: (55.09%) (16995/30848)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (1.2389) | Acc: (55.21%) (17739/32128)\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (1.2394) | Acc: (55.17%) (18432/33408)\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (1.2383) | Acc: (55.26%) (19168/34688)\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (1.2362) | Acc: (55.32%) (19898/35968)\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (1.2350) | Acc: (55.35%) (20616/37248)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (1.2331) | Acc: (55.44%) (21359/38528)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Batch_idx: 310 |  Loss: (1.2285) | Acc: (55.59%) (22129/39808)\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (1.2269) | Acc: (55.64%) (22861/41088)\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (1.2258) | Acc: (55.73%) (23613/42368)\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (1.2247) | Acc: (55.76%) (24339/43648)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (1.2225) | Acc: (55.85%) (25093/44928)\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (1.2218) | Acc: (55.90%) (25832/46208)\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (1.2198) | Acc: (55.98%) (26584/47488)\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (1.2177) | Acc: (56.08%) (27350/48768)\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (1.2159) | Acc: (56.13%) (28066/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1989) | Acc: (56.56%) (5656/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (1.1087) | Acc: (62.50%) (80/128)\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (1.0944) | Acc: (61.72%) (869/1408)\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (1.1246) | Acc: (60.19%) (1618/2688)\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (1.1383) | Acc: (59.90%) (2377/3968)\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (1.1408) | Acc: (59.36%) (3115/5248)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (1.1347) | Acc: (59.22%) (3866/6528)\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (1.1298) | Acc: (59.38%) (4636/7808)\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (1.1352) | Acc: (59.21%) (5381/9088)\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (1.1344) | Acc: (59.09%) (6126/10368)\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (1.1334) | Acc: (59.21%) (6897/11648)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (1.1296) | Acc: (59.51%) (7694/12928)\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (1.1317) | Acc: (59.47%) (8450/14208)\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (1.1279) | Acc: (59.58%) (9227/15488)\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (1.1268) | Acc: (59.61%) (9996/16768)\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (1.1258) | Acc: (59.71%) (10776/18048)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (1.1239) | Acc: (59.81%) (11561/19328)\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (1.1237) | Acc: (59.77%) (12317/20608)\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (1.1219) | Acc: (59.86%) (13102/21888)\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (1.1221) | Acc: (59.85%) (13866/23168)\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (1.1203) | Acc: (59.96%) (14660/24448)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (1.1197) | Acc: (59.99%) (15435/25728)\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (1.1195) | Acc: (59.94%) (16189/27008)\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (1.1182) | Acc: (59.98%) (16966/28288)\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (1.1150) | Acc: (60.09%) (17767/29568)\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (1.1124) | Acc: (60.20%) (18569/30848)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (1.1110) | Acc: (60.22%) (19348/32128)\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (1.1104) | Acc: (60.27%) (20135/33408)\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (1.1105) | Acc: (60.27%) (20908/34688)\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (1.1113) | Acc: (60.25%) (21670/35968)\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (1.1087) | Acc: (60.36%) (22482/37248)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (1.1079) | Acc: (60.36%) (23256/38528)\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (1.1064) | Acc: (60.40%) (24044/39808)\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (1.1042) | Acc: (60.48%) (24848/41088)\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (1.1030) | Acc: (60.51%) (25635/42368)\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (1.1022) | Acc: (60.57%) (26438/43648)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (1.1004) | Acc: (60.67%) (27256/44928)\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (1.0996) | Acc: (60.71%) (28053/46208)\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (1.0971) | Acc: (60.81%) (28876/47488)\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (1.0966) | Acc: (60.80%) (29653/48768)\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (1.0962) | Acc: (60.80%) (30402/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1349) | Acc: (59.57%) (5957/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (1.2249) | Acc: (53.12%) (68/128)\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (1.0526) | Acc: (62.36%) (878/1408)\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (1.0515) | Acc: (62.69%) (1685/2688)\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (1.0445) | Acc: (63.00%) (2500/3968)\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (1.0451) | Acc: (62.79%) (3295/5248)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (1.0466) | Acc: (62.65%) (4090/6528)\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (1.0444) | Acc: (62.65%) (4892/7808)\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (1.0396) | Acc: (62.94%) (5720/9088)\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (1.0366) | Acc: (63.08%) (6540/10368)\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (1.0335) | Acc: (63.17%) (7358/11648)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (1.0342) | Acc: (63.17%) (8166/12928)\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (1.0296) | Acc: (63.37%) (9004/14208)\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (1.0330) | Acc: (63.29%) (9802/15488)\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (1.0280) | Acc: (63.43%) (10636/16768)\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (1.0288) | Acc: (63.28%) (11421/18048)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (1.0293) | Acc: (63.22%) (12220/19328)\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (1.0271) | Acc: (63.27%) (13039/20608)\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (1.0234) | Acc: (63.36%) (13868/21888)\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (1.0238) | Acc: (63.35%) (14676/23168)\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (1.0250) | Acc: (63.27%) (15468/24448)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (1.0238) | Acc: (63.37%) (16303/25728)\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (1.0242) | Acc: (63.40%) (17122/27008)\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (1.0229) | Acc: (63.43%) (17944/28288)\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (1.0232) | Acc: (63.46%) (18763/29568)\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (1.0228) | Acc: (63.49%) (19584/30848)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (1.0231) | Acc: (63.55%) (20417/32128)\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (1.0225) | Acc: (63.56%) (21235/33408)\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (1.0222) | Acc: (63.58%) (22053/34688)\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (1.0212) | Acc: (63.61%) (22881/35968)\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (1.0191) | Acc: (63.69%) (23722/37248)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (1.0186) | Acc: (63.72%) (24551/38528)\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (1.0147) | Acc: (63.87%) (25424/39808)\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (1.0138) | Acc: (63.89%) (26253/41088)\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (1.0141) | Acc: (63.90%) (27074/42368)\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (1.0131) | Acc: (63.93%) (27905/43648)\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (1.0122) | Acc: (63.96%) (28735/44928)\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (1.0116) | Acc: (64.00%) (29574/46208)\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (1.0112) | Acc: (64.02%) (30402/47488)\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (1.0107) | Acc: (64.02%) (31220/48768)\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (1.0100) | Acc: (64.06%) (32030/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.0242) | Acc: (63.59%) (6359/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (1.0627) | Acc: (63.28%) (81/128)\n",
      "Epoch: 5 | Batch_idx: 10 |  Loss: (0.9352) | Acc: (65.13%) (917/1408)\n",
      "Epoch: 5 | Batch_idx: 20 |  Loss: (0.9492) | Acc: (64.84%) (1743/2688)\n",
      "Epoch: 5 | Batch_idx: 30 |  Loss: (0.9401) | Acc: (65.78%) (2610/3968)\n",
      "Epoch: 5 | Batch_idx: 40 |  Loss: (0.9424) | Acc: (65.80%) (3453/5248)\n",
      "Epoch: 5 | Batch_idx: 50 |  Loss: (0.9427) | Acc: (65.98%) (4307/6528)\n",
      "Epoch: 5 | Batch_idx: 60 |  Loss: (0.9507) | Acc: (65.61%) (5123/7808)\n",
      "Epoch: 5 | Batch_idx: 70 |  Loss: (0.9556) | Acc: (65.28%) (5933/9088)\n",
      "Epoch: 5 | Batch_idx: 80 |  Loss: (0.9572) | Acc: (65.20%) (6760/10368)\n",
      "Epoch: 5 | Batch_idx: 90 |  Loss: (0.9532) | Acc: (65.43%) (7621/11648)\n",
      "Epoch: 5 | Batch_idx: 100 |  Loss: (0.9478) | Acc: (65.59%) (8480/12928)\n",
      "Epoch: 5 | Batch_idx: 110 |  Loss: (0.9439) | Acc: (65.59%) (9319/14208)\n",
      "Epoch: 5 | Batch_idx: 120 |  Loss: (0.9444) | Acc: (65.72%) (10179/15488)\n",
      "Epoch: 5 | Batch_idx: 130 |  Loss: (0.9445) | Acc: (65.78%) (11030/16768)\n",
      "Epoch: 5 | Batch_idx: 140 |  Loss: (0.9409) | Acc: (66.01%) (11914/18048)\n",
      "Epoch: 5 | Batch_idx: 150 |  Loss: (0.9439) | Acc: (65.91%) (12739/19328)\n",
      "Epoch: 5 | Batch_idx: 160 |  Loss: (0.9468) | Acc: (65.89%) (13579/20608)\n",
      "Epoch: 5 | Batch_idx: 170 |  Loss: (0.9471) | Acc: (65.87%) (14418/21888)\n",
      "Epoch: 5 | Batch_idx: 180 |  Loss: (0.9465) | Acc: (65.86%) (15258/23168)\n",
      "Epoch: 5 | Batch_idx: 190 |  Loss: (0.9456) | Acc: (65.91%) (16114/24448)\n",
      "Epoch: 5 | Batch_idx: 200 |  Loss: (0.9453) | Acc: (65.94%) (16966/25728)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Batch_idx: 210 |  Loss: (0.9467) | Acc: (65.90%) (17799/27008)\n",
      "Epoch: 5 | Batch_idx: 220 |  Loss: (0.9444) | Acc: (66.01%) (18674/28288)\n",
      "Epoch: 5 | Batch_idx: 230 |  Loss: (0.9447) | Acc: (66.02%) (19522/29568)\n",
      "Epoch: 5 | Batch_idx: 240 |  Loss: (0.9439) | Acc: (66.08%) (20385/30848)\n",
      "Epoch: 5 | Batch_idx: 250 |  Loss: (0.9428) | Acc: (66.09%) (21233/32128)\n",
      "Epoch: 5 | Batch_idx: 260 |  Loss: (0.9433) | Acc: (66.09%) (22080/33408)\n",
      "Epoch: 5 | Batch_idx: 270 |  Loss: (0.9437) | Acc: (66.04%) (22908/34688)\n",
      "Epoch: 5 | Batch_idx: 280 |  Loss: (0.9444) | Acc: (66.05%) (23756/35968)\n",
      "Epoch: 5 | Batch_idx: 290 |  Loss: (0.9436) | Acc: (66.11%) (24626/37248)\n",
      "Epoch: 5 | Batch_idx: 300 |  Loss: (0.9427) | Acc: (66.19%) (25503/38528)\n",
      "Epoch: 5 | Batch_idx: 310 |  Loss: (0.9418) | Acc: (66.27%) (26381/39808)\n",
      "Epoch: 5 | Batch_idx: 320 |  Loss: (0.9416) | Acc: (66.30%) (27242/41088)\n",
      "Epoch: 5 | Batch_idx: 330 |  Loss: (0.9425) | Acc: (66.30%) (28090/42368)\n",
      "Epoch: 5 | Batch_idx: 340 |  Loss: (0.9419) | Acc: (66.32%) (28949/43648)\n",
      "Epoch: 5 | Batch_idx: 350 |  Loss: (0.9411) | Acc: (66.40%) (29830/44928)\n",
      "Epoch: 5 | Batch_idx: 360 |  Loss: (0.9407) | Acc: (66.46%) (30709/46208)\n",
      "Epoch: 5 | Batch_idx: 370 |  Loss: (0.9401) | Acc: (66.51%) (31585/47488)\n",
      "Epoch: 5 | Batch_idx: 380 |  Loss: (0.9388) | Acc: (66.55%) (32454/48768)\n",
      "Epoch: 5 | Batch_idx: 390 |  Loss: (0.9394) | Acc: (66.57%) (33283/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.0903) | Acc: (63.18%) (6318/10000)\n",
      "Epoch: 6 | Batch_idx: 0 |  Loss: (0.8690) | Acc: (73.44%) (94/128)\n",
      "Epoch: 6 | Batch_idx: 10 |  Loss: (0.8643) | Acc: (69.03%) (972/1408)\n",
      "Epoch: 6 | Batch_idx: 20 |  Loss: (0.8807) | Acc: (67.86%) (1824/2688)\n",
      "Epoch: 6 | Batch_idx: 30 |  Loss: (0.8898) | Acc: (67.74%) (2688/3968)\n",
      "Epoch: 6 | Batch_idx: 40 |  Loss: (0.8861) | Acc: (67.76%) (3556/5248)\n",
      "Epoch: 6 | Batch_idx: 50 |  Loss: (0.9003) | Acc: (67.66%) (4417/6528)\n",
      "Epoch: 6 | Batch_idx: 60 |  Loss: (0.8995) | Acc: (67.73%) (5288/7808)\n",
      "Epoch: 6 | Batch_idx: 70 |  Loss: (0.8997) | Acc: (67.69%) (6152/9088)\n",
      "Epoch: 6 | Batch_idx: 80 |  Loss: (0.8958) | Acc: (67.81%) (7031/10368)\n",
      "Epoch: 6 | Batch_idx: 90 |  Loss: (0.8923) | Acc: (68.03%) (7924/11648)\n",
      "Epoch: 6 | Batch_idx: 100 |  Loss: (0.8926) | Acc: (68.15%) (8811/12928)\n",
      "Epoch: 6 | Batch_idx: 110 |  Loss: (0.8922) | Acc: (68.28%) (9701/14208)\n",
      "Epoch: 6 | Batch_idx: 120 |  Loss: (0.8925) | Acc: (68.24%) (10569/15488)\n",
      "Epoch: 6 | Batch_idx: 130 |  Loss: (0.8920) | Acc: (68.30%) (11453/16768)\n",
      "Epoch: 6 | Batch_idx: 140 |  Loss: (0.8876) | Acc: (68.48%) (12360/18048)\n",
      "Epoch: 6 | Batch_idx: 150 |  Loss: (0.8919) | Acc: (68.40%) (13220/19328)\n",
      "Epoch: 6 | Batch_idx: 160 |  Loss: (0.8899) | Acc: (68.46%) (14108/20608)\n",
      "Epoch: 6 | Batch_idx: 170 |  Loss: (0.8899) | Acc: (68.42%) (14976/21888)\n",
      "Epoch: 6 | Batch_idx: 180 |  Loss: (0.8912) | Acc: (68.43%) (15855/23168)\n",
      "Epoch: 6 | Batch_idx: 190 |  Loss: (0.8904) | Acc: (68.53%) (16755/24448)\n",
      "Epoch: 6 | Batch_idx: 200 |  Loss: (0.8926) | Acc: (68.47%) (17615/25728)\n",
      "Epoch: 6 | Batch_idx: 210 |  Loss: (0.8907) | Acc: (68.49%) (18499/27008)\n",
      "Epoch: 6 | Batch_idx: 220 |  Loss: (0.8913) | Acc: (68.55%) (19392/28288)\n",
      "Epoch: 6 | Batch_idx: 230 |  Loss: (0.8905) | Acc: (68.60%) (20285/29568)\n",
      "Epoch: 6 | Batch_idx: 240 |  Loss: (0.8891) | Acc: (68.69%) (21189/30848)\n",
      "Epoch: 6 | Batch_idx: 250 |  Loss: (0.8890) | Acc: (68.66%) (22058/32128)\n",
      "Epoch: 6 | Batch_idx: 260 |  Loss: (0.8887) | Acc: (68.68%) (22946/33408)\n",
      "Epoch: 6 | Batch_idx: 270 |  Loss: (0.8881) | Acc: (68.67%) (23821/34688)\n",
      "Epoch: 6 | Batch_idx: 280 |  Loss: (0.8883) | Acc: (68.66%) (24694/35968)\n",
      "Epoch: 6 | Batch_idx: 290 |  Loss: (0.8873) | Acc: (68.66%) (25573/37248)\n",
      "Epoch: 6 | Batch_idx: 300 |  Loss: (0.8865) | Acc: (68.63%) (26443/38528)\n",
      "Epoch: 6 | Batch_idx: 310 |  Loss: (0.8861) | Acc: (68.62%) (27318/39808)\n",
      "Epoch: 6 | Batch_idx: 320 |  Loss: (0.8864) | Acc: (68.57%) (28175/41088)\n",
      "Epoch: 6 | Batch_idx: 330 |  Loss: (0.8864) | Acc: (68.59%) (29061/42368)\n",
      "Epoch: 6 | Batch_idx: 340 |  Loss: (0.8854) | Acc: (68.64%) (29962/43648)\n",
      "Epoch: 6 | Batch_idx: 350 |  Loss: (0.8842) | Acc: (68.68%) (30855/44928)\n",
      "Epoch: 6 | Batch_idx: 360 |  Loss: (0.8837) | Acc: (68.69%) (31740/46208)\n",
      "Epoch: 6 | Batch_idx: 370 |  Loss: (0.8835) | Acc: (68.68%) (32613/47488)\n",
      "Epoch: 6 | Batch_idx: 380 |  Loss: (0.8853) | Acc: (68.61%) (33461/48768)\n",
      "Epoch: 6 | Batch_idx: 390 |  Loss: (0.8855) | Acc: (68.63%) (34315/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9625) | Acc: (66.84%) (6684/10000)\n",
      "Epoch: 7 | Batch_idx: 0 |  Loss: (0.7876) | Acc: (71.88%) (92/128)\n",
      "Epoch: 7 | Batch_idx: 10 |  Loss: (0.8430) | Acc: (71.09%) (1001/1408)\n",
      "Epoch: 7 | Batch_idx: 20 |  Loss: (0.8392) | Acc: (70.50%) (1895/2688)\n",
      "Epoch: 7 | Batch_idx: 30 |  Loss: (0.8432) | Acc: (70.36%) (2792/3968)\n",
      "Epoch: 7 | Batch_idx: 40 |  Loss: (0.8407) | Acc: (70.33%) (3691/5248)\n",
      "Epoch: 7 | Batch_idx: 50 |  Loss: (0.8375) | Acc: (70.48%) (4601/6528)\n",
      "Epoch: 7 | Batch_idx: 60 |  Loss: (0.8335) | Acc: (70.76%) (5525/7808)\n",
      "Epoch: 7 | Batch_idx: 70 |  Loss: (0.8343) | Acc: (70.79%) (6433/9088)\n",
      "Epoch: 7 | Batch_idx: 80 |  Loss: (0.8337) | Acc: (70.68%) (7328/10368)\n",
      "Epoch: 7 | Batch_idx: 90 |  Loss: (0.8296) | Acc: (70.85%) (8253/11648)\n",
      "Epoch: 7 | Batch_idx: 100 |  Loss: (0.8354) | Acc: (70.65%) (9134/12928)\n",
      "Epoch: 7 | Batch_idx: 110 |  Loss: (0.8350) | Acc: (70.71%) (10046/14208)\n",
      "Epoch: 7 | Batch_idx: 120 |  Loss: (0.8319) | Acc: (70.80%) (10966/15488)\n",
      "Epoch: 7 | Batch_idx: 130 |  Loss: (0.8332) | Acc: (70.60%) (11838/16768)\n",
      "Epoch: 7 | Batch_idx: 140 |  Loss: (0.8358) | Acc: (70.60%) (12742/18048)\n",
      "Epoch: 7 | Batch_idx: 150 |  Loss: (0.8358) | Acc: (70.47%) (13621/19328)\n",
      "Epoch: 7 | Batch_idx: 160 |  Loss: (0.8382) | Acc: (70.34%) (14495/20608)\n",
      "Epoch: 7 | Batch_idx: 170 |  Loss: (0.8415) | Acc: (70.24%) (15375/21888)\n",
      "Epoch: 7 | Batch_idx: 180 |  Loss: (0.8403) | Acc: (70.27%) (16280/23168)\n",
      "Epoch: 7 | Batch_idx: 190 |  Loss: (0.8402) | Acc: (70.31%) (17189/24448)\n",
      "Epoch: 7 | Batch_idx: 200 |  Loss: (0.8414) | Acc: (70.34%) (18096/25728)\n",
      "Epoch: 7 | Batch_idx: 210 |  Loss: (0.8417) | Acc: (70.40%) (19014/27008)\n",
      "Epoch: 7 | Batch_idx: 220 |  Loss: (0.8397) | Acc: (70.51%) (19946/28288)\n",
      "Epoch: 7 | Batch_idx: 230 |  Loss: (0.8373) | Acc: (70.64%) (20888/29568)\n",
      "Epoch: 7 | Batch_idx: 240 |  Loss: (0.8358) | Acc: (70.62%) (21785/30848)\n",
      "Epoch: 7 | Batch_idx: 250 |  Loss: (0.8369) | Acc: (70.57%) (22672/32128)\n",
      "Epoch: 7 | Batch_idx: 260 |  Loss: (0.8370) | Acc: (70.55%) (23571/33408)\n",
      "Epoch: 7 | Batch_idx: 270 |  Loss: (0.8386) | Acc: (70.51%) (24458/34688)\n",
      "Epoch: 7 | Batch_idx: 280 |  Loss: (0.8396) | Acc: (70.45%) (25341/35968)\n",
      "Epoch: 7 | Batch_idx: 290 |  Loss: (0.8404) | Acc: (70.42%) (26230/37248)\n",
      "Epoch: 7 | Batch_idx: 300 |  Loss: (0.8403) | Acc: (70.42%) (27133/38528)\n",
      "Epoch: 7 | Batch_idx: 310 |  Loss: (0.8396) | Acc: (70.49%) (28059/39808)\n",
      "Epoch: 7 | Batch_idx: 320 |  Loss: (0.8404) | Acc: (70.46%) (28952/41088)\n",
      "Epoch: 7 | Batch_idx: 330 |  Loss: (0.8388) | Acc: (70.51%) (29875/42368)\n",
      "Epoch: 7 | Batch_idx: 340 |  Loss: (0.8392) | Acc: (70.45%) (30749/43648)\n",
      "Epoch: 7 | Batch_idx: 350 |  Loss: (0.8397) | Acc: (70.45%) (31652/44928)\n",
      "Epoch: 7 | Batch_idx: 360 |  Loss: (0.8396) | Acc: (70.47%) (32561/46208)\n",
      "Epoch: 7 | Batch_idx: 370 |  Loss: (0.8385) | Acc: (70.51%) (33484/47488)\n",
      "Epoch: 7 | Batch_idx: 380 |  Loss: (0.8382) | Acc: (70.55%) (34406/48768)\n",
      "Epoch: 7 | Batch_idx: 390 |  Loss: (0.8380) | Acc: (70.56%) (35281/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.0135) | Acc: (64.58%) (6458/10000)\n",
      "Epoch: 8 | Batch_idx: 0 |  Loss: (0.8278) | Acc: (72.66%) (93/128)\n",
      "Epoch: 8 | Batch_idx: 10 |  Loss: (0.8589) | Acc: (70.60%) (994/1408)\n",
      "Epoch: 8 | Batch_idx: 20 |  Loss: (0.8183) | Acc: (71.21%) (1914/2688)\n",
      "Epoch: 8 | Batch_idx: 30 |  Loss: (0.8219) | Acc: (71.07%) (2820/3968)\n",
      "Epoch: 8 | Batch_idx: 40 |  Loss: (0.8228) | Acc: (70.83%) (3717/5248)\n",
      "Epoch: 8 | Batch_idx: 50 |  Loss: (0.8234) | Acc: (70.70%) (4615/6528)\n",
      "Epoch: 8 | Batch_idx: 60 |  Loss: (0.8139) | Acc: (71.09%) (5551/7808)\n",
      "Epoch: 8 | Batch_idx: 70 |  Loss: (0.8144) | Acc: (70.96%) (6449/9088)\n",
      "Epoch: 8 | Batch_idx: 80 |  Loss: (0.8129) | Acc: (70.98%) (7359/10368)\n",
      "Epoch: 8 | Batch_idx: 90 |  Loss: (0.8123) | Acc: (71.02%) (8272/11648)\n",
      "Epoch: 8 | Batch_idx: 100 |  Loss: (0.8131) | Acc: (71.12%) (9194/12928)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Batch_idx: 110 |  Loss: (0.8153) | Acc: (71.01%) (10089/14208)\n",
      "Epoch: 8 | Batch_idx: 120 |  Loss: (0.8127) | Acc: (71.14%) (11018/15488)\n",
      "Epoch: 8 | Batch_idx: 130 |  Loss: (0.8129) | Acc: (71.12%) (11926/16768)\n",
      "Epoch: 8 | Batch_idx: 140 |  Loss: (0.8120) | Acc: (71.09%) (12830/18048)\n",
      "Epoch: 8 | Batch_idx: 150 |  Loss: (0.8114) | Acc: (71.25%) (13772/19328)\n",
      "Epoch: 8 | Batch_idx: 160 |  Loss: (0.8096) | Acc: (71.30%) (14694/20608)\n",
      "Epoch: 8 | Batch_idx: 170 |  Loss: (0.8068) | Acc: (71.39%) (15625/21888)\n",
      "Epoch: 8 | Batch_idx: 180 |  Loss: (0.8053) | Acc: (71.43%) (16549/23168)\n",
      "Epoch: 8 | Batch_idx: 190 |  Loss: (0.8055) | Acc: (71.47%) (17474/24448)\n",
      "Epoch: 8 | Batch_idx: 200 |  Loss: (0.8046) | Acc: (71.48%) (18391/25728)\n",
      "Epoch: 8 | Batch_idx: 210 |  Loss: (0.8049) | Acc: (71.47%) (19302/27008)\n",
      "Epoch: 8 | Batch_idx: 220 |  Loss: (0.8039) | Acc: (71.51%) (20229/28288)\n",
      "Epoch: 8 | Batch_idx: 230 |  Loss: (0.8020) | Acc: (71.60%) (21172/29568)\n",
      "Epoch: 8 | Batch_idx: 240 |  Loss: (0.8013) | Acc: (71.59%) (22084/30848)\n",
      "Epoch: 8 | Batch_idx: 250 |  Loss: (0.8013) | Acc: (71.60%) (23005/32128)\n",
      "Epoch: 8 | Batch_idx: 260 |  Loss: (0.8021) | Acc: (71.58%) (23913/33408)\n",
      "Epoch: 8 | Batch_idx: 270 |  Loss: (0.8008) | Acc: (71.60%) (24837/34688)\n",
      "Epoch: 8 | Batch_idx: 280 |  Loss: (0.8025) | Acc: (71.51%) (25722/35968)\n",
      "Epoch: 8 | Batch_idx: 290 |  Loss: (0.8026) | Acc: (71.49%) (26627/37248)\n",
      "Epoch: 8 | Batch_idx: 300 |  Loss: (0.8003) | Acc: (71.57%) (27574/38528)\n",
      "Epoch: 8 | Batch_idx: 310 |  Loss: (0.7998) | Acc: (71.57%) (28492/39808)\n",
      "Epoch: 8 | Batch_idx: 320 |  Loss: (0.7990) | Acc: (71.60%) (29417/41088)\n",
      "Epoch: 8 | Batch_idx: 330 |  Loss: (0.7990) | Acc: (71.62%) (30342/42368)\n",
      "Epoch: 8 | Batch_idx: 340 |  Loss: (0.7979) | Acc: (71.63%) (31267/43648)\n",
      "Epoch: 8 | Batch_idx: 350 |  Loss: (0.7981) | Acc: (71.65%) (32189/44928)\n",
      "Epoch: 8 | Batch_idx: 360 |  Loss: (0.7978) | Acc: (71.66%) (33112/46208)\n",
      "Epoch: 8 | Batch_idx: 370 |  Loss: (0.7964) | Acc: (71.70%) (34049/47488)\n",
      "Epoch: 8 | Batch_idx: 380 |  Loss: (0.7975) | Acc: (71.67%) (34952/48768)\n",
      "Epoch: 8 | Batch_idx: 390 |  Loss: (0.7977) | Acc: (71.67%) (35837/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9500) | Acc: (67.80%) (6780/10000)\n",
      "Epoch: 9 | Batch_idx: 0 |  Loss: (0.6903) | Acc: (76.56%) (98/128)\n",
      "Epoch: 9 | Batch_idx: 10 |  Loss: (0.7102) | Acc: (75.36%) (1061/1408)\n",
      "Epoch: 9 | Batch_idx: 20 |  Loss: (0.7279) | Acc: (73.66%) (1980/2688)\n",
      "Epoch: 9 | Batch_idx: 30 |  Loss: (0.7313) | Acc: (73.79%) (2928/3968)\n",
      "Epoch: 9 | Batch_idx: 40 |  Loss: (0.7433) | Acc: (73.44%) (3854/5248)\n",
      "Epoch: 9 | Batch_idx: 50 |  Loss: (0.7442) | Acc: (73.59%) (4804/6528)\n",
      "Epoch: 9 | Batch_idx: 60 |  Loss: (0.7459) | Acc: (73.37%) (5729/7808)\n",
      "Epoch: 9 | Batch_idx: 70 |  Loss: (0.7497) | Acc: (73.29%) (6661/9088)\n",
      "Epoch: 9 | Batch_idx: 80 |  Loss: (0.7530) | Acc: (73.27%) (7597/10368)\n",
      "Epoch: 9 | Batch_idx: 90 |  Loss: (0.7565) | Acc: (73.14%) (8519/11648)\n",
      "Epoch: 9 | Batch_idx: 100 |  Loss: (0.7593) | Acc: (73.04%) (9443/12928)\n",
      "Epoch: 9 | Batch_idx: 110 |  Loss: (0.7614) | Acc: (73.13%) (10391/14208)\n",
      "Epoch: 9 | Batch_idx: 120 |  Loss: (0.7588) | Acc: (73.24%) (11343/15488)\n",
      "Epoch: 9 | Batch_idx: 130 |  Loss: (0.7572) | Acc: (73.23%) (12280/16768)\n",
      "Epoch: 9 | Batch_idx: 140 |  Loss: (0.7592) | Acc: (73.19%) (13210/18048)\n",
      "Epoch: 9 | Batch_idx: 150 |  Loss: (0.7571) | Acc: (73.25%) (14157/19328)\n",
      "Epoch: 9 | Batch_idx: 160 |  Loss: (0.7569) | Acc: (73.26%) (15098/20608)\n",
      "Epoch: 9 | Batch_idx: 170 |  Loss: (0.7586) | Acc: (73.16%) (16013/21888)\n",
      "Epoch: 9 | Batch_idx: 180 |  Loss: (0.7573) | Acc: (73.16%) (16950/23168)\n",
      "Epoch: 9 | Batch_idx: 190 |  Loss: (0.7582) | Acc: (73.15%) (17883/24448)\n",
      "Epoch: 9 | Batch_idx: 200 |  Loss: (0.7587) | Acc: (73.15%) (18819/25728)\n",
      "Epoch: 9 | Batch_idx: 210 |  Loss: (0.7581) | Acc: (73.19%) (19768/27008)\n",
      "Epoch: 9 | Batch_idx: 220 |  Loss: (0.7566) | Acc: (73.27%) (20726/28288)\n",
      "Epoch: 9 | Batch_idx: 230 |  Loss: (0.7574) | Acc: (73.28%) (21667/29568)\n",
      "Epoch: 9 | Batch_idx: 240 |  Loss: (0.7597) | Acc: (73.20%) (22580/30848)\n",
      "Epoch: 9 | Batch_idx: 250 |  Loss: (0.7598) | Acc: (73.19%) (23516/32128)\n",
      "Epoch: 9 | Batch_idx: 260 |  Loss: (0.7612) | Acc: (73.12%) (24427/33408)\n",
      "Epoch: 9 | Batch_idx: 270 |  Loss: (0.7585) | Acc: (73.21%) (25394/34688)\n",
      "Epoch: 9 | Batch_idx: 280 |  Loss: (0.7582) | Acc: (73.20%) (26329/35968)\n",
      "Epoch: 9 | Batch_idx: 290 |  Loss: (0.7588) | Acc: (73.19%) (27262/37248)\n",
      "Epoch: 9 | Batch_idx: 300 |  Loss: (0.7594) | Acc: (73.19%) (28198/38528)\n",
      "Epoch: 9 | Batch_idx: 310 |  Loss: (0.7601) | Acc: (73.15%) (29120/39808)\n",
      "Epoch: 9 | Batch_idx: 320 |  Loss: (0.7582) | Acc: (73.21%) (30081/41088)\n",
      "Epoch: 9 | Batch_idx: 330 |  Loss: (0.7590) | Acc: (73.22%) (31022/42368)\n",
      "Epoch: 9 | Batch_idx: 340 |  Loss: (0.7600) | Acc: (73.15%) (31927/43648)\n",
      "Epoch: 9 | Batch_idx: 350 |  Loss: (0.7599) | Acc: (73.13%) (32854/44928)\n",
      "Epoch: 9 | Batch_idx: 360 |  Loss: (0.7605) | Acc: (73.08%) (33770/46208)\n",
      "Epoch: 9 | Batch_idx: 370 |  Loss: (0.7607) | Acc: (73.10%) (34716/47488)\n",
      "Epoch: 9 | Batch_idx: 380 |  Loss: (0.7601) | Acc: (73.13%) (35663/48768)\n",
      "Epoch: 9 | Batch_idx: 390 |  Loss: (0.7586) | Acc: (73.18%) (36590/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8438) | Acc: (70.68%) (7068/10000)\n",
      "Epoch: 10 | Batch_idx: 0 |  Loss: (0.8882) | Acc: (66.41%) (85/128)\n",
      "Epoch: 10 | Batch_idx: 10 |  Loss: (0.7552) | Acc: (73.72%) (1038/1408)\n",
      "Epoch: 10 | Batch_idx: 20 |  Loss: (0.7538) | Acc: (74.11%) (1992/2688)\n",
      "Epoch: 10 | Batch_idx: 30 |  Loss: (0.7526) | Acc: (74.14%) (2942/3968)\n",
      "Epoch: 10 | Batch_idx: 40 |  Loss: (0.7624) | Acc: (73.38%) (3851/5248)\n",
      "Epoch: 10 | Batch_idx: 50 |  Loss: (0.7525) | Acc: (73.90%) (4824/6528)\n",
      "Epoch: 10 | Batch_idx: 60 |  Loss: (0.7508) | Acc: (73.98%) (5776/7808)\n",
      "Epoch: 10 | Batch_idx: 70 |  Loss: (0.7539) | Acc: (73.89%) (6715/9088)\n",
      "Epoch: 10 | Batch_idx: 80 |  Loss: (0.7538) | Acc: (73.78%) (7650/10368)\n",
      "Epoch: 10 | Batch_idx: 90 |  Loss: (0.7450) | Acc: (73.93%) (8611/11648)\n",
      "Epoch: 10 | Batch_idx: 100 |  Loss: (0.7436) | Acc: (74.08%) (9577/12928)\n",
      "Epoch: 10 | Batch_idx: 110 |  Loss: (0.7378) | Acc: (74.28%) (10554/14208)\n",
      "Epoch: 10 | Batch_idx: 120 |  Loss: (0.7366) | Acc: (74.22%) (11495/15488)\n",
      "Epoch: 10 | Batch_idx: 130 |  Loss: (0.7346) | Acc: (74.31%) (12460/16768)\n",
      "Epoch: 10 | Batch_idx: 140 |  Loss: (0.7322) | Acc: (74.27%) (13405/18048)\n",
      "Epoch: 10 | Batch_idx: 150 |  Loss: (0.7339) | Acc: (74.16%) (14333/19328)\n",
      "Epoch: 10 | Batch_idx: 160 |  Loss: (0.7357) | Acc: (74.10%) (15270/20608)\n",
      "Epoch: 10 | Batch_idx: 170 |  Loss: (0.7343) | Acc: (74.10%) (16219/21888)\n",
      "Epoch: 10 | Batch_idx: 180 |  Loss: (0.7333) | Acc: (74.11%) (17170/23168)\n",
      "Epoch: 10 | Batch_idx: 190 |  Loss: (0.7325) | Acc: (74.16%) (18131/24448)\n",
      "Epoch: 10 | Batch_idx: 200 |  Loss: (0.7314) | Acc: (74.24%) (19100/25728)\n",
      "Epoch: 10 | Batch_idx: 210 |  Loss: (0.7326) | Acc: (74.17%) (20033/27008)\n",
      "Epoch: 10 | Batch_idx: 220 |  Loss: (0.7334) | Acc: (74.09%) (20959/28288)\n",
      "Epoch: 10 | Batch_idx: 230 |  Loss: (0.7333) | Acc: (74.15%) (21926/29568)\n",
      "Epoch: 10 | Batch_idx: 240 |  Loss: (0.7326) | Acc: (74.21%) (22891/30848)\n",
      "Epoch: 10 | Batch_idx: 250 |  Loss: (0.7322) | Acc: (74.21%) (23841/32128)\n",
      "Epoch: 10 | Batch_idx: 260 |  Loss: (0.7331) | Acc: (74.13%) (24767/33408)\n",
      "Epoch: 10 | Batch_idx: 270 |  Loss: (0.7329) | Acc: (74.18%) (25732/34688)\n",
      "Epoch: 10 | Batch_idx: 280 |  Loss: (0.7321) | Acc: (74.24%) (26704/35968)\n",
      "Epoch: 10 | Batch_idx: 290 |  Loss: (0.7304) | Acc: (74.28%) (27668/37248)\n",
      "Epoch: 10 | Batch_idx: 300 |  Loss: (0.7301) | Acc: (74.33%) (28637/38528)\n",
      "Epoch: 10 | Batch_idx: 310 |  Loss: (0.7296) | Acc: (74.33%) (29589/39808)\n",
      "Epoch: 10 | Batch_idx: 320 |  Loss: (0.7299) | Acc: (74.35%) (30548/41088)\n",
      "Epoch: 10 | Batch_idx: 330 |  Loss: (0.7308) | Acc: (74.30%) (31481/42368)\n",
      "Epoch: 10 | Batch_idx: 340 |  Loss: (0.7295) | Acc: (74.35%) (32454/43648)\n",
      "Epoch: 10 | Batch_idx: 350 |  Loss: (0.7291) | Acc: (74.38%) (33417/44928)\n",
      "Epoch: 10 | Batch_idx: 360 |  Loss: (0.7278) | Acc: (74.40%) (34380/46208)\n",
      "Epoch: 10 | Batch_idx: 370 |  Loss: (0.7265) | Acc: (74.43%) (35345/47488)\n",
      "Epoch: 10 | Batch_idx: 380 |  Loss: (0.7262) | Acc: (74.44%) (36305/48768)\n",
      "Epoch: 10 | Batch_idx: 390 |  Loss: (0.7251) | Acc: (74.46%) (37231/50000)\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TEST : Loss: (0.8007) | Acc: (71.98%) (7198/10000)\n",
      "Epoch: 11 | Batch_idx: 0 |  Loss: (0.5799) | Acc: (79.69%) (102/128)\n",
      "Epoch: 11 | Batch_idx: 10 |  Loss: (0.7196) | Acc: (74.72%) (1052/1408)\n",
      "Epoch: 11 | Batch_idx: 20 |  Loss: (0.7080) | Acc: (75.04%) (2017/2688)\n",
      "Epoch: 11 | Batch_idx: 30 |  Loss: (0.7061) | Acc: (75.43%) (2993/3968)\n",
      "Epoch: 11 | Batch_idx: 40 |  Loss: (0.7113) | Acc: (74.92%) (3932/5248)\n",
      "Epoch: 11 | Batch_idx: 50 |  Loss: (0.7017) | Acc: (75.43%) (4924/6528)\n",
      "Epoch: 11 | Batch_idx: 60 |  Loss: (0.7052) | Acc: (75.15%) (5868/7808)\n",
      "Epoch: 11 | Batch_idx: 70 |  Loss: (0.7072) | Acc: (75.18%) (6832/9088)\n",
      "Epoch: 11 | Batch_idx: 80 |  Loss: (0.7069) | Acc: (75.14%) (7791/10368)\n",
      "Epoch: 11 | Batch_idx: 90 |  Loss: (0.7067) | Acc: (75.14%) (8752/11648)\n",
      "Epoch: 11 | Batch_idx: 100 |  Loss: (0.7068) | Acc: (75.06%) (9704/12928)\n",
      "Epoch: 11 | Batch_idx: 110 |  Loss: (0.7029) | Acc: (75.18%) (10682/14208)\n",
      "Epoch: 11 | Batch_idx: 120 |  Loss: (0.7019) | Acc: (75.13%) (11636/15488)\n",
      "Epoch: 11 | Batch_idx: 130 |  Loss: (0.6999) | Acc: (75.26%) (12620/16768)\n",
      "Epoch: 11 | Batch_idx: 140 |  Loss: (0.7010) | Acc: (75.36%) (13601/18048)\n",
      "Epoch: 11 | Batch_idx: 150 |  Loss: (0.7040) | Acc: (75.27%) (14549/19328)\n",
      "Epoch: 11 | Batch_idx: 160 |  Loss: (0.7012) | Acc: (75.35%) (15528/20608)\n",
      "Epoch: 11 | Batch_idx: 170 |  Loss: (0.7001) | Acc: (75.46%) (16517/21888)\n",
      "Epoch: 11 | Batch_idx: 180 |  Loss: (0.7026) | Acc: (75.34%) (17455/23168)\n",
      "Epoch: 11 | Batch_idx: 190 |  Loss: (0.7001) | Acc: (75.43%) (18441/24448)\n",
      "Epoch: 11 | Batch_idx: 200 |  Loss: (0.6995) | Acc: (75.47%) (19418/25728)\n",
      "Epoch: 11 | Batch_idx: 210 |  Loss: (0.6992) | Acc: (75.44%) (20375/27008)\n",
      "Epoch: 11 | Batch_idx: 220 |  Loss: (0.7020) | Acc: (75.34%) (21313/28288)\n",
      "Epoch: 11 | Batch_idx: 230 |  Loss: (0.7011) | Acc: (75.36%) (22283/29568)\n",
      "Epoch: 11 | Batch_idx: 240 |  Loss: (0.7002) | Acc: (75.42%) (23266/30848)\n",
      "Epoch: 11 | Batch_idx: 250 |  Loss: (0.7010) | Acc: (75.37%) (24215/32128)\n",
      "Epoch: 11 | Batch_idx: 260 |  Loss: (0.7019) | Acc: (75.35%) (25172/33408)\n",
      "Epoch: 11 | Batch_idx: 270 |  Loss: (0.6999) | Acc: (75.37%) (26143/34688)\n",
      "Epoch: 11 | Batch_idx: 280 |  Loss: (0.6987) | Acc: (75.41%) (27124/35968)\n",
      "Epoch: 11 | Batch_idx: 290 |  Loss: (0.6979) | Acc: (75.43%) (28095/37248)\n",
      "Epoch: 11 | Batch_idx: 300 |  Loss: (0.6976) | Acc: (75.41%) (29054/38528)\n",
      "Epoch: 11 | Batch_idx: 310 |  Loss: (0.6991) | Acc: (75.31%) (29981/39808)\n",
      "Epoch: 11 | Batch_idx: 320 |  Loss: (0.6994) | Acc: (75.33%) (30952/41088)\n",
      "Epoch: 11 | Batch_idx: 330 |  Loss: (0.6993) | Acc: (75.35%) (31924/42368)\n",
      "Epoch: 11 | Batch_idx: 340 |  Loss: (0.6993) | Acc: (75.36%) (32894/43648)\n",
      "Epoch: 11 | Batch_idx: 350 |  Loss: (0.6990) | Acc: (75.36%) (33858/44928)\n",
      "Epoch: 11 | Batch_idx: 360 |  Loss: (0.6995) | Acc: (75.36%) (34824/46208)\n",
      "Epoch: 11 | Batch_idx: 370 |  Loss: (0.6989) | Acc: (75.41%) (35811/47488)\n",
      "Epoch: 11 | Batch_idx: 380 |  Loss: (0.6981) | Acc: (75.47%) (36807/48768)\n",
      "Epoch: 11 | Batch_idx: 390 |  Loss: (0.6974) | Acc: (75.51%) (37755/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7954) | Acc: (72.60%) (7260/10000)\n",
      "Epoch: 12 | Batch_idx: 0 |  Loss: (0.6110) | Acc: (80.47%) (103/128)\n",
      "Epoch: 12 | Batch_idx: 10 |  Loss: (0.6726) | Acc: (76.28%) (1074/1408)\n",
      "Epoch: 12 | Batch_idx: 20 |  Loss: (0.6675) | Acc: (76.00%) (2043/2688)\n",
      "Epoch: 12 | Batch_idx: 30 |  Loss: (0.6669) | Acc: (76.44%) (3033/3968)\n",
      "Epoch: 12 | Batch_idx: 40 |  Loss: (0.6654) | Acc: (76.70%) (4025/5248)\n",
      "Epoch: 12 | Batch_idx: 50 |  Loss: (0.6585) | Acc: (76.91%) (5021/6528)\n",
      "Epoch: 12 | Batch_idx: 60 |  Loss: (0.6593) | Acc: (76.73%) (5991/7808)\n",
      "Epoch: 12 | Batch_idx: 70 |  Loss: (0.6616) | Acc: (76.58%) (6960/9088)\n",
      "Epoch: 12 | Batch_idx: 80 |  Loss: (0.6569) | Acc: (76.75%) (7957/10368)\n",
      "Epoch: 12 | Batch_idx: 90 |  Loss: (0.6601) | Acc: (76.74%) (8939/11648)\n",
      "Epoch: 12 | Batch_idx: 100 |  Loss: (0.6613) | Acc: (76.69%) (9915/12928)\n",
      "Epoch: 12 | Batch_idx: 110 |  Loss: (0.6581) | Acc: (76.82%) (10914/14208)\n",
      "Epoch: 12 | Batch_idx: 120 |  Loss: (0.6627) | Acc: (76.63%) (11868/15488)\n",
      "Epoch: 12 | Batch_idx: 130 |  Loss: (0.6623) | Acc: (76.59%) (12842/16768)\n",
      "Epoch: 12 | Batch_idx: 140 |  Loss: (0.6610) | Acc: (76.66%) (13835/18048)\n",
      "Epoch: 12 | Batch_idx: 150 |  Loss: (0.6628) | Acc: (76.66%) (14816/19328)\n",
      "Epoch: 12 | Batch_idx: 160 |  Loss: (0.6647) | Acc: (76.56%) (15778/20608)\n",
      "Epoch: 12 | Batch_idx: 170 |  Loss: (0.6633) | Acc: (76.61%) (16768/21888)\n",
      "Epoch: 12 | Batch_idx: 180 |  Loss: (0.6638) | Acc: (76.63%) (17754/23168)\n",
      "Epoch: 12 | Batch_idx: 190 |  Loss: (0.6632) | Acc: (76.67%) (18745/24448)\n",
      "Epoch: 12 | Batch_idx: 200 |  Loss: (0.6639) | Acc: (76.69%) (19731/25728)\n",
      "Epoch: 12 | Batch_idx: 210 |  Loss: (0.6650) | Acc: (76.66%) (20705/27008)\n",
      "Epoch: 12 | Batch_idx: 220 |  Loss: (0.6659) | Acc: (76.72%) (21702/28288)\n",
      "Epoch: 12 | Batch_idx: 230 |  Loss: (0.6653) | Acc: (76.77%) (22699/29568)\n",
      "Epoch: 12 | Batch_idx: 240 |  Loss: (0.6665) | Acc: (76.72%) (23667/30848)\n",
      "Epoch: 12 | Batch_idx: 250 |  Loss: (0.6675) | Acc: (76.70%) (24641/32128)\n",
      "Epoch: 12 | Batch_idx: 260 |  Loss: (0.6668) | Acc: (76.73%) (25635/33408)\n",
      "Epoch: 12 | Batch_idx: 270 |  Loss: (0.6667) | Acc: (76.76%) (26626/34688)\n",
      "Epoch: 12 | Batch_idx: 280 |  Loss: (0.6662) | Acc: (76.74%) (27601/35968)\n",
      "Epoch: 12 | Batch_idx: 290 |  Loss: (0.6665) | Acc: (76.73%) (28581/37248)\n",
      "Epoch: 12 | Batch_idx: 300 |  Loss: (0.6674) | Acc: (76.72%) (29557/38528)\n",
      "Epoch: 12 | Batch_idx: 310 |  Loss: (0.6659) | Acc: (76.80%) (30572/39808)\n",
      "Epoch: 12 | Batch_idx: 320 |  Loss: (0.6651) | Acc: (76.83%) (31567/41088)\n",
      "Epoch: 12 | Batch_idx: 330 |  Loss: (0.6646) | Acc: (76.85%) (32559/42368)\n",
      "Epoch: 12 | Batch_idx: 340 |  Loss: (0.6653) | Acc: (76.84%) (33537/43648)\n",
      "Epoch: 12 | Batch_idx: 350 |  Loss: (0.6653) | Acc: (76.85%) (34527/44928)\n",
      "Epoch: 12 | Batch_idx: 360 |  Loss: (0.6637) | Acc: (76.91%) (35539/46208)\n",
      "Epoch: 12 | Batch_idx: 370 |  Loss: (0.6645) | Acc: (76.88%) (36509/47488)\n",
      "Epoch: 12 | Batch_idx: 380 |  Loss: (0.6647) | Acc: (76.90%) (37501/48768)\n",
      "Epoch: 12 | Batch_idx: 390 |  Loss: (0.6640) | Acc: (76.92%) (38462/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7347) | Acc: (73.80%) (7380/10000)\n",
      "Epoch: 13 | Batch_idx: 0 |  Loss: (0.5821) | Acc: (78.91%) (101/128)\n",
      "Epoch: 13 | Batch_idx: 10 |  Loss: (0.6434) | Acc: (78.55%) (1106/1408)\n",
      "Epoch: 13 | Batch_idx: 20 |  Loss: (0.6476) | Acc: (77.83%) (2092/2688)\n",
      "Epoch: 13 | Batch_idx: 30 |  Loss: (0.6377) | Acc: (78.07%) (3098/3968)\n",
      "Epoch: 13 | Batch_idx: 40 |  Loss: (0.6392) | Acc: (77.46%) (4065/5248)\n",
      "Epoch: 13 | Batch_idx: 50 |  Loss: (0.6436) | Acc: (77.39%) (5052/6528)\n",
      "Epoch: 13 | Batch_idx: 60 |  Loss: (0.6390) | Acc: (77.61%) (6060/7808)\n",
      "Epoch: 13 | Batch_idx: 70 |  Loss: (0.6373) | Acc: (77.79%) (7070/9088)\n",
      "Epoch: 13 | Batch_idx: 80 |  Loss: (0.6372) | Acc: (77.82%) (8068/10368)\n",
      "Epoch: 13 | Batch_idx: 90 |  Loss: (0.6365) | Acc: (77.78%) (9060/11648)\n",
      "Epoch: 13 | Batch_idx: 100 |  Loss: (0.6410) | Acc: (77.61%) (10033/12928)\n",
      "Epoch: 13 | Batch_idx: 110 |  Loss: (0.6417) | Acc: (77.51%) (11013/14208)\n",
      "Epoch: 13 | Batch_idx: 120 |  Loss: (0.6438) | Acc: (77.30%) (11972/15488)\n",
      "Epoch: 13 | Batch_idx: 130 |  Loss: (0.6422) | Acc: (77.34%) (12968/16768)\n",
      "Epoch: 13 | Batch_idx: 140 |  Loss: (0.6445) | Acc: (77.24%) (13940/18048)\n",
      "Epoch: 13 | Batch_idx: 150 |  Loss: (0.6453) | Acc: (77.20%) (14921/19328)\n",
      "Epoch: 13 | Batch_idx: 160 |  Loss: (0.6465) | Acc: (77.14%) (15897/20608)\n",
      "Epoch: 13 | Batch_idx: 170 |  Loss: (0.6481) | Acc: (77.12%) (16880/21888)\n",
      "Epoch: 13 | Batch_idx: 180 |  Loss: (0.6502) | Acc: (77.10%) (17863/23168)\n",
      "Epoch: 13 | Batch_idx: 190 |  Loss: (0.6496) | Acc: (77.13%) (18856/24448)\n",
      "Epoch: 13 | Batch_idx: 200 |  Loss: (0.6508) | Acc: (77.03%) (19819/25728)\n",
      "Epoch: 13 | Batch_idx: 210 |  Loss: (0.6494) | Acc: (77.10%) (20822/27008)\n",
      "Epoch: 13 | Batch_idx: 220 |  Loss: (0.6498) | Acc: (77.06%) (21799/28288)\n",
      "Epoch: 13 | Batch_idx: 230 |  Loss: (0.6485) | Acc: (77.12%) (22803/29568)\n",
      "Epoch: 13 | Batch_idx: 240 |  Loss: (0.6471) | Acc: (77.21%) (23818/30848)\n",
      "Epoch: 13 | Batch_idx: 250 |  Loss: (0.6443) | Acc: (77.36%) (24855/32128)\n",
      "Epoch: 13 | Batch_idx: 260 |  Loss: (0.6455) | Acc: (77.36%) (25843/33408)\n",
      "Epoch: 13 | Batch_idx: 270 |  Loss: (0.6453) | Acc: (77.36%) (26836/34688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Batch_idx: 280 |  Loss: (0.6452) | Acc: (77.36%) (27825/35968)\n",
      "Epoch: 13 | Batch_idx: 290 |  Loss: (0.6435) | Acc: (77.36%) (28816/37248)\n",
      "Epoch: 13 | Batch_idx: 300 |  Loss: (0.6431) | Acc: (77.37%) (29810/38528)\n",
      "Epoch: 13 | Batch_idx: 310 |  Loss: (0.6427) | Acc: (77.40%) (30810/39808)\n",
      "Epoch: 13 | Batch_idx: 320 |  Loss: (0.6426) | Acc: (77.42%) (31811/41088)\n",
      "Epoch: 13 | Batch_idx: 330 |  Loss: (0.6419) | Acc: (77.43%) (32806/42368)\n",
      "Epoch: 13 | Batch_idx: 340 |  Loss: (0.6420) | Acc: (77.43%) (33797/43648)\n",
      "Epoch: 13 | Batch_idx: 350 |  Loss: (0.6421) | Acc: (77.41%) (34781/44928)\n",
      "Epoch: 13 | Batch_idx: 360 |  Loss: (0.6422) | Acc: (77.44%) (35784/46208)\n",
      "Epoch: 13 | Batch_idx: 370 |  Loss: (0.6410) | Acc: (77.51%) (36806/47488)\n",
      "Epoch: 13 | Batch_idx: 380 |  Loss: (0.6396) | Acc: (77.58%) (37832/48768)\n",
      "Epoch: 13 | Batch_idx: 390 |  Loss: (0.6399) | Acc: (77.57%) (38786/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7416) | Acc: (74.27%) (7427/10000)\n",
      "Epoch: 14 | Batch_idx: 0 |  Loss: (0.5956) | Acc: (81.25%) (104/128)\n",
      "Epoch: 14 | Batch_idx: 10 |  Loss: (0.6068) | Acc: (79.69%) (1122/1408)\n",
      "Epoch: 14 | Batch_idx: 20 |  Loss: (0.6292) | Acc: (78.24%) (2103/2688)\n",
      "Epoch: 14 | Batch_idx: 30 |  Loss: (0.6438) | Acc: (77.82%) (3088/3968)\n",
      "Epoch: 14 | Batch_idx: 40 |  Loss: (0.6338) | Acc: (78.09%) (4098/5248)\n",
      "Epoch: 14 | Batch_idx: 50 |  Loss: (0.6203) | Acc: (78.54%) (5127/6528)\n",
      "Epoch: 14 | Batch_idx: 60 |  Loss: (0.6219) | Acc: (78.36%) (6118/7808)\n",
      "Epoch: 14 | Batch_idx: 70 |  Loss: (0.6212) | Acc: (78.39%) (7124/9088)\n",
      "Epoch: 14 | Batch_idx: 80 |  Loss: (0.6197) | Acc: (78.51%) (8140/10368)\n",
      "Epoch: 14 | Batch_idx: 90 |  Loss: (0.6201) | Acc: (78.48%) (9141/11648)\n",
      "Epoch: 14 | Batch_idx: 100 |  Loss: (0.6214) | Acc: (78.50%) (10149/12928)\n",
      "Epoch: 14 | Batch_idx: 110 |  Loss: (0.6223) | Acc: (78.46%) (11147/14208)\n",
      "Epoch: 14 | Batch_idx: 120 |  Loss: (0.6247) | Acc: (78.31%) (12129/15488)\n",
      "Epoch: 14 | Batch_idx: 130 |  Loss: (0.6247) | Acc: (78.32%) (13133/16768)\n",
      "Epoch: 14 | Batch_idx: 140 |  Loss: (0.6220) | Acc: (78.44%) (14157/18048)\n",
      "Epoch: 14 | Batch_idx: 150 |  Loss: (0.6215) | Acc: (78.45%) (15162/19328)\n",
      "Epoch: 14 | Batch_idx: 160 |  Loss: (0.6227) | Acc: (78.41%) (16158/20608)\n",
      "Epoch: 14 | Batch_idx: 170 |  Loss: (0.6214) | Acc: (78.46%) (17173/21888)\n",
      "Epoch: 14 | Batch_idx: 180 |  Loss: (0.6188) | Acc: (78.57%) (18203/23168)\n",
      "Epoch: 14 | Batch_idx: 190 |  Loss: (0.6194) | Acc: (78.56%) (19206/24448)\n",
      "Epoch: 14 | Batch_idx: 200 |  Loss: (0.6182) | Acc: (78.57%) (20214/25728)\n",
      "Epoch: 14 | Batch_idx: 210 |  Loss: (0.6178) | Acc: (78.62%) (21234/27008)\n",
      "Epoch: 14 | Batch_idx: 220 |  Loss: (0.6210) | Acc: (78.46%) (22195/28288)\n",
      "Epoch: 14 | Batch_idx: 230 |  Loss: (0.6183) | Acc: (78.52%) (23218/29568)\n",
      "Epoch: 14 | Batch_idx: 240 |  Loss: (0.6197) | Acc: (78.47%) (24207/30848)\n",
      "Epoch: 14 | Batch_idx: 250 |  Loss: (0.6184) | Acc: (78.50%) (25222/32128)\n",
      "Epoch: 14 | Batch_idx: 260 |  Loss: (0.6185) | Acc: (78.49%) (26222/33408)\n",
      "Epoch: 14 | Batch_idx: 270 |  Loss: (0.6189) | Acc: (78.48%) (27224/34688)\n",
      "Epoch: 14 | Batch_idx: 280 |  Loss: (0.6198) | Acc: (78.43%) (28210/35968)\n",
      "Epoch: 14 | Batch_idx: 290 |  Loss: (0.6192) | Acc: (78.44%) (29219/37248)\n",
      "Epoch: 14 | Batch_idx: 300 |  Loss: (0.6177) | Acc: (78.48%) (30238/38528)\n",
      "Epoch: 14 | Batch_idx: 310 |  Loss: (0.6182) | Acc: (78.45%) (31228/39808)\n",
      "Epoch: 14 | Batch_idx: 320 |  Loss: (0.6183) | Acc: (78.44%) (32230/41088)\n",
      "Epoch: 14 | Batch_idx: 330 |  Loss: (0.6170) | Acc: (78.48%) (33251/42368)\n",
      "Epoch: 14 | Batch_idx: 340 |  Loss: (0.6158) | Acc: (78.51%) (34270/43648)\n",
      "Epoch: 14 | Batch_idx: 350 |  Loss: (0.6165) | Acc: (78.49%) (35264/44928)\n",
      "Epoch: 14 | Batch_idx: 360 |  Loss: (0.6145) | Acc: (78.58%) (36309/46208)\n",
      "Epoch: 14 | Batch_idx: 370 |  Loss: (0.6141) | Acc: (78.58%) (37317/47488)\n",
      "Epoch: 14 | Batch_idx: 380 |  Loss: (0.6131) | Acc: (78.62%) (38342/48768)\n",
      "Epoch: 14 | Batch_idx: 390 |  Loss: (0.6135) | Acc: (78.60%) (39298/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6613) | Acc: (76.92%) (7692/10000)\n",
      "Epoch: 15 | Batch_idx: 0 |  Loss: (0.5931) | Acc: (76.56%) (98/128)\n",
      "Epoch: 15 | Batch_idx: 10 |  Loss: (0.5951) | Acc: (78.20%) (1101/1408)\n",
      "Epoch: 15 | Batch_idx: 20 |  Loss: (0.5925) | Acc: (78.91%) (2121/2688)\n",
      "Epoch: 15 | Batch_idx: 30 |  Loss: (0.6033) | Acc: (78.81%) (3127/3968)\n",
      "Epoch: 15 | Batch_idx: 40 |  Loss: (0.6048) | Acc: (78.77%) (4134/5248)\n",
      "Epoch: 15 | Batch_idx: 50 |  Loss: (0.6013) | Acc: (78.80%) (5144/6528)\n",
      "Epoch: 15 | Batch_idx: 60 |  Loss: (0.6008) | Acc: (78.59%) (6136/7808)\n",
      "Epoch: 15 | Batch_idx: 70 |  Loss: (0.6019) | Acc: (78.50%) (7134/9088)\n",
      "Epoch: 15 | Batch_idx: 80 |  Loss: (0.5990) | Acc: (78.67%) (8157/10368)\n",
      "Epoch: 15 | Batch_idx: 90 |  Loss: (0.6023) | Acc: (78.61%) (9157/11648)\n",
      "Epoch: 15 | Batch_idx: 100 |  Loss: (0.6003) | Acc: (78.78%) (10185/12928)\n",
      "Epoch: 15 | Batch_idx: 110 |  Loss: (0.6083) | Acc: (78.44%) (11145/14208)\n",
      "Epoch: 15 | Batch_idx: 120 |  Loss: (0.6123) | Acc: (78.38%) (12139/15488)\n",
      "Epoch: 15 | Batch_idx: 130 |  Loss: (0.6091) | Acc: (78.52%) (13166/16768)\n",
      "Epoch: 15 | Batch_idx: 140 |  Loss: (0.6040) | Acc: (78.77%) (14216/18048)\n",
      "Epoch: 15 | Batch_idx: 150 |  Loss: (0.6040) | Acc: (78.85%) (15241/19328)\n",
      "Epoch: 15 | Batch_idx: 160 |  Loss: (0.6029) | Acc: (78.80%) (16240/20608)\n",
      "Epoch: 15 | Batch_idx: 170 |  Loss: (0.6061) | Acc: (78.66%) (17217/21888)\n",
      "Epoch: 15 | Batch_idx: 180 |  Loss: (0.6050) | Acc: (78.68%) (18228/23168)\n",
      "Epoch: 15 | Batch_idx: 190 |  Loss: (0.6044) | Acc: (78.71%) (19244/24448)\n",
      "Epoch: 15 | Batch_idx: 200 |  Loss: (0.6036) | Acc: (78.82%) (20278/25728)\n",
      "Epoch: 15 | Batch_idx: 210 |  Loss: (0.6035) | Acc: (78.84%) (21292/27008)\n",
      "Epoch: 15 | Batch_idx: 220 |  Loss: (0.6051) | Acc: (78.81%) (22295/28288)\n",
      "Epoch: 15 | Batch_idx: 230 |  Loss: (0.6052) | Acc: (78.83%) (23307/29568)\n",
      "Epoch: 15 | Batch_idx: 240 |  Loss: (0.6041) | Acc: (78.88%) (24333/30848)\n",
      "Epoch: 15 | Batch_idx: 250 |  Loss: (0.6019) | Acc: (78.94%) (25363/32128)\n",
      "Epoch: 15 | Batch_idx: 260 |  Loss: (0.6010) | Acc: (79.02%) (26399/33408)\n",
      "Epoch: 15 | Batch_idx: 270 |  Loss: (0.6020) | Acc: (78.99%) (27401/34688)\n",
      "Epoch: 15 | Batch_idx: 280 |  Loss: (0.6000) | Acc: (79.04%) (28430/35968)\n",
      "Epoch: 15 | Batch_idx: 290 |  Loss: (0.6000) | Acc: (79.08%) (29456/37248)\n",
      "Epoch: 15 | Batch_idx: 300 |  Loss: (0.5991) | Acc: (79.12%) (30483/38528)\n",
      "Epoch: 15 | Batch_idx: 310 |  Loss: (0.5980) | Acc: (79.15%) (31508/39808)\n",
      "Epoch: 15 | Batch_idx: 320 |  Loss: (0.5976) | Acc: (79.17%) (32531/41088)\n",
      "Epoch: 15 | Batch_idx: 330 |  Loss: (0.5969) | Acc: (79.18%) (33547/42368)\n",
      "Epoch: 15 | Batch_idx: 340 |  Loss: (0.5960) | Acc: (79.21%) (34572/43648)\n",
      "Epoch: 15 | Batch_idx: 350 |  Loss: (0.5960) | Acc: (79.20%) (35585/44928)\n",
      "Epoch: 15 | Batch_idx: 360 |  Loss: (0.5947) | Acc: (79.27%) (36630/46208)\n",
      "Epoch: 15 | Batch_idx: 370 |  Loss: (0.5949) | Acc: (79.27%) (37642/47488)\n",
      "Epoch: 15 | Batch_idx: 380 |  Loss: (0.5944) | Acc: (79.25%) (38650/48768)\n",
      "Epoch: 15 | Batch_idx: 390 |  Loss: (0.5937) | Acc: (79.27%) (39635/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6798) | Acc: (76.14%) (7614/10000)\n",
      "Epoch: 16 | Batch_idx: 0 |  Loss: (0.5027) | Acc: (82.81%) (106/128)\n",
      "Epoch: 16 | Batch_idx: 10 |  Loss: (0.5460) | Acc: (80.26%) (1130/1408)\n",
      "Epoch: 16 | Batch_idx: 20 |  Loss: (0.5456) | Acc: (80.10%) (2153/2688)\n",
      "Epoch: 16 | Batch_idx: 30 |  Loss: (0.5683) | Acc: (79.94%) (3172/3968)\n",
      "Epoch: 16 | Batch_idx: 40 |  Loss: (0.5679) | Acc: (79.84%) (4190/5248)\n",
      "Epoch: 16 | Batch_idx: 50 |  Loss: (0.5708) | Acc: (79.89%) (5215/6528)\n",
      "Epoch: 16 | Batch_idx: 60 |  Loss: (0.5714) | Acc: (79.93%) (6241/7808)\n",
      "Epoch: 16 | Batch_idx: 70 |  Loss: (0.5800) | Acc: (79.53%) (7228/9088)\n",
      "Epoch: 16 | Batch_idx: 80 |  Loss: (0.5793) | Acc: (79.52%) (8245/10368)\n",
      "Epoch: 16 | Batch_idx: 90 |  Loss: (0.5813) | Acc: (79.43%) (9252/11648)\n",
      "Epoch: 16 | Batch_idx: 100 |  Loss: (0.5811) | Acc: (79.55%) (10284/12928)\n",
      "Epoch: 16 | Batch_idx: 110 |  Loss: (0.5835) | Acc: (79.53%) (11299/14208)\n",
      "Epoch: 16 | Batch_idx: 120 |  Loss: (0.5832) | Acc: (79.55%) (12321/15488)\n",
      "Epoch: 16 | Batch_idx: 130 |  Loss: (0.5810) | Acc: (79.69%) (13362/16768)\n",
      "Epoch: 16 | Batch_idx: 140 |  Loss: (0.5784) | Acc: (79.79%) (14400/18048)\n",
      "Epoch: 16 | Batch_idx: 150 |  Loss: (0.5764) | Acc: (79.78%) (15419/19328)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Batch_idx: 160 |  Loss: (0.5752) | Acc: (79.84%) (16454/20608)\n",
      "Epoch: 16 | Batch_idx: 170 |  Loss: (0.5736) | Acc: (79.92%) (17493/21888)\n",
      "Epoch: 16 | Batch_idx: 180 |  Loss: (0.5728) | Acc: (79.94%) (18521/23168)\n",
      "Epoch: 16 | Batch_idx: 190 |  Loss: (0.5732) | Acc: (79.94%) (19544/24448)\n",
      "Epoch: 16 | Batch_idx: 200 |  Loss: (0.5735) | Acc: (79.93%) (20565/25728)\n",
      "Epoch: 16 | Batch_idx: 210 |  Loss: (0.5753) | Acc: (79.89%) (21577/27008)\n",
      "Epoch: 16 | Batch_idx: 220 |  Loss: (0.5756) | Acc: (79.93%) (22610/28288)\n",
      "Epoch: 16 | Batch_idx: 230 |  Loss: (0.5747) | Acc: (79.99%) (23652/29568)\n",
      "Epoch: 16 | Batch_idx: 240 |  Loss: (0.5749) | Acc: (80.01%) (24681/30848)\n",
      "Epoch: 16 | Batch_idx: 250 |  Loss: (0.5737) | Acc: (80.03%) (25711/32128)\n",
      "Epoch: 16 | Batch_idx: 260 |  Loss: (0.5723) | Acc: (80.09%) (26755/33408)\n",
      "Epoch: 16 | Batch_idx: 270 |  Loss: (0.5728) | Acc: (80.03%) (27761/34688)\n",
      "Epoch: 16 | Batch_idx: 280 |  Loss: (0.5728) | Acc: (80.10%) (28809/35968)\n",
      "Epoch: 16 | Batch_idx: 290 |  Loss: (0.5718) | Acc: (80.18%) (29864/37248)\n",
      "Epoch: 16 | Batch_idx: 300 |  Loss: (0.5717) | Acc: (80.18%) (30893/38528)\n",
      "Epoch: 16 | Batch_idx: 310 |  Loss: (0.5696) | Acc: (80.24%) (31940/39808)\n",
      "Epoch: 16 | Batch_idx: 320 |  Loss: (0.5700) | Acc: (80.21%) (32958/41088)\n",
      "Epoch: 16 | Batch_idx: 330 |  Loss: (0.5691) | Acc: (80.24%) (33996/42368)\n",
      "Epoch: 16 | Batch_idx: 340 |  Loss: (0.5690) | Acc: (80.27%) (35035/43648)\n",
      "Epoch: 16 | Batch_idx: 350 |  Loss: (0.5692) | Acc: (80.26%) (36059/44928)\n",
      "Epoch: 16 | Batch_idx: 360 |  Loss: (0.5688) | Acc: (80.27%) (37090/46208)\n",
      "Epoch: 16 | Batch_idx: 370 |  Loss: (0.5690) | Acc: (80.24%) (38104/47488)\n",
      "Epoch: 16 | Batch_idx: 380 |  Loss: (0.5691) | Acc: (80.25%) (39135/48768)\n",
      "Epoch: 16 | Batch_idx: 390 |  Loss: (0.5676) | Acc: (80.30%) (40148/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6404) | Acc: (78.55%) (7855/10000)\n",
      "Epoch: 17 | Batch_idx: 0 |  Loss: (0.4448) | Acc: (83.59%) (107/128)\n",
      "Epoch: 17 | Batch_idx: 10 |  Loss: (0.5292) | Acc: (81.39%) (1146/1408)\n",
      "Epoch: 17 | Batch_idx: 20 |  Loss: (0.5307) | Acc: (81.40%) (2188/2688)\n",
      "Epoch: 17 | Batch_idx: 30 |  Loss: (0.5419) | Acc: (80.92%) (3211/3968)\n",
      "Epoch: 17 | Batch_idx: 40 |  Loss: (0.5458) | Acc: (80.74%) (4237/5248)\n",
      "Epoch: 17 | Batch_idx: 50 |  Loss: (0.5497) | Acc: (80.58%) (5260/6528)\n",
      "Epoch: 17 | Batch_idx: 60 |  Loss: (0.5478) | Acc: (80.70%) (6301/7808)\n",
      "Epoch: 17 | Batch_idx: 70 |  Loss: (0.5495) | Acc: (80.69%) (7333/9088)\n",
      "Epoch: 17 | Batch_idx: 80 |  Loss: (0.5538) | Acc: (80.55%) (8351/10368)\n",
      "Epoch: 17 | Batch_idx: 90 |  Loss: (0.5557) | Acc: (80.53%) (9380/11648)\n",
      "Epoch: 17 | Batch_idx: 100 |  Loss: (0.5566) | Acc: (80.45%) (10400/12928)\n",
      "Epoch: 17 | Batch_idx: 110 |  Loss: (0.5550) | Acc: (80.53%) (11442/14208)\n",
      "Epoch: 17 | Batch_idx: 120 |  Loss: (0.5592) | Acc: (80.34%) (12443/15488)\n",
      "Epoch: 17 | Batch_idx: 130 |  Loss: (0.5598) | Acc: (80.43%) (13487/16768)\n",
      "Epoch: 17 | Batch_idx: 140 |  Loss: (0.5607) | Acc: (80.44%) (14517/18048)\n",
      "Epoch: 17 | Batch_idx: 150 |  Loss: (0.5611) | Acc: (80.41%) (15542/19328)\n",
      "Epoch: 17 | Batch_idx: 160 |  Loss: (0.5606) | Acc: (80.38%) (16564/20608)\n",
      "Epoch: 17 | Batch_idx: 170 |  Loss: (0.5586) | Acc: (80.49%) (17617/21888)\n",
      "Epoch: 17 | Batch_idx: 180 |  Loss: (0.5594) | Acc: (80.57%) (18667/23168)\n",
      "Epoch: 17 | Batch_idx: 190 |  Loss: (0.5588) | Acc: (80.54%) (19691/24448)\n",
      "Epoch: 17 | Batch_idx: 200 |  Loss: (0.5574) | Acc: (80.63%) (20744/25728)\n",
      "Epoch: 17 | Batch_idx: 210 |  Loss: (0.5557) | Acc: (80.66%) (21786/27008)\n",
      "Epoch: 17 | Batch_idx: 220 |  Loss: (0.5546) | Acc: (80.71%) (22831/28288)\n",
      "Epoch: 17 | Batch_idx: 230 |  Loss: (0.5535) | Acc: (80.78%) (23886/29568)\n",
      "Epoch: 17 | Batch_idx: 240 |  Loss: (0.5539) | Acc: (80.77%) (24917/30848)\n",
      "Epoch: 17 | Batch_idx: 250 |  Loss: (0.5532) | Acc: (80.80%) (25958/32128)\n",
      "Epoch: 17 | Batch_idx: 260 |  Loss: (0.5530) | Acc: (80.81%) (26996/33408)\n",
      "Epoch: 17 | Batch_idx: 270 |  Loss: (0.5539) | Acc: (80.79%) (28025/34688)\n",
      "Epoch: 17 | Batch_idx: 280 |  Loss: (0.5532) | Acc: (80.81%) (29067/35968)\n",
      "Epoch: 17 | Batch_idx: 290 |  Loss: (0.5532) | Acc: (80.81%) (30101/37248)\n",
      "Epoch: 17 | Batch_idx: 300 |  Loss: (0.5528) | Acc: (80.81%) (31133/38528)\n",
      "Epoch: 17 | Batch_idx: 310 |  Loss: (0.5537) | Acc: (80.78%) (32155/39808)\n",
      "Epoch: 17 | Batch_idx: 320 |  Loss: (0.5534) | Acc: (80.78%) (33191/41088)\n",
      "Epoch: 17 | Batch_idx: 330 |  Loss: (0.5533) | Acc: (80.76%) (34218/42368)\n",
      "Epoch: 17 | Batch_idx: 340 |  Loss: (0.5545) | Acc: (80.74%) (35243/43648)\n",
      "Epoch: 17 | Batch_idx: 350 |  Loss: (0.5535) | Acc: (80.78%) (36293/44928)\n",
      "Epoch: 17 | Batch_idx: 360 |  Loss: (0.5543) | Acc: (80.75%) (37313/46208)\n",
      "Epoch: 17 | Batch_idx: 370 |  Loss: (0.5536) | Acc: (80.76%) (38350/47488)\n",
      "Epoch: 17 | Batch_idx: 380 |  Loss: (0.5537) | Acc: (80.76%) (39385/48768)\n",
      "Epoch: 17 | Batch_idx: 390 |  Loss: (0.5540) | Acc: (80.74%) (40369/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6115) | Acc: (78.71%) (7871/10000)\n",
      "Epoch: 18 | Batch_idx: 0 |  Loss: (0.6436) | Acc: (80.47%) (103/128)\n",
      "Epoch: 18 | Batch_idx: 10 |  Loss: (0.5687) | Acc: (80.47%) (1133/1408)\n",
      "Epoch: 18 | Batch_idx: 20 |  Loss: (0.5503) | Acc: (80.58%) (2166/2688)\n",
      "Epoch: 18 | Batch_idx: 30 |  Loss: (0.5466) | Acc: (80.90%) (3210/3968)\n",
      "Epoch: 18 | Batch_idx: 40 |  Loss: (0.5383) | Acc: (81.17%) (4260/5248)\n",
      "Epoch: 18 | Batch_idx: 50 |  Loss: (0.5459) | Acc: (80.76%) (5272/6528)\n",
      "Epoch: 18 | Batch_idx: 60 |  Loss: (0.5451) | Acc: (80.84%) (6312/7808)\n",
      "Epoch: 18 | Batch_idx: 70 |  Loss: (0.5503) | Acc: (80.70%) (7334/9088)\n",
      "Epoch: 18 | Batch_idx: 80 |  Loss: (0.5500) | Acc: (80.88%) (8386/10368)\n",
      "Epoch: 18 | Batch_idx: 90 |  Loss: (0.5418) | Acc: (81.28%) (9467/11648)\n",
      "Epoch: 18 | Batch_idx: 100 |  Loss: (0.5360) | Acc: (81.65%) (10556/12928)\n",
      "Epoch: 18 | Batch_idx: 110 |  Loss: (0.5377) | Acc: (81.53%) (11584/14208)\n",
      "Epoch: 18 | Batch_idx: 120 |  Loss: (0.5319) | Acc: (81.67%) (12649/15488)\n",
      "Epoch: 18 | Batch_idx: 130 |  Loss: (0.5325) | Acc: (81.72%) (13702/16768)\n",
      "Epoch: 18 | Batch_idx: 140 |  Loss: (0.5278) | Acc: (81.80%) (14763/18048)\n",
      "Epoch: 18 | Batch_idx: 150 |  Loss: (0.5304) | Acc: (81.71%) (15793/19328)\n",
      "Epoch: 18 | Batch_idx: 160 |  Loss: (0.5309) | Acc: (81.65%) (16826/20608)\n",
      "Epoch: 18 | Batch_idx: 170 |  Loss: (0.5306) | Acc: (81.64%) (17870/21888)\n",
      "Epoch: 18 | Batch_idx: 180 |  Loss: (0.5298) | Acc: (81.66%) (18919/23168)\n",
      "Epoch: 18 | Batch_idx: 190 |  Loss: (0.5298) | Acc: (81.63%) (19957/24448)\n",
      "Epoch: 18 | Batch_idx: 200 |  Loss: (0.5301) | Acc: (81.59%) (20992/25728)\n",
      "Epoch: 18 | Batch_idx: 210 |  Loss: (0.5307) | Acc: (81.52%) (22016/27008)\n",
      "Epoch: 18 | Batch_idx: 220 |  Loss: (0.5324) | Acc: (81.49%) (23053/28288)\n",
      "Epoch: 18 | Batch_idx: 230 |  Loss: (0.5308) | Acc: (81.54%) (24111/29568)\n",
      "Epoch: 18 | Batch_idx: 240 |  Loss: (0.5326) | Acc: (81.47%) (25131/30848)\n",
      "Epoch: 18 | Batch_idx: 250 |  Loss: (0.5331) | Acc: (81.47%) (26176/32128)\n",
      "Epoch: 18 | Batch_idx: 260 |  Loss: (0.5329) | Acc: (81.48%) (27221/33408)\n",
      "Epoch: 18 | Batch_idx: 270 |  Loss: (0.5334) | Acc: (81.47%) (28262/34688)\n",
      "Epoch: 18 | Batch_idx: 280 |  Loss: (0.5325) | Acc: (81.49%) (29311/35968)\n",
      "Epoch: 18 | Batch_idx: 290 |  Loss: (0.5319) | Acc: (81.52%) (30364/37248)\n",
      "Epoch: 18 | Batch_idx: 300 |  Loss: (0.5313) | Acc: (81.55%) (31418/38528)\n",
      "Epoch: 18 | Batch_idx: 310 |  Loss: (0.5295) | Acc: (81.62%) (32492/39808)\n",
      "Epoch: 18 | Batch_idx: 320 |  Loss: (0.5304) | Acc: (81.62%) (33537/41088)\n",
      "Epoch: 18 | Batch_idx: 330 |  Loss: (0.5299) | Acc: (81.64%) (34589/42368)\n",
      "Epoch: 18 | Batch_idx: 340 |  Loss: (0.5304) | Acc: (81.65%) (35637/43648)\n",
      "Epoch: 18 | Batch_idx: 350 |  Loss: (0.5314) | Acc: (81.62%) (36671/44928)\n",
      "Epoch: 18 | Batch_idx: 360 |  Loss: (0.5318) | Acc: (81.58%) (37697/46208)\n",
      "Epoch: 18 | Batch_idx: 370 |  Loss: (0.5313) | Acc: (81.60%) (38748/47488)\n",
      "Epoch: 18 | Batch_idx: 380 |  Loss: (0.5306) | Acc: (81.57%) (39781/48768)\n",
      "Epoch: 18 | Batch_idx: 390 |  Loss: (0.5316) | Acc: (81.54%) (40768/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6325) | Acc: (78.48%) (7848/10000)\n",
      "Epoch: 19 | Batch_idx: 0 |  Loss: (0.4442) | Acc: (83.59%) (107/128)\n",
      "Epoch: 19 | Batch_idx: 10 |  Loss: (0.5058) | Acc: (81.96%) (1154/1408)\n",
      "Epoch: 19 | Batch_idx: 20 |  Loss: (0.5153) | Acc: (81.99%) (2204/2688)\n",
      "Epoch: 19 | Batch_idx: 30 |  Loss: (0.5127) | Acc: (82.13%) (3259/3968)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Batch_idx: 40 |  Loss: (0.5123) | Acc: (82.13%) (4310/5248)\n",
      "Epoch: 19 | Batch_idx: 50 |  Loss: (0.5080) | Acc: (82.11%) (5360/6528)\n",
      "Epoch: 19 | Batch_idx: 60 |  Loss: (0.5039) | Acc: (82.10%) (6410/7808)\n",
      "Epoch: 19 | Batch_idx: 70 |  Loss: (0.5017) | Acc: (82.43%) (7491/9088)\n",
      "Epoch: 19 | Batch_idx: 80 |  Loss: (0.5034) | Acc: (82.50%) (8554/10368)\n",
      "Epoch: 19 | Batch_idx: 90 |  Loss: (0.5041) | Acc: (82.49%) (9609/11648)\n",
      "Epoch: 19 | Batch_idx: 100 |  Loss: (0.5060) | Acc: (82.36%) (10648/12928)\n",
      "Epoch: 19 | Batch_idx: 110 |  Loss: (0.5093) | Acc: (82.21%) (11680/14208)\n",
      "Epoch: 19 | Batch_idx: 120 |  Loss: (0.5115) | Acc: (82.22%) (12735/15488)\n",
      "Epoch: 19 | Batch_idx: 130 |  Loss: (0.5109) | Acc: (82.27%) (13795/16768)\n",
      "Epoch: 19 | Batch_idx: 140 |  Loss: (0.5096) | Acc: (82.36%) (14865/18048)\n",
      "Epoch: 19 | Batch_idx: 150 |  Loss: (0.5128) | Acc: (82.23%) (15893/19328)\n",
      "Epoch: 19 | Batch_idx: 160 |  Loss: (0.5131) | Acc: (82.21%) (16941/20608)\n",
      "Epoch: 19 | Batch_idx: 170 |  Loss: (0.5144) | Acc: (82.11%) (17972/21888)\n",
      "Epoch: 19 | Batch_idx: 180 |  Loss: (0.5130) | Acc: (82.16%) (19035/23168)\n",
      "Epoch: 19 | Batch_idx: 190 |  Loss: (0.5120) | Acc: (82.19%) (20093/24448)\n",
      "Epoch: 19 | Batch_idx: 200 |  Loss: (0.5134) | Acc: (82.12%) (21129/25728)\n",
      "Epoch: 19 | Batch_idx: 210 |  Loss: (0.5130) | Acc: (82.12%) (22179/27008)\n",
      "Epoch: 19 | Batch_idx: 220 |  Loss: (0.5128) | Acc: (82.15%) (23240/28288)\n",
      "Epoch: 19 | Batch_idx: 230 |  Loss: (0.5135) | Acc: (82.15%) (24291/29568)\n",
      "Epoch: 19 | Batch_idx: 240 |  Loss: (0.5137) | Acc: (82.15%) (25342/30848)\n",
      "Epoch: 19 | Batch_idx: 250 |  Loss: (0.5133) | Acc: (82.19%) (26405/32128)\n",
      "Epoch: 19 | Batch_idx: 260 |  Loss: (0.5143) | Acc: (82.15%) (27445/33408)\n",
      "Epoch: 19 | Batch_idx: 270 |  Loss: (0.5142) | Acc: (82.16%) (28499/34688)\n",
      "Epoch: 19 | Batch_idx: 280 |  Loss: (0.5127) | Acc: (82.23%) (29577/35968)\n",
      "Epoch: 19 | Batch_idx: 290 |  Loss: (0.5143) | Acc: (82.13%) (30593/37248)\n",
      "Epoch: 19 | Batch_idx: 300 |  Loss: (0.5145) | Acc: (82.14%) (31648/38528)\n",
      "Epoch: 19 | Batch_idx: 310 |  Loss: (0.5145) | Acc: (82.14%) (32698/39808)\n",
      "Epoch: 19 | Batch_idx: 320 |  Loss: (0.5154) | Acc: (82.09%) (33729/41088)\n",
      "Epoch: 19 | Batch_idx: 330 |  Loss: (0.5168) | Acc: (82.03%) (34755/42368)\n",
      "Epoch: 19 | Batch_idx: 340 |  Loss: (0.5175) | Acc: (81.98%) (35781/43648)\n",
      "Epoch: 19 | Batch_idx: 350 |  Loss: (0.5178) | Acc: (81.95%) (36818/44928)\n",
      "Epoch: 19 | Batch_idx: 360 |  Loss: (0.5185) | Acc: (81.93%) (37858/46208)\n",
      "Epoch: 19 | Batch_idx: 370 |  Loss: (0.5180) | Acc: (81.95%) (38915/47488)\n",
      "Epoch: 19 | Batch_idx: 380 |  Loss: (0.5187) | Acc: (81.90%) (39943/48768)\n",
      "Epoch: 19 | Batch_idx: 390 |  Loss: (0.5186) | Acc: (81.91%) (40955/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5914) | Acc: (79.35%) (7935/10000)\n",
      "Epoch: 20 | Batch_idx: 0 |  Loss: (0.6030) | Acc: (85.16%) (109/128)\n",
      "Epoch: 20 | Batch_idx: 10 |  Loss: (0.5295) | Acc: (81.89%) (1153/1408)\n",
      "Epoch: 20 | Batch_idx: 20 |  Loss: (0.5100) | Acc: (82.48%) (2217/2688)\n",
      "Epoch: 20 | Batch_idx: 30 |  Loss: (0.5178) | Acc: (81.93%) (3251/3968)\n",
      "Epoch: 20 | Batch_idx: 40 |  Loss: (0.5179) | Acc: (81.82%) (4294/5248)\n",
      "Epoch: 20 | Batch_idx: 50 |  Loss: (0.5106) | Acc: (82.35%) (5376/6528)\n",
      "Epoch: 20 | Batch_idx: 60 |  Loss: (0.5066) | Acc: (82.56%) (6446/7808)\n",
      "Epoch: 20 | Batch_idx: 70 |  Loss: (0.5092) | Acc: (82.53%) (7500/9088)\n",
      "Epoch: 20 | Batch_idx: 80 |  Loss: (0.5053) | Acc: (82.62%) (8566/10368)\n",
      "Epoch: 20 | Batch_idx: 90 |  Loss: (0.5069) | Acc: (82.59%) (9620/11648)\n",
      "Epoch: 20 | Batch_idx: 100 |  Loss: (0.5022) | Acc: (82.67%) (10687/12928)\n",
      "Epoch: 20 | Batch_idx: 110 |  Loss: (0.5044) | Acc: (82.51%) (11723/14208)\n",
      "Epoch: 20 | Batch_idx: 120 |  Loss: (0.5034) | Acc: (82.63%) (12798/15488)\n",
      "Epoch: 20 | Batch_idx: 130 |  Loss: (0.5016) | Acc: (82.61%) (13852/16768)\n",
      "Epoch: 20 | Batch_idx: 140 |  Loss: (0.5016) | Acc: (82.67%) (14921/18048)\n",
      "Epoch: 20 | Batch_idx: 150 |  Loss: (0.5012) | Acc: (82.64%) (15973/19328)\n",
      "Epoch: 20 | Batch_idx: 160 |  Loss: (0.5005) | Acc: (82.71%) (17045/20608)\n",
      "Epoch: 20 | Batch_idx: 170 |  Loss: (0.4977) | Acc: (82.84%) (18131/21888)\n",
      "Epoch: 20 | Batch_idx: 180 |  Loss: (0.4965) | Acc: (82.83%) (19190/23168)\n",
      "Epoch: 20 | Batch_idx: 190 |  Loss: (0.4992) | Acc: (82.74%) (20228/24448)\n",
      "Epoch: 20 | Batch_idx: 200 |  Loss: (0.5000) | Acc: (82.66%) (21268/25728)\n",
      "Epoch: 20 | Batch_idx: 210 |  Loss: (0.4996) | Acc: (82.66%) (22324/27008)\n",
      "Epoch: 20 | Batch_idx: 220 |  Loss: (0.4995) | Acc: (82.71%) (23396/28288)\n",
      "Epoch: 20 | Batch_idx: 230 |  Loss: (0.4995) | Acc: (82.72%) (24459/29568)\n",
      "Epoch: 20 | Batch_idx: 240 |  Loss: (0.4988) | Acc: (82.73%) (25522/30848)\n",
      "Epoch: 20 | Batch_idx: 250 |  Loss: (0.4977) | Acc: (82.72%) (26576/32128)\n",
      "Epoch: 20 | Batch_idx: 260 |  Loss: (0.4977) | Acc: (82.72%) (27634/33408)\n",
      "Epoch: 20 | Batch_idx: 270 |  Loss: (0.4979) | Acc: (82.69%) (28683/34688)\n",
      "Epoch: 20 | Batch_idx: 280 |  Loss: (0.4982) | Acc: (82.67%) (29735/35968)\n",
      "Epoch: 20 | Batch_idx: 290 |  Loss: (0.4981) | Acc: (82.64%) (30782/37248)\n",
      "Epoch: 20 | Batch_idx: 300 |  Loss: (0.4992) | Acc: (82.63%) (31835/38528)\n",
      "Epoch: 20 | Batch_idx: 310 |  Loss: (0.4983) | Acc: (82.66%) (32906/39808)\n",
      "Epoch: 20 | Batch_idx: 320 |  Loss: (0.4993) | Acc: (82.61%) (33944/41088)\n",
      "Epoch: 20 | Batch_idx: 330 |  Loss: (0.4996) | Acc: (82.63%) (35010/42368)\n",
      "Epoch: 20 | Batch_idx: 340 |  Loss: (0.5001) | Acc: (82.65%) (36073/43648)\n",
      "Epoch: 20 | Batch_idx: 350 |  Loss: (0.4990) | Acc: (82.67%) (37142/44928)\n",
      "Epoch: 20 | Batch_idx: 360 |  Loss: (0.4997) | Acc: (82.63%) (38182/46208)\n",
      "Epoch: 20 | Batch_idx: 370 |  Loss: (0.4987) | Acc: (82.64%) (39242/47488)\n",
      "Epoch: 20 | Batch_idx: 380 |  Loss: (0.4992) | Acc: (82.60%) (40284/48768)\n",
      "Epoch: 20 | Batch_idx: 390 |  Loss: (0.4987) | Acc: (82.62%) (41310/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5648) | Acc: (80.39%) (8039/10000)\n",
      "Epoch: 21 | Batch_idx: 0 |  Loss: (0.5915) | Acc: (76.56%) (98/128)\n",
      "Epoch: 21 | Batch_idx: 10 |  Loss: (0.5039) | Acc: (82.74%) (1165/1408)\n",
      "Epoch: 21 | Batch_idx: 20 |  Loss: (0.4799) | Acc: (83.30%) (2239/2688)\n",
      "Epoch: 21 | Batch_idx: 30 |  Loss: (0.4879) | Acc: (82.79%) (3285/3968)\n",
      "Epoch: 21 | Batch_idx: 40 |  Loss: (0.4885) | Acc: (82.81%) (4346/5248)\n",
      "Epoch: 21 | Batch_idx: 50 |  Loss: (0.4849) | Acc: (82.90%) (5412/6528)\n",
      "Epoch: 21 | Batch_idx: 60 |  Loss: (0.4858) | Acc: (82.56%) (6446/7808)\n",
      "Epoch: 21 | Batch_idx: 70 |  Loss: (0.4903) | Acc: (82.47%) (7495/9088)\n",
      "Epoch: 21 | Batch_idx: 80 |  Loss: (0.4836) | Acc: (82.61%) (8565/10368)\n",
      "Epoch: 21 | Batch_idx: 90 |  Loss: (0.4811) | Acc: (82.83%) (9648/11648)\n",
      "Epoch: 21 | Batch_idx: 100 |  Loss: (0.4836) | Acc: (82.70%) (10692/12928)\n",
      "Epoch: 21 | Batch_idx: 110 |  Loss: (0.4876) | Acc: (82.67%) (11746/14208)\n",
      "Epoch: 21 | Batch_idx: 120 |  Loss: (0.4879) | Acc: (82.72%) (12811/15488)\n",
      "Epoch: 21 | Batch_idx: 130 |  Loss: (0.4879) | Acc: (82.68%) (13864/16768)\n",
      "Epoch: 21 | Batch_idx: 140 |  Loss: (0.4871) | Acc: (82.78%) (14940/18048)\n",
      "Epoch: 21 | Batch_idx: 150 |  Loss: (0.4875) | Acc: (82.73%) (15991/19328)\n",
      "Epoch: 21 | Batch_idx: 160 |  Loss: (0.4867) | Acc: (82.79%) (17061/20608)\n",
      "Epoch: 21 | Batch_idx: 170 |  Loss: (0.4865) | Acc: (82.83%) (18129/21888)\n",
      "Epoch: 21 | Batch_idx: 180 |  Loss: (0.4843) | Acc: (82.94%) (19215/23168)\n",
      "Epoch: 21 | Batch_idx: 190 |  Loss: (0.4837) | Acc: (82.91%) (20270/24448)\n",
      "Epoch: 21 | Batch_idx: 200 |  Loss: (0.4858) | Acc: (82.86%) (21318/25728)\n",
      "Epoch: 21 | Batch_idx: 210 |  Loss: (0.4829) | Acc: (82.95%) (22404/27008)\n",
      "Epoch: 21 | Batch_idx: 220 |  Loss: (0.4820) | Acc: (82.98%) (23472/28288)\n",
      "Epoch: 21 | Batch_idx: 230 |  Loss: (0.4818) | Acc: (82.97%) (24534/29568)\n",
      "Epoch: 21 | Batch_idx: 240 |  Loss: (0.4822) | Acc: (82.94%) (25586/30848)\n",
      "Epoch: 21 | Batch_idx: 250 |  Loss: (0.4815) | Acc: (82.97%) (26656/32128)\n",
      "Epoch: 21 | Batch_idx: 260 |  Loss: (0.4832) | Acc: (82.94%) (27709/33408)\n",
      "Epoch: 21 | Batch_idx: 270 |  Loss: (0.4845) | Acc: (82.92%) (28762/34688)\n",
      "Epoch: 21 | Batch_idx: 280 |  Loss: (0.4832) | Acc: (82.95%) (29834/35968)\n",
      "Epoch: 21 | Batch_idx: 290 |  Loss: (0.4833) | Acc: (82.95%) (30896/37248)\n",
      "Epoch: 21 | Batch_idx: 300 |  Loss: (0.4838) | Acc: (82.96%) (31964/38528)\n",
      "Epoch: 21 | Batch_idx: 310 |  Loss: (0.4843) | Acc: (82.98%) (33031/39808)\n",
      "Epoch: 21 | Batch_idx: 320 |  Loss: (0.4845) | Acc: (82.99%) (34099/41088)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Batch_idx: 330 |  Loss: (0.4839) | Acc: (83.02%) (35172/42368)\n",
      "Epoch: 21 | Batch_idx: 340 |  Loss: (0.4842) | Acc: (83.03%) (36240/43648)\n",
      "Epoch: 21 | Batch_idx: 350 |  Loss: (0.4844) | Acc: (82.99%) (37284/44928)\n",
      "Epoch: 21 | Batch_idx: 360 |  Loss: (0.4855) | Acc: (82.95%) (38330/46208)\n",
      "Epoch: 21 | Batch_idx: 370 |  Loss: (0.4862) | Acc: (82.93%) (39382/47488)\n",
      "Epoch: 21 | Batch_idx: 380 |  Loss: (0.4863) | Acc: (82.96%) (40456/48768)\n",
      "Epoch: 21 | Batch_idx: 390 |  Loss: (0.4858) | Acc: (82.95%) (41476/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6274) | Acc: (78.71%) (7871/10000)\n",
      "Epoch: 22 | Batch_idx: 0 |  Loss: (0.3872) | Acc: (86.72%) (111/128)\n",
      "Epoch: 22 | Batch_idx: 10 |  Loss: (0.4340) | Acc: (85.09%) (1198/1408)\n",
      "Epoch: 22 | Batch_idx: 20 |  Loss: (0.4575) | Acc: (84.34%) (2267/2688)\n",
      "Epoch: 22 | Batch_idx: 30 |  Loss: (0.4663) | Acc: (84.07%) (3336/3968)\n",
      "Epoch: 22 | Batch_idx: 40 |  Loss: (0.4708) | Acc: (83.73%) (4394/5248)\n",
      "Epoch: 22 | Batch_idx: 50 |  Loss: (0.4630) | Acc: (84.01%) (5484/6528)\n",
      "Epoch: 22 | Batch_idx: 60 |  Loss: (0.4656) | Acc: (84.12%) (6568/7808)\n",
      "Epoch: 22 | Batch_idx: 70 |  Loss: (0.4641) | Acc: (84.13%) (7646/9088)\n",
      "Epoch: 22 | Batch_idx: 80 |  Loss: (0.4656) | Acc: (84.00%) (8709/10368)\n",
      "Epoch: 22 | Batch_idx: 90 |  Loss: (0.4662) | Acc: (84.01%) (9785/11648)\n",
      "Epoch: 22 | Batch_idx: 100 |  Loss: (0.4655) | Acc: (84.05%) (10866/12928)\n",
      "Epoch: 22 | Batch_idx: 110 |  Loss: (0.4671) | Acc: (83.90%) (11921/14208)\n",
      "Epoch: 22 | Batch_idx: 120 |  Loss: (0.4651) | Acc: (84.04%) (13016/15488)\n",
      "Epoch: 22 | Batch_idx: 130 |  Loss: (0.4659) | Acc: (83.95%) (14076/16768)\n",
      "Epoch: 22 | Batch_idx: 140 |  Loss: (0.4691) | Acc: (83.85%) (15133/18048)\n",
      "Epoch: 22 | Batch_idx: 150 |  Loss: (0.4678) | Acc: (83.87%) (16211/19328)\n",
      "Epoch: 22 | Batch_idx: 160 |  Loss: (0.4689) | Acc: (83.84%) (17278/20608)\n",
      "Epoch: 22 | Batch_idx: 170 |  Loss: (0.4687) | Acc: (83.82%) (18346/21888)\n",
      "Epoch: 22 | Batch_idx: 180 |  Loss: (0.4690) | Acc: (83.76%) (19406/23168)\n",
      "Epoch: 22 | Batch_idx: 190 |  Loss: (0.4685) | Acc: (83.77%) (20481/24448)\n",
      "Epoch: 22 | Batch_idx: 200 |  Loss: (0.4692) | Acc: (83.75%) (21547/25728)\n",
      "Epoch: 22 | Batch_idx: 210 |  Loss: (0.4706) | Acc: (83.65%) (22591/27008)\n",
      "Epoch: 22 | Batch_idx: 220 |  Loss: (0.4695) | Acc: (83.70%) (23677/28288)\n",
      "Epoch: 22 | Batch_idx: 230 |  Loss: (0.4702) | Acc: (83.73%) (24757/29568)\n",
      "Epoch: 22 | Batch_idx: 240 |  Loss: (0.4706) | Acc: (83.75%) (25836/30848)\n",
      "Epoch: 22 | Batch_idx: 250 |  Loss: (0.4699) | Acc: (83.79%) (26921/32128)\n",
      "Epoch: 22 | Batch_idx: 260 |  Loss: (0.4702) | Acc: (83.76%) (27982/33408)\n",
      "Epoch: 22 | Batch_idx: 270 |  Loss: (0.4698) | Acc: (83.73%) (29045/34688)\n",
      "Epoch: 22 | Batch_idx: 280 |  Loss: (0.4708) | Acc: (83.70%) (30107/35968)\n",
      "Epoch: 22 | Batch_idx: 290 |  Loss: (0.4716) | Acc: (83.69%) (31171/37248)\n",
      "Epoch: 22 | Batch_idx: 300 |  Loss: (0.4728) | Acc: (83.65%) (32227/38528)\n",
      "Epoch: 22 | Batch_idx: 310 |  Loss: (0.4716) | Acc: (83.69%) (33316/39808)\n",
      "Epoch: 22 | Batch_idx: 320 |  Loss: (0.4726) | Acc: (83.66%) (34375/41088)\n",
      "Epoch: 22 | Batch_idx: 330 |  Loss: (0.4732) | Acc: (83.65%) (35440/42368)\n",
      "Epoch: 22 | Batch_idx: 340 |  Loss: (0.4733) | Acc: (83.65%) (36511/43648)\n",
      "Epoch: 22 | Batch_idx: 350 |  Loss: (0.4721) | Acc: (83.68%) (37595/44928)\n",
      "Epoch: 22 | Batch_idx: 360 |  Loss: (0.4719) | Acc: (83.70%) (38675/46208)\n",
      "Epoch: 22 | Batch_idx: 370 |  Loss: (0.4717) | Acc: (83.69%) (39745/47488)\n",
      "Epoch: 22 | Batch_idx: 380 |  Loss: (0.4715) | Acc: (83.72%) (40828/48768)\n",
      "Epoch: 22 | Batch_idx: 390 |  Loss: (0.4724) | Acc: (83.68%) (41840/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5903) | Acc: (80.60%) (8060/10000)\n",
      "Epoch: 23 | Batch_idx: 0 |  Loss: (0.4267) | Acc: (83.59%) (107/128)\n",
      "Epoch: 23 | Batch_idx: 10 |  Loss: (0.4474) | Acc: (84.66%) (1192/1408)\n",
      "Epoch: 23 | Batch_idx: 20 |  Loss: (0.4349) | Acc: (85.08%) (2287/2688)\n",
      "Epoch: 23 | Batch_idx: 30 |  Loss: (0.4408) | Acc: (84.73%) (3362/3968)\n",
      "Epoch: 23 | Batch_idx: 40 |  Loss: (0.4438) | Acc: (84.76%) (4448/5248)\n",
      "Epoch: 23 | Batch_idx: 50 |  Loss: (0.4439) | Acc: (84.79%) (5535/6528)\n",
      "Epoch: 23 | Batch_idx: 60 |  Loss: (0.4522) | Acc: (84.59%) (6605/7808)\n",
      "Epoch: 23 | Batch_idx: 70 |  Loss: (0.4494) | Acc: (84.69%) (7697/9088)\n",
      "Epoch: 23 | Batch_idx: 80 |  Loss: (0.4544) | Acc: (84.50%) (8761/10368)\n",
      "Epoch: 23 | Batch_idx: 90 |  Loss: (0.4537) | Acc: (84.58%) (9852/11648)\n",
      "Epoch: 23 | Batch_idx: 100 |  Loss: (0.4579) | Acc: (84.45%) (10918/12928)\n",
      "Epoch: 23 | Batch_idx: 110 |  Loss: (0.4549) | Acc: (84.59%) (12019/14208)\n",
      "Epoch: 23 | Batch_idx: 120 |  Loss: (0.4580) | Acc: (84.46%) (13081/15488)\n",
      "Epoch: 23 | Batch_idx: 130 |  Loss: (0.4599) | Acc: (84.45%) (14160/16768)\n",
      "Epoch: 23 | Batch_idx: 140 |  Loss: (0.4617) | Acc: (84.34%) (15222/18048)\n",
      "Epoch: 23 | Batch_idx: 150 |  Loss: (0.4627) | Acc: (84.31%) (16296/19328)\n",
      "Epoch: 23 | Batch_idx: 160 |  Loss: (0.4615) | Acc: (84.36%) (17385/20608)\n",
      "Epoch: 23 | Batch_idx: 170 |  Loss: (0.4635) | Acc: (84.30%) (18451/21888)\n",
      "Epoch: 23 | Batch_idx: 180 |  Loss: (0.4627) | Acc: (84.33%) (19537/23168)\n",
      "Epoch: 23 | Batch_idx: 190 |  Loss: (0.4622) | Acc: (84.36%) (20625/24448)\n",
      "Epoch: 23 | Batch_idx: 200 |  Loss: (0.4633) | Acc: (84.29%) (21685/25728)\n",
      "Epoch: 23 | Batch_idx: 210 |  Loss: (0.4642) | Acc: (84.26%) (22758/27008)\n",
      "Epoch: 23 | Batch_idx: 220 |  Loss: (0.4624) | Acc: (84.33%) (23856/28288)\n",
      "Epoch: 23 | Batch_idx: 230 |  Loss: (0.4622) | Acc: (84.34%) (24937/29568)\n",
      "Epoch: 23 | Batch_idx: 240 |  Loss: (0.4621) | Acc: (84.33%) (26014/30848)\n",
      "Epoch: 23 | Batch_idx: 250 |  Loss: (0.4617) | Acc: (84.35%) (27101/32128)\n",
      "Epoch: 23 | Batch_idx: 260 |  Loss: (0.4620) | Acc: (84.30%) (28164/33408)\n",
      "Epoch: 23 | Batch_idx: 270 |  Loss: (0.4622) | Acc: (84.29%) (29239/34688)\n",
      "Epoch: 23 | Batch_idx: 280 |  Loss: (0.4628) | Acc: (84.25%) (30303/35968)\n",
      "Epoch: 23 | Batch_idx: 290 |  Loss: (0.4619) | Acc: (84.28%) (31391/37248)\n",
      "Epoch: 23 | Batch_idx: 300 |  Loss: (0.4628) | Acc: (84.20%) (32442/38528)\n",
      "Epoch: 23 | Batch_idx: 310 |  Loss: (0.4624) | Acc: (84.19%) (33515/39808)\n",
      "Epoch: 23 | Batch_idx: 320 |  Loss: (0.4629) | Acc: (84.14%) (34572/41088)\n",
      "Epoch: 23 | Batch_idx: 330 |  Loss: (0.4611) | Acc: (84.22%) (35683/42368)\n",
      "Epoch: 23 | Batch_idx: 340 |  Loss: (0.4605) | Acc: (84.22%) (36759/43648)\n",
      "Epoch: 23 | Batch_idx: 350 |  Loss: (0.4597) | Acc: (84.27%) (37859/44928)\n",
      "Epoch: 23 | Batch_idx: 360 |  Loss: (0.4597) | Acc: (84.26%) (38936/46208)\n",
      "Epoch: 23 | Batch_idx: 370 |  Loss: (0.4588) | Acc: (84.30%) (40032/47488)\n",
      "Epoch: 23 | Batch_idx: 380 |  Loss: (0.4581) | Acc: (84.32%) (41119/48768)\n",
      "Epoch: 23 | Batch_idx: 390 |  Loss: (0.4589) | Acc: (84.27%) (42133/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5762) | Acc: (80.57%) (8057/10000)\n",
      "Epoch: 24 | Batch_idx: 0 |  Loss: (0.4002) | Acc: (84.38%) (108/128)\n",
      "Epoch: 24 | Batch_idx: 10 |  Loss: (0.4398) | Acc: (85.23%) (1200/1408)\n",
      "Epoch: 24 | Batch_idx: 20 |  Loss: (0.4357) | Acc: (85.23%) (2291/2688)\n",
      "Epoch: 24 | Batch_idx: 30 |  Loss: (0.4390) | Acc: (84.80%) (3365/3968)\n",
      "Epoch: 24 | Batch_idx: 40 |  Loss: (0.4380) | Acc: (84.83%) (4452/5248)\n",
      "Epoch: 24 | Batch_idx: 50 |  Loss: (0.4447) | Acc: (84.70%) (5529/6528)\n",
      "Epoch: 24 | Batch_idx: 60 |  Loss: (0.4539) | Acc: (84.46%) (6595/7808)\n",
      "Epoch: 24 | Batch_idx: 70 |  Loss: (0.4556) | Acc: (84.54%) (7683/9088)\n",
      "Epoch: 24 | Batch_idx: 80 |  Loss: (0.4479) | Acc: (84.89%) (8801/10368)\n",
      "Epoch: 24 | Batch_idx: 90 |  Loss: (0.4468) | Acc: (84.88%) (9887/11648)\n",
      "Epoch: 24 | Batch_idx: 100 |  Loss: (0.4438) | Acc: (84.96%) (10984/12928)\n",
      "Epoch: 24 | Batch_idx: 110 |  Loss: (0.4473) | Acc: (84.87%) (12059/14208)\n",
      "Epoch: 24 | Batch_idx: 120 |  Loss: (0.4478) | Acc: (84.75%) (13126/15488)\n",
      "Epoch: 24 | Batch_idx: 130 |  Loss: (0.4454) | Acc: (84.83%) (14225/16768)\n",
      "Epoch: 24 | Batch_idx: 140 |  Loss: (0.4464) | Acc: (84.76%) (15297/18048)\n",
      "Epoch: 24 | Batch_idx: 150 |  Loss: (0.4453) | Acc: (84.79%) (16388/19328)\n",
      "Epoch: 24 | Batch_idx: 160 |  Loss: (0.4451) | Acc: (84.76%) (17467/20608)\n",
      "Epoch: 24 | Batch_idx: 170 |  Loss: (0.4464) | Acc: (84.67%) (18532/21888)\n",
      "Epoch: 24 | Batch_idx: 180 |  Loss: (0.4464) | Acc: (84.63%) (19607/23168)\n",
      "Epoch: 24 | Batch_idx: 190 |  Loss: (0.4445) | Acc: (84.67%) (20700/24448)\n",
      "Epoch: 24 | Batch_idx: 200 |  Loss: (0.4443) | Acc: (84.65%) (21780/25728)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Batch_idx: 210 |  Loss: (0.4459) | Acc: (84.55%) (22836/27008)\n",
      "Epoch: 24 | Batch_idx: 220 |  Loss: (0.4457) | Acc: (84.51%) (23905/28288)\n",
      "Epoch: 24 | Batch_idx: 230 |  Loss: (0.4460) | Acc: (84.47%) (24976/29568)\n",
      "Epoch: 24 | Batch_idx: 240 |  Loss: (0.4455) | Acc: (84.46%) (26054/30848)\n",
      "Epoch: 24 | Batch_idx: 250 |  Loss: (0.4453) | Acc: (84.49%) (27146/32128)\n",
      "Epoch: 24 | Batch_idx: 260 |  Loss: (0.4472) | Acc: (84.43%) (28207/33408)\n",
      "Epoch: 24 | Batch_idx: 270 |  Loss: (0.4470) | Acc: (84.42%) (29285/34688)\n",
      "Epoch: 24 | Batch_idx: 280 |  Loss: (0.4471) | Acc: (84.43%) (30369/35968)\n",
      "Epoch: 24 | Batch_idx: 290 |  Loss: (0.4468) | Acc: (84.48%) (31466/37248)\n",
      "Epoch: 24 | Batch_idx: 300 |  Loss: (0.4468) | Acc: (84.46%) (32539/38528)\n",
      "Epoch: 24 | Batch_idx: 310 |  Loss: (0.4467) | Acc: (84.44%) (33614/39808)\n",
      "Epoch: 24 | Batch_idx: 320 |  Loss: (0.4459) | Acc: (84.48%) (34711/41088)\n",
      "Epoch: 24 | Batch_idx: 330 |  Loss: (0.4460) | Acc: (84.45%) (35781/42368)\n",
      "Epoch: 24 | Batch_idx: 340 |  Loss: (0.4473) | Acc: (84.39%) (36836/43648)\n",
      "Epoch: 24 | Batch_idx: 350 |  Loss: (0.4487) | Acc: (84.36%) (37903/44928)\n",
      "Epoch: 24 | Batch_idx: 360 |  Loss: (0.4485) | Acc: (84.35%) (38977/46208)\n",
      "Epoch: 24 | Batch_idx: 370 |  Loss: (0.4491) | Acc: (84.34%) (40051/47488)\n",
      "Epoch: 24 | Batch_idx: 380 |  Loss: (0.4492) | Acc: (84.32%) (41121/48768)\n",
      "Epoch: 24 | Batch_idx: 390 |  Loss: (0.4487) | Acc: (84.37%) (42183/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6180) | Acc: (79.99%) (7999/10000)\n",
      "Epoch: 25 | Batch_idx: 0 |  Loss: (0.3857) | Acc: (84.38%) (108/128)\n",
      "Epoch: 25 | Batch_idx: 10 |  Loss: (0.4460) | Acc: (84.87%) (1195/1408)\n",
      "Epoch: 25 | Batch_idx: 20 |  Loss: (0.4380) | Acc: (85.04%) (2286/2688)\n",
      "Epoch: 25 | Batch_idx: 30 |  Loss: (0.4375) | Acc: (85.08%) (3376/3968)\n",
      "Epoch: 25 | Batch_idx: 40 |  Loss: (0.4445) | Acc: (84.68%) (4444/5248)\n",
      "Epoch: 25 | Batch_idx: 50 |  Loss: (0.4355) | Acc: (85.09%) (5555/6528)\n",
      "Epoch: 25 | Batch_idx: 60 |  Loss: (0.4380) | Acc: (84.89%) (6628/7808)\n",
      "Epoch: 25 | Batch_idx: 70 |  Loss: (0.4412) | Acc: (84.83%) (7709/9088)\n",
      "Epoch: 25 | Batch_idx: 80 |  Loss: (0.4384) | Acc: (84.96%) (8809/10368)\n",
      "Epoch: 25 | Batch_idx: 90 |  Loss: (0.4394) | Acc: (84.93%) (9893/11648)\n",
      "Epoch: 25 | Batch_idx: 100 |  Loss: (0.4402) | Acc: (84.88%) (10973/12928)\n",
      "Epoch: 25 | Batch_idx: 110 |  Loss: (0.4372) | Acc: (84.95%) (12070/14208)\n",
      "Epoch: 25 | Batch_idx: 120 |  Loss: (0.4391) | Acc: (84.80%) (13134/15488)\n",
      "Epoch: 25 | Batch_idx: 130 |  Loss: (0.4396) | Acc: (84.79%) (14218/16768)\n",
      "Epoch: 25 | Batch_idx: 140 |  Loss: (0.4374) | Acc: (84.87%) (15318/18048)\n",
      "Epoch: 25 | Batch_idx: 150 |  Loss: (0.4391) | Acc: (84.82%) (16394/19328)\n",
      "Epoch: 25 | Batch_idx: 160 |  Loss: (0.4394) | Acc: (84.85%) (17486/20608)\n",
      "Epoch: 25 | Batch_idx: 170 |  Loss: (0.4409) | Acc: (84.84%) (18570/21888)\n",
      "Epoch: 25 | Batch_idx: 180 |  Loss: (0.4410) | Acc: (84.80%) (19646/23168)\n",
      "Epoch: 25 | Batch_idx: 190 |  Loss: (0.4404) | Acc: (84.82%) (20737/24448)\n",
      "Epoch: 25 | Batch_idx: 200 |  Loss: (0.4378) | Acc: (84.91%) (21846/25728)\n",
      "Epoch: 25 | Batch_idx: 210 |  Loss: (0.4376) | Acc: (84.89%) (22926/27008)\n",
      "Epoch: 25 | Batch_idx: 220 |  Loss: (0.4354) | Acc: (84.99%) (24041/28288)\n",
      "Epoch: 25 | Batch_idx: 230 |  Loss: (0.4374) | Acc: (84.90%) (25102/29568)\n",
      "Epoch: 25 | Batch_idx: 240 |  Loss: (0.4389) | Acc: (84.88%) (26184/30848)\n",
      "Epoch: 25 | Batch_idx: 250 |  Loss: (0.4372) | Acc: (84.92%) (27284/32128)\n",
      "Epoch: 25 | Batch_idx: 260 |  Loss: (0.4364) | Acc: (84.97%) (28386/33408)\n",
      "Epoch: 25 | Batch_idx: 270 |  Loss: (0.4376) | Acc: (84.90%) (29449/34688)\n",
      "Epoch: 25 | Batch_idx: 280 |  Loss: (0.4379) | Acc: (84.84%) (30514/35968)\n",
      "Epoch: 25 | Batch_idx: 290 |  Loss: (0.4373) | Acc: (84.86%) (31610/37248)\n",
      "Epoch: 25 | Batch_idx: 300 |  Loss: (0.4367) | Acc: (84.89%) (32706/38528)\n",
      "Epoch: 25 | Batch_idx: 310 |  Loss: (0.4364) | Acc: (84.88%) (33789/39808)\n",
      "Epoch: 25 | Batch_idx: 320 |  Loss: (0.4364) | Acc: (84.87%) (34873/41088)\n",
      "Epoch: 25 | Batch_idx: 330 |  Loss: (0.4372) | Acc: (84.87%) (35957/42368)\n",
      "Epoch: 25 | Batch_idx: 340 |  Loss: (0.4363) | Acc: (84.91%) (37061/43648)\n",
      "Epoch: 25 | Batch_idx: 350 |  Loss: (0.4359) | Acc: (84.92%) (38155/44928)\n",
      "Epoch: 25 | Batch_idx: 360 |  Loss: (0.4368) | Acc: (84.88%) (39223/46208)\n",
      "Epoch: 25 | Batch_idx: 370 |  Loss: (0.4364) | Acc: (84.86%) (40299/47488)\n",
      "Epoch: 25 | Batch_idx: 380 |  Loss: (0.4370) | Acc: (84.83%) (41370/48768)\n",
      "Epoch: 25 | Batch_idx: 390 |  Loss: (0.4369) | Acc: (84.83%) (42417/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5342) | Acc: (82.28%) (8228/10000)\n",
      "Epoch: 26 | Batch_idx: 0 |  Loss: (0.3593) | Acc: (85.94%) (110/128)\n",
      "Epoch: 26 | Batch_idx: 10 |  Loss: (0.3992) | Acc: (85.51%) (1204/1408)\n",
      "Epoch: 26 | Batch_idx: 20 |  Loss: (0.4136) | Acc: (85.31%) (2293/2688)\n",
      "Epoch: 26 | Batch_idx: 30 |  Loss: (0.4156) | Acc: (85.28%) (3384/3968)\n",
      "Epoch: 26 | Batch_idx: 40 |  Loss: (0.4222) | Acc: (84.97%) (4459/5248)\n",
      "Epoch: 26 | Batch_idx: 50 |  Loss: (0.4165) | Acc: (85.14%) (5558/6528)\n",
      "Epoch: 26 | Batch_idx: 60 |  Loss: (0.4163) | Acc: (85.16%) (6649/7808)\n",
      "Epoch: 26 | Batch_idx: 70 |  Loss: (0.4200) | Acc: (85.01%) (7726/9088)\n",
      "Epoch: 26 | Batch_idx: 80 |  Loss: (0.4211) | Acc: (85.10%) (8823/10368)\n",
      "Epoch: 26 | Batch_idx: 90 |  Loss: (0.4164) | Acc: (85.22%) (9926/11648)\n",
      "Epoch: 26 | Batch_idx: 100 |  Loss: (0.4167) | Acc: (85.24%) (11020/12928)\n",
      "Epoch: 26 | Batch_idx: 110 |  Loss: (0.4212) | Acc: (85.13%) (12095/14208)\n",
      "Epoch: 26 | Batch_idx: 120 |  Loss: (0.4208) | Acc: (85.19%) (13195/15488)\n",
      "Epoch: 26 | Batch_idx: 130 |  Loss: (0.4248) | Acc: (85.11%) (14271/16768)\n",
      "Epoch: 26 | Batch_idx: 140 |  Loss: (0.4255) | Acc: (85.06%) (15352/18048)\n",
      "Epoch: 26 | Batch_idx: 150 |  Loss: (0.4241) | Acc: (85.13%) (16454/19328)\n",
      "Epoch: 26 | Batch_idx: 160 |  Loss: (0.4251) | Acc: (85.09%) (17536/20608)\n",
      "Epoch: 26 | Batch_idx: 170 |  Loss: (0.4236) | Acc: (85.13%) (18633/21888)\n",
      "Epoch: 26 | Batch_idx: 180 |  Loss: (0.4237) | Acc: (85.16%) (19731/23168)\n",
      "Epoch: 26 | Batch_idx: 190 |  Loss: (0.4244) | Acc: (85.15%) (20817/24448)\n",
      "Epoch: 26 | Batch_idx: 200 |  Loss: (0.4256) | Acc: (85.14%) (21906/25728)\n",
      "Epoch: 26 | Batch_idx: 210 |  Loss: (0.4259) | Acc: (85.20%) (23010/27008)\n",
      "Epoch: 26 | Batch_idx: 220 |  Loss: (0.4280) | Acc: (85.15%) (24086/28288)\n",
      "Epoch: 26 | Batch_idx: 230 |  Loss: (0.4277) | Acc: (85.15%) (25176/29568)\n",
      "Epoch: 26 | Batch_idx: 240 |  Loss: (0.4294) | Acc: (85.11%) (26255/30848)\n",
      "Epoch: 26 | Batch_idx: 250 |  Loss: (0.4296) | Acc: (85.09%) (27339/32128)\n",
      "Epoch: 26 | Batch_idx: 260 |  Loss: (0.4300) | Acc: (85.06%) (28418/33408)\n",
      "Epoch: 26 | Batch_idx: 270 |  Loss: (0.4307) | Acc: (85.05%) (29501/34688)\n",
      "Epoch: 26 | Batch_idx: 280 |  Loss: (0.4298) | Acc: (85.08%) (30603/35968)\n",
      "Epoch: 26 | Batch_idx: 290 |  Loss: (0.4296) | Acc: (85.08%) (31692/37248)\n",
      "Epoch: 26 | Batch_idx: 300 |  Loss: (0.4295) | Acc: (85.06%) (32773/38528)\n",
      "Epoch: 26 | Batch_idx: 310 |  Loss: (0.4292) | Acc: (85.10%) (33878/39808)\n",
      "Epoch: 26 | Batch_idx: 320 |  Loss: (0.4276) | Acc: (85.17%) (34995/41088)\n",
      "Epoch: 26 | Batch_idx: 330 |  Loss: (0.4262) | Acc: (85.23%) (36109/42368)\n",
      "Epoch: 26 | Batch_idx: 340 |  Loss: (0.4266) | Acc: (85.17%) (37176/43648)\n",
      "Epoch: 26 | Batch_idx: 350 |  Loss: (0.4253) | Acc: (85.23%) (38291/44928)\n",
      "Epoch: 26 | Batch_idx: 360 |  Loss: (0.4260) | Acc: (85.21%) (39374/46208)\n",
      "Epoch: 26 | Batch_idx: 370 |  Loss: (0.4261) | Acc: (85.21%) (40464/47488)\n",
      "Epoch: 26 | Batch_idx: 380 |  Loss: (0.4271) | Acc: (85.16%) (41530/48768)\n",
      "Epoch: 26 | Batch_idx: 390 |  Loss: (0.4272) | Acc: (85.14%) (42571/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5814) | Acc: (80.65%) (8065/10000)\n",
      "Epoch: 27 | Batch_idx: 0 |  Loss: (0.2886) | Acc: (89.06%) (114/128)\n",
      "Epoch: 27 | Batch_idx: 10 |  Loss: (0.4258) | Acc: (86.01%) (1211/1408)\n",
      "Epoch: 27 | Batch_idx: 20 |  Loss: (0.4209) | Acc: (86.01%) (2312/2688)\n",
      "Epoch: 27 | Batch_idx: 30 |  Loss: (0.4168) | Acc: (86.06%) (3415/3968)\n",
      "Epoch: 27 | Batch_idx: 40 |  Loss: (0.4217) | Acc: (85.77%) (4501/5248)\n",
      "Epoch: 27 | Batch_idx: 50 |  Loss: (0.4223) | Acc: (85.52%) (5583/6528)\n",
      "Epoch: 27 | Batch_idx: 60 |  Loss: (0.4215) | Acc: (85.46%) (6673/7808)\n",
      "Epoch: 27 | Batch_idx: 70 |  Loss: (0.4258) | Acc: (85.38%) (7759/9088)\n",
      "Epoch: 27 | Batch_idx: 80 |  Loss: (0.4237) | Acc: (85.59%) (8874/10368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Batch_idx: 90 |  Loss: (0.4214) | Acc: (85.66%) (9978/11648)\n",
      "Epoch: 27 | Batch_idx: 100 |  Loss: (0.4196) | Acc: (85.81%) (11093/12928)\n",
      "Epoch: 27 | Batch_idx: 110 |  Loss: (0.4207) | Acc: (85.76%) (12185/14208)\n",
      "Epoch: 27 | Batch_idx: 120 |  Loss: (0.4187) | Acc: (85.85%) (13296/15488)\n",
      "Epoch: 27 | Batch_idx: 130 |  Loss: (0.4174) | Acc: (85.82%) (14390/16768)\n",
      "Epoch: 27 | Batch_idx: 140 |  Loss: (0.4158) | Acc: (85.92%) (15507/18048)\n",
      "Epoch: 27 | Batch_idx: 150 |  Loss: (0.4143) | Acc: (85.95%) (16612/19328)\n",
      "Epoch: 27 | Batch_idx: 160 |  Loss: (0.4161) | Acc: (85.86%) (17693/20608)\n",
      "Epoch: 27 | Batch_idx: 170 |  Loss: (0.4142) | Acc: (85.91%) (18803/21888)\n",
      "Epoch: 27 | Batch_idx: 180 |  Loss: (0.4150) | Acc: (85.86%) (19891/23168)\n",
      "Epoch: 27 | Batch_idx: 190 |  Loss: (0.4156) | Acc: (85.84%) (20985/24448)\n",
      "Epoch: 27 | Batch_idx: 200 |  Loss: (0.4162) | Acc: (85.79%) (22071/25728)\n",
      "Epoch: 27 | Batch_idx: 210 |  Loss: (0.4169) | Acc: (85.76%) (23163/27008)\n",
      "Epoch: 27 | Batch_idx: 220 |  Loss: (0.4159) | Acc: (85.85%) (24286/28288)\n",
      "Epoch: 27 | Batch_idx: 230 |  Loss: (0.4161) | Acc: (85.81%) (25372/29568)\n",
      "Epoch: 27 | Batch_idx: 240 |  Loss: (0.4160) | Acc: (85.80%) (26469/30848)\n",
      "Epoch: 27 | Batch_idx: 250 |  Loss: (0.4165) | Acc: (85.80%) (27566/32128)\n",
      "Epoch: 27 | Batch_idx: 260 |  Loss: (0.4172) | Acc: (85.76%) (28651/33408)\n",
      "Epoch: 27 | Batch_idx: 270 |  Loss: (0.4172) | Acc: (85.74%) (29742/34688)\n",
      "Epoch: 27 | Batch_idx: 280 |  Loss: (0.4155) | Acc: (85.82%) (30866/35968)\n",
      "Epoch: 27 | Batch_idx: 290 |  Loss: (0.4154) | Acc: (85.82%) (31968/37248)\n",
      "Epoch: 27 | Batch_idx: 300 |  Loss: (0.4141) | Acc: (85.86%) (33082/38528)\n",
      "Epoch: 27 | Batch_idx: 310 |  Loss: (0.4149) | Acc: (85.86%) (34181/39808)\n",
      "Epoch: 27 | Batch_idx: 320 |  Loss: (0.4154) | Acc: (85.86%) (35277/41088)\n",
      "Epoch: 27 | Batch_idx: 330 |  Loss: (0.4162) | Acc: (85.83%) (36365/42368)\n",
      "Epoch: 27 | Batch_idx: 340 |  Loss: (0.4163) | Acc: (85.86%) (37477/43648)\n",
      "Epoch: 27 | Batch_idx: 350 |  Loss: (0.4157) | Acc: (85.86%) (38577/44928)\n",
      "Epoch: 27 | Batch_idx: 360 |  Loss: (0.4168) | Acc: (85.82%) (39656/46208)\n",
      "Epoch: 27 | Batch_idx: 370 |  Loss: (0.4159) | Acc: (85.86%) (40775/47488)\n",
      "Epoch: 27 | Batch_idx: 380 |  Loss: (0.4149) | Acc: (85.87%) (41876/48768)\n",
      "Epoch: 27 | Batch_idx: 390 |  Loss: (0.4148) | Acc: (85.88%) (42940/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6214) | Acc: (79.51%) (7951/10000)\n",
      "Epoch: 28 | Batch_idx: 0 |  Loss: (0.3703) | Acc: (85.94%) (110/128)\n",
      "Epoch: 28 | Batch_idx: 10 |  Loss: (0.4187) | Acc: (85.37%) (1202/1408)\n",
      "Epoch: 28 | Batch_idx: 20 |  Loss: (0.4015) | Acc: (85.53%) (2299/2688)\n",
      "Epoch: 28 | Batch_idx: 30 |  Loss: (0.4087) | Acc: (85.66%) (3399/3968)\n",
      "Epoch: 28 | Batch_idx: 40 |  Loss: (0.4082) | Acc: (86.01%) (4514/5248)\n",
      "Epoch: 28 | Batch_idx: 50 |  Loss: (0.4020) | Acc: (86.37%) (5638/6528)\n",
      "Epoch: 28 | Batch_idx: 60 |  Loss: (0.4003) | Acc: (86.36%) (6743/7808)\n",
      "Epoch: 28 | Batch_idx: 70 |  Loss: (0.4016) | Acc: (86.38%) (7850/9088)\n",
      "Epoch: 28 | Batch_idx: 80 |  Loss: (0.3999) | Acc: (86.48%) (8966/10368)\n",
      "Epoch: 28 | Batch_idx: 90 |  Loss: (0.4004) | Acc: (86.45%) (10070/11648)\n",
      "Epoch: 28 | Batch_idx: 100 |  Loss: (0.3995) | Acc: (86.47%) (11179/12928)\n",
      "Epoch: 28 | Batch_idx: 110 |  Loss: (0.4000) | Acc: (86.54%) (12296/14208)\n",
      "Epoch: 28 | Batch_idx: 120 |  Loss: (0.3998) | Acc: (86.53%) (13402/15488)\n",
      "Epoch: 28 | Batch_idx: 130 |  Loss: (0.4006) | Acc: (86.47%) (14500/16768)\n",
      "Epoch: 28 | Batch_idx: 140 |  Loss: (0.4003) | Acc: (86.46%) (15605/18048)\n",
      "Epoch: 28 | Batch_idx: 150 |  Loss: (0.3975) | Acc: (86.58%) (16735/19328)\n",
      "Epoch: 28 | Batch_idx: 160 |  Loss: (0.3984) | Acc: (86.51%) (17827/20608)\n",
      "Epoch: 28 | Batch_idx: 170 |  Loss: (0.3963) | Acc: (86.57%) (18949/21888)\n",
      "Epoch: 28 | Batch_idx: 180 |  Loss: (0.3970) | Acc: (86.50%) (20040/23168)\n",
      "Epoch: 28 | Batch_idx: 190 |  Loss: (0.3977) | Acc: (86.46%) (21138/24448)\n",
      "Epoch: 28 | Batch_idx: 200 |  Loss: (0.3970) | Acc: (86.49%) (22252/25728)\n",
      "Epoch: 28 | Batch_idx: 210 |  Loss: (0.3988) | Acc: (86.43%) (23342/27008)\n",
      "Epoch: 28 | Batch_idx: 220 |  Loss: (0.3986) | Acc: (86.41%) (24445/28288)\n",
      "Epoch: 28 | Batch_idx: 230 |  Loss: (0.3988) | Acc: (86.37%) (25539/29568)\n",
      "Epoch: 28 | Batch_idx: 240 |  Loss: (0.4012) | Acc: (86.28%) (26617/30848)\n",
      "Epoch: 28 | Batch_idx: 250 |  Loss: (0.4009) | Acc: (86.25%) (27710/32128)\n",
      "Epoch: 28 | Batch_idx: 260 |  Loss: (0.3998) | Acc: (86.30%) (28831/33408)\n",
      "Epoch: 28 | Batch_idx: 270 |  Loss: (0.4006) | Acc: (86.26%) (29923/34688)\n",
      "Epoch: 28 | Batch_idx: 280 |  Loss: (0.4007) | Acc: (86.27%) (31031/35968)\n",
      "Epoch: 28 | Batch_idx: 290 |  Loss: (0.4004) | Acc: (86.25%) (32127/37248)\n",
      "Epoch: 28 | Batch_idx: 300 |  Loss: (0.4005) | Acc: (86.26%) (33234/38528)\n",
      "Epoch: 28 | Batch_idx: 310 |  Loss: (0.4010) | Acc: (86.27%) (34341/39808)\n",
      "Epoch: 28 | Batch_idx: 320 |  Loss: (0.4005) | Acc: (86.30%) (35460/41088)\n",
      "Epoch: 28 | Batch_idx: 330 |  Loss: (0.4007) | Acc: (86.28%) (36554/42368)\n",
      "Epoch: 28 | Batch_idx: 340 |  Loss: (0.4007) | Acc: (86.28%) (37658/43648)\n",
      "Epoch: 28 | Batch_idx: 350 |  Loss: (0.4016) | Acc: (86.25%) (38751/44928)\n",
      "Epoch: 28 | Batch_idx: 360 |  Loss: (0.4018) | Acc: (86.23%) (39846/46208)\n",
      "Epoch: 28 | Batch_idx: 370 |  Loss: (0.4023) | Acc: (86.19%) (40930/47488)\n",
      "Epoch: 28 | Batch_idx: 380 |  Loss: (0.4021) | Acc: (86.22%) (42048/48768)\n",
      "Epoch: 28 | Batch_idx: 390 |  Loss: (0.4021) | Acc: (86.22%) (43110/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6770) | Acc: (78.93%) (7893/10000)\n",
      "Epoch: 29 | Batch_idx: 0 |  Loss: (0.4295) | Acc: (83.59%) (107/128)\n",
      "Epoch: 29 | Batch_idx: 10 |  Loss: (0.4113) | Acc: (85.72%) (1207/1408)\n",
      "Epoch: 29 | Batch_idx: 20 |  Loss: (0.3976) | Acc: (85.94%) (2310/2688)\n",
      "Epoch: 29 | Batch_idx: 30 |  Loss: (0.3929) | Acc: (86.19%) (3420/3968)\n",
      "Epoch: 29 | Batch_idx: 40 |  Loss: (0.3876) | Acc: (86.30%) (4529/5248)\n",
      "Epoch: 29 | Batch_idx: 50 |  Loss: (0.3908) | Acc: (86.20%) (5627/6528)\n",
      "Epoch: 29 | Batch_idx: 60 |  Loss: (0.3841) | Acc: (86.51%) (6755/7808)\n",
      "Epoch: 29 | Batch_idx: 70 |  Loss: (0.3811) | Acc: (86.86%) (7894/9088)\n",
      "Epoch: 29 | Batch_idx: 80 |  Loss: (0.3830) | Acc: (86.76%) (8995/10368)\n",
      "Epoch: 29 | Batch_idx: 90 |  Loss: (0.3836) | Acc: (86.66%) (10094/11648)\n",
      "Epoch: 29 | Batch_idx: 100 |  Loss: (0.3852) | Acc: (86.59%) (11195/12928)\n",
      "Epoch: 29 | Batch_idx: 110 |  Loss: (0.3823) | Acc: (86.74%) (12324/14208)\n",
      "Epoch: 29 | Batch_idx: 120 |  Loss: (0.3891) | Acc: (86.47%) (13392/15488)\n",
      "Epoch: 29 | Batch_idx: 130 |  Loss: (0.3880) | Acc: (86.52%) (14507/16768)\n",
      "Epoch: 29 | Batch_idx: 140 |  Loss: (0.3874) | Acc: (86.57%) (15625/18048)\n",
      "Epoch: 29 | Batch_idx: 150 |  Loss: (0.3873) | Acc: (86.61%) (16740/19328)\n",
      "Epoch: 29 | Batch_idx: 160 |  Loss: (0.3879) | Acc: (86.57%) (17840/20608)\n",
      "Epoch: 29 | Batch_idx: 170 |  Loss: (0.3884) | Acc: (86.56%) (18946/21888)\n",
      "Epoch: 29 | Batch_idx: 180 |  Loss: (0.3876) | Acc: (86.52%) (20045/23168)\n",
      "Epoch: 29 | Batch_idx: 190 |  Loss: (0.3898) | Acc: (86.44%) (21132/24448)\n",
      "Epoch: 29 | Batch_idx: 200 |  Loss: (0.3892) | Acc: (86.50%) (22254/25728)\n",
      "Epoch: 29 | Batch_idx: 210 |  Loss: (0.3922) | Acc: (86.41%) (23337/27008)\n",
      "Epoch: 29 | Batch_idx: 220 |  Loss: (0.3917) | Acc: (86.40%) (24440/28288)\n",
      "Epoch: 29 | Batch_idx: 230 |  Loss: (0.3921) | Acc: (86.33%) (25526/29568)\n",
      "Epoch: 29 | Batch_idx: 240 |  Loss: (0.3938) | Acc: (86.30%) (26621/30848)\n",
      "Epoch: 29 | Batch_idx: 250 |  Loss: (0.3945) | Acc: (86.27%) (27716/32128)\n",
      "Epoch: 29 | Batch_idx: 260 |  Loss: (0.3949) | Acc: (86.25%) (28813/33408)\n",
      "Epoch: 29 | Batch_idx: 270 |  Loss: (0.3944) | Acc: (86.30%) (29936/34688)\n",
      "Epoch: 29 | Batch_idx: 280 |  Loss: (0.3943) | Acc: (86.32%) (31049/35968)\n",
      "Epoch: 29 | Batch_idx: 290 |  Loss: (0.3953) | Acc: (86.31%) (32147/37248)\n",
      "Epoch: 29 | Batch_idx: 300 |  Loss: (0.3953) | Acc: (86.31%) (33253/38528)\n",
      "Epoch: 29 | Batch_idx: 310 |  Loss: (0.3953) | Acc: (86.29%) (34349/39808)\n",
      "Epoch: 29 | Batch_idx: 320 |  Loss: (0.3960) | Acc: (86.28%) (35450/41088)\n",
      "Epoch: 29 | Batch_idx: 330 |  Loss: (0.3956) | Acc: (86.30%) (36562/42368)\n",
      "Epoch: 29 | Batch_idx: 340 |  Loss: (0.3964) | Acc: (86.29%) (37664/43648)\n",
      "Epoch: 29 | Batch_idx: 350 |  Loss: (0.3971) | Acc: (86.25%) (38750/44928)\n",
      "Epoch: 29 | Batch_idx: 360 |  Loss: (0.3969) | Acc: (86.24%) (39848/46208)\n",
      "Epoch: 29 | Batch_idx: 370 |  Loss: (0.3969) | Acc: (86.23%) (40948/47488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Batch_idx: 380 |  Loss: (0.3958) | Acc: (86.27%) (42072/48768)\n",
      "Epoch: 29 | Batch_idx: 390 |  Loss: (0.3962) | Acc: (86.23%) (43116/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4991) | Acc: (82.80%) (8280/10000)\n",
      "Epoch: 30 | Batch_idx: 0 |  Loss: (0.3407) | Acc: (89.84%) (115/128)\n",
      "Epoch: 30 | Batch_idx: 10 |  Loss: (0.3719) | Acc: (88.14%) (1241/1408)\n",
      "Epoch: 30 | Batch_idx: 20 |  Loss: (0.3773) | Acc: (87.57%) (2354/2688)\n",
      "Epoch: 30 | Batch_idx: 30 |  Loss: (0.3747) | Acc: (87.73%) (3481/3968)\n",
      "Epoch: 30 | Batch_idx: 40 |  Loss: (0.3798) | Acc: (87.27%) (4580/5248)\n",
      "Epoch: 30 | Batch_idx: 50 |  Loss: (0.3772) | Acc: (87.41%) (5706/6528)\n",
      "Epoch: 30 | Batch_idx: 60 |  Loss: (0.3807) | Acc: (87.19%) (6808/7808)\n",
      "Epoch: 30 | Batch_idx: 70 |  Loss: (0.3791) | Acc: (87.24%) (7928/9088)\n",
      "Epoch: 30 | Batch_idx: 80 |  Loss: (0.3786) | Acc: (87.26%) (9047/10368)\n",
      "Epoch: 30 | Batch_idx: 90 |  Loss: (0.3784) | Acc: (87.12%) (10148/11648)\n",
      "Epoch: 30 | Batch_idx: 100 |  Loss: (0.3799) | Acc: (87.07%) (11256/12928)\n",
      "Epoch: 30 | Batch_idx: 110 |  Loss: (0.3782) | Acc: (87.15%) (12382/14208)\n",
      "Epoch: 30 | Batch_idx: 120 |  Loss: (0.3791) | Acc: (87.11%) (13492/15488)\n",
      "Epoch: 30 | Batch_idx: 130 |  Loss: (0.3792) | Acc: (87.10%) (14605/16768)\n",
      "Epoch: 30 | Batch_idx: 140 |  Loss: (0.3767) | Acc: (87.12%) (15723/18048)\n",
      "Epoch: 30 | Batch_idx: 150 |  Loss: (0.3783) | Acc: (87.00%) (16815/19328)\n",
      "Epoch: 30 | Batch_idx: 160 |  Loss: (0.3788) | Acc: (86.91%) (17910/20608)\n",
      "Epoch: 30 | Batch_idx: 170 |  Loss: (0.3799) | Acc: (86.83%) (19006/21888)\n",
      "Epoch: 30 | Batch_idx: 180 |  Loss: (0.3804) | Acc: (86.79%) (20108/23168)\n",
      "Epoch: 30 | Batch_idx: 190 |  Loss: (0.3817) | Acc: (86.78%) (21216/24448)\n",
      "Epoch: 30 | Batch_idx: 200 |  Loss: (0.3817) | Acc: (86.76%) (22321/25728)\n",
      "Epoch: 30 | Batch_idx: 210 |  Loss: (0.3817) | Acc: (86.77%) (23435/27008)\n",
      "Epoch: 30 | Batch_idx: 220 |  Loss: (0.3837) | Acc: (86.76%) (24542/28288)\n",
      "Epoch: 30 | Batch_idx: 230 |  Loss: (0.3848) | Acc: (86.67%) (25628/29568)\n",
      "Epoch: 30 | Batch_idx: 240 |  Loss: (0.3846) | Acc: (86.69%) (26741/30848)\n",
      "Epoch: 30 | Batch_idx: 250 |  Loss: (0.3854) | Acc: (86.63%) (27834/32128)\n",
      "Epoch: 30 | Batch_idx: 260 |  Loss: (0.3852) | Acc: (86.64%) (28946/33408)\n",
      "Epoch: 30 | Batch_idx: 270 |  Loss: (0.3857) | Acc: (86.61%) (30045/34688)\n",
      "Epoch: 30 | Batch_idx: 280 |  Loss: (0.3860) | Acc: (86.62%) (31154/35968)\n",
      "Epoch: 30 | Batch_idx: 290 |  Loss: (0.3856) | Acc: (86.62%) (32266/37248)\n",
      "Epoch: 30 | Batch_idx: 300 |  Loss: (0.3868) | Acc: (86.58%) (33357/38528)\n",
      "Epoch: 30 | Batch_idx: 310 |  Loss: (0.3875) | Acc: (86.56%) (34457/39808)\n",
      "Epoch: 30 | Batch_idx: 320 |  Loss: (0.3879) | Acc: (86.56%) (35567/41088)\n",
      "Epoch: 30 | Batch_idx: 330 |  Loss: (0.3872) | Acc: (86.58%) (36684/42368)\n",
      "Epoch: 30 | Batch_idx: 340 |  Loss: (0.3862) | Acc: (86.62%) (37806/43648)\n",
      "Epoch: 30 | Batch_idx: 350 |  Loss: (0.3864) | Acc: (86.64%) (38926/44928)\n",
      "Epoch: 30 | Batch_idx: 360 |  Loss: (0.3866) | Acc: (86.62%) (40027/46208)\n",
      "Epoch: 30 | Batch_idx: 370 |  Loss: (0.3865) | Acc: (86.63%) (41139/47488)\n",
      "Epoch: 30 | Batch_idx: 380 |  Loss: (0.3872) | Acc: (86.60%) (42232/48768)\n",
      "Epoch: 30 | Batch_idx: 390 |  Loss: (0.3885) | Acc: (86.53%) (43267/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5252) | Acc: (82.97%) (8297/10000)\n",
      "Epoch: 31 | Batch_idx: 0 |  Loss: (0.4196) | Acc: (85.16%) (109/128)\n",
      "Epoch: 31 | Batch_idx: 10 |  Loss: (0.3872) | Acc: (86.36%) (1216/1408)\n",
      "Epoch: 31 | Batch_idx: 20 |  Loss: (0.3792) | Acc: (86.94%) (2337/2688)\n",
      "Epoch: 31 | Batch_idx: 30 |  Loss: (0.3715) | Acc: (86.97%) (3451/3968)\n",
      "Epoch: 31 | Batch_idx: 40 |  Loss: (0.3785) | Acc: (86.51%) (4540/5248)\n",
      "Epoch: 31 | Batch_idx: 50 |  Loss: (0.3731) | Acc: (86.96%) (5677/6528)\n",
      "Epoch: 31 | Batch_idx: 60 |  Loss: (0.3764) | Acc: (86.65%) (6766/7808)\n",
      "Epoch: 31 | Batch_idx: 70 |  Loss: (0.3780) | Acc: (86.64%) (7874/9088)\n",
      "Epoch: 31 | Batch_idx: 80 |  Loss: (0.3784) | Acc: (86.84%) (9004/10368)\n",
      "Epoch: 31 | Batch_idx: 90 |  Loss: (0.3790) | Acc: (86.80%) (10111/11648)\n",
      "Epoch: 31 | Batch_idx: 100 |  Loss: (0.3795) | Acc: (86.76%) (11216/12928)\n",
      "Epoch: 31 | Batch_idx: 110 |  Loss: (0.3810) | Acc: (86.58%) (12301/14208)\n",
      "Epoch: 31 | Batch_idx: 120 |  Loss: (0.3780) | Acc: (86.71%) (13430/15488)\n",
      "Epoch: 31 | Batch_idx: 130 |  Loss: (0.3750) | Acc: (86.90%) (14572/16768)\n",
      "Epoch: 31 | Batch_idx: 140 |  Loss: (0.3726) | Acc: (87.11%) (15722/18048)\n",
      "Epoch: 31 | Batch_idx: 150 |  Loss: (0.3715) | Acc: (87.10%) (16835/19328)\n",
      "Epoch: 31 | Batch_idx: 160 |  Loss: (0.3726) | Acc: (87.09%) (17947/20608)\n",
      "Epoch: 31 | Batch_idx: 170 |  Loss: (0.3718) | Acc: (87.11%) (19066/21888)\n",
      "Epoch: 31 | Batch_idx: 180 |  Loss: (0.3752) | Acc: (86.95%) (20145/23168)\n",
      "Epoch: 31 | Batch_idx: 190 |  Loss: (0.3751) | Acc: (86.94%) (21256/24448)\n",
      "Epoch: 31 | Batch_idx: 200 |  Loss: (0.3757) | Acc: (86.91%) (22359/25728)\n",
      "Epoch: 31 | Batch_idx: 210 |  Loss: (0.3747) | Acc: (87.00%) (23497/27008)\n",
      "Epoch: 31 | Batch_idx: 220 |  Loss: (0.3758) | Acc: (86.92%) (24589/28288)\n",
      "Epoch: 31 | Batch_idx: 230 |  Loss: (0.3747) | Acc: (86.97%) (25714/29568)\n",
      "Epoch: 31 | Batch_idx: 240 |  Loss: (0.3745) | Acc: (86.99%) (26835/30848)\n",
      "Epoch: 31 | Batch_idx: 250 |  Loss: (0.3762) | Acc: (86.96%) (27940/32128)\n",
      "Epoch: 31 | Batch_idx: 260 |  Loss: (0.3757) | Acc: (86.98%) (29057/33408)\n",
      "Epoch: 31 | Batch_idx: 270 |  Loss: (0.3757) | Acc: (86.95%) (30161/34688)\n",
      "Epoch: 31 | Batch_idx: 280 |  Loss: (0.3767) | Acc: (86.92%) (31262/35968)\n",
      "Epoch: 31 | Batch_idx: 290 |  Loss: (0.3766) | Acc: (86.90%) (32370/37248)\n",
      "Epoch: 31 | Batch_idx: 300 |  Loss: (0.3755) | Acc: (86.96%) (33504/38528)\n",
      "Epoch: 31 | Batch_idx: 310 |  Loss: (0.3777) | Acc: (86.91%) (34596/39808)\n",
      "Epoch: 31 | Batch_idx: 320 |  Loss: (0.3772) | Acc: (86.93%) (35717/41088)\n",
      "Epoch: 31 | Batch_idx: 330 |  Loss: (0.3764) | Acc: (86.95%) (36837/42368)\n",
      "Epoch: 31 | Batch_idx: 340 |  Loss: (0.3763) | Acc: (86.95%) (37952/43648)\n",
      "Epoch: 31 | Batch_idx: 350 |  Loss: (0.3761) | Acc: (86.95%) (39066/44928)\n",
      "Epoch: 31 | Batch_idx: 360 |  Loss: (0.3770) | Acc: (86.92%) (40166/46208)\n",
      "Epoch: 31 | Batch_idx: 370 |  Loss: (0.3778) | Acc: (86.88%) (41258/47488)\n",
      "Epoch: 31 | Batch_idx: 380 |  Loss: (0.3786) | Acc: (86.85%) (42355/48768)\n",
      "Epoch: 31 | Batch_idx: 390 |  Loss: (0.3794) | Acc: (86.81%) (43404/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7057) | Acc: (78.54%) (7854/10000)\n",
      "Epoch: 32 | Batch_idx: 0 |  Loss: (0.4818) | Acc: (83.59%) (107/128)\n",
      "Epoch: 32 | Batch_idx: 10 |  Loss: (0.3278) | Acc: (88.78%) (1250/1408)\n",
      "Epoch: 32 | Batch_idx: 20 |  Loss: (0.3412) | Acc: (88.02%) (2366/2688)\n",
      "Epoch: 32 | Batch_idx: 30 |  Loss: (0.3588) | Acc: (87.65%) (3478/3968)\n",
      "Epoch: 32 | Batch_idx: 40 |  Loss: (0.3655) | Acc: (87.35%) (4584/5248)\n",
      "Epoch: 32 | Batch_idx: 50 |  Loss: (0.3640) | Acc: (87.39%) (5705/6528)\n",
      "Epoch: 32 | Batch_idx: 60 |  Loss: (0.3639) | Acc: (87.23%) (6811/7808)\n",
      "Epoch: 32 | Batch_idx: 70 |  Loss: (0.3631) | Acc: (87.27%) (7931/9088)\n",
      "Epoch: 32 | Batch_idx: 80 |  Loss: (0.3632) | Acc: (87.34%) (9055/10368)\n",
      "Epoch: 32 | Batch_idx: 90 |  Loss: (0.3591) | Acc: (87.45%) (10186/11648)\n",
      "Epoch: 32 | Batch_idx: 100 |  Loss: (0.3590) | Acc: (87.53%) (11316/12928)\n",
      "Epoch: 32 | Batch_idx: 110 |  Loss: (0.3609) | Acc: (87.37%) (12413/14208)\n",
      "Epoch: 32 | Batch_idx: 120 |  Loss: (0.3608) | Acc: (87.33%) (13526/15488)\n",
      "Epoch: 32 | Batch_idx: 130 |  Loss: (0.3600) | Acc: (87.35%) (14647/16768)\n",
      "Epoch: 32 | Batch_idx: 140 |  Loss: (0.3589) | Acc: (87.46%) (15785/18048)\n",
      "Epoch: 32 | Batch_idx: 150 |  Loss: (0.3614) | Acc: (87.40%) (16892/19328)\n",
      "Epoch: 32 | Batch_idx: 160 |  Loss: (0.3594) | Acc: (87.44%) (18020/20608)\n",
      "Epoch: 32 | Batch_idx: 170 |  Loss: (0.3599) | Acc: (87.44%) (19139/21888)\n",
      "Epoch: 32 | Batch_idx: 180 |  Loss: (0.3590) | Acc: (87.46%) (20263/23168)\n",
      "Epoch: 32 | Batch_idx: 190 |  Loss: (0.3588) | Acc: (87.49%) (21390/24448)\n",
      "Epoch: 32 | Batch_idx: 200 |  Loss: (0.3613) | Acc: (87.39%) (22483/25728)\n",
      "Epoch: 32 | Batch_idx: 210 |  Loss: (0.3606) | Acc: (87.37%) (23598/27008)\n",
      "Epoch: 32 | Batch_idx: 220 |  Loss: (0.3624) | Acc: (87.31%) (24697/28288)\n",
      "Epoch: 32 | Batch_idx: 230 |  Loss: (0.3642) | Acc: (87.25%) (25799/29568)\n",
      "Epoch: 32 | Batch_idx: 240 |  Loss: (0.3640) | Acc: (87.28%) (26923/30848)\n",
      "Epoch: 32 | Batch_idx: 250 |  Loss: (0.3650) | Acc: (87.27%) (28037/32128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Batch_idx: 260 |  Loss: (0.3659) | Acc: (87.22%) (29137/33408)\n",
      "Epoch: 32 | Batch_idx: 270 |  Loss: (0.3656) | Acc: (87.23%) (30259/34688)\n",
      "Epoch: 32 | Batch_idx: 280 |  Loss: (0.3668) | Acc: (87.18%) (31358/35968)\n",
      "Epoch: 32 | Batch_idx: 290 |  Loss: (0.3680) | Acc: (87.16%) (32466/37248)\n",
      "Epoch: 32 | Batch_idx: 300 |  Loss: (0.3684) | Acc: (87.14%) (33575/38528)\n",
      "Epoch: 32 | Batch_idx: 310 |  Loss: (0.3675) | Acc: (87.18%) (34706/39808)\n",
      "Epoch: 32 | Batch_idx: 320 |  Loss: (0.3681) | Acc: (87.16%) (35812/41088)\n",
      "Epoch: 32 | Batch_idx: 330 |  Loss: (0.3679) | Acc: (87.18%) (36937/42368)\n",
      "Epoch: 32 | Batch_idx: 340 |  Loss: (0.3677) | Acc: (87.20%) (38061/43648)\n",
      "Epoch: 32 | Batch_idx: 350 |  Loss: (0.3669) | Acc: (87.25%) (39199/44928)\n",
      "Epoch: 32 | Batch_idx: 360 |  Loss: (0.3670) | Acc: (87.25%) (40316/46208)\n",
      "Epoch: 32 | Batch_idx: 370 |  Loss: (0.3672) | Acc: (87.22%) (41420/47488)\n",
      "Epoch: 32 | Batch_idx: 380 |  Loss: (0.3669) | Acc: (87.21%) (42530/48768)\n",
      "Epoch: 32 | Batch_idx: 390 |  Loss: (0.3670) | Acc: (87.22%) (43611/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5338) | Acc: (82.43%) (8243/10000)\n",
      "Epoch: 33 | Batch_idx: 0 |  Loss: (0.3726) | Acc: (85.94%) (110/128)\n",
      "Epoch: 33 | Batch_idx: 10 |  Loss: (0.3619) | Acc: (87.14%) (1227/1408)\n",
      "Epoch: 33 | Batch_idx: 20 |  Loss: (0.3762) | Acc: (86.50%) (2325/2688)\n",
      "Epoch: 33 | Batch_idx: 30 |  Loss: (0.3692) | Acc: (87.17%) (3459/3968)\n",
      "Epoch: 33 | Batch_idx: 40 |  Loss: (0.3585) | Acc: (87.63%) (4599/5248)\n",
      "Epoch: 33 | Batch_idx: 50 |  Loss: (0.3600) | Acc: (87.47%) (5710/6528)\n",
      "Epoch: 33 | Batch_idx: 60 |  Loss: (0.3520) | Acc: (87.74%) (6851/7808)\n",
      "Epoch: 33 | Batch_idx: 70 |  Loss: (0.3524) | Acc: (87.70%) (7970/9088)\n",
      "Epoch: 33 | Batch_idx: 80 |  Loss: (0.3573) | Acc: (87.58%) (9080/10368)\n",
      "Epoch: 33 | Batch_idx: 90 |  Loss: (0.3556) | Acc: (87.69%) (10214/11648)\n",
      "Epoch: 33 | Batch_idx: 100 |  Loss: (0.3538) | Acc: (87.75%) (11344/12928)\n",
      "Epoch: 33 | Batch_idx: 110 |  Loss: (0.3530) | Acc: (87.84%) (12481/14208)\n",
      "Epoch: 33 | Batch_idx: 120 |  Loss: (0.3541) | Acc: (87.84%) (13605/15488)\n",
      "Epoch: 33 | Batch_idx: 130 |  Loss: (0.3556) | Acc: (87.86%) (14732/16768)\n",
      "Epoch: 33 | Batch_idx: 140 |  Loss: (0.3565) | Acc: (87.77%) (15841/18048)\n",
      "Epoch: 33 | Batch_idx: 150 |  Loss: (0.3576) | Acc: (87.75%) (16960/19328)\n",
      "Epoch: 33 | Batch_idx: 160 |  Loss: (0.3591) | Acc: (87.71%) (18075/20608)\n",
      "Epoch: 33 | Batch_idx: 170 |  Loss: (0.3576) | Acc: (87.79%) (19216/21888)\n",
      "Epoch: 33 | Batch_idx: 180 |  Loss: (0.3567) | Acc: (87.82%) (20345/23168)\n",
      "Epoch: 33 | Batch_idx: 190 |  Loss: (0.3558) | Acc: (87.80%) (21466/24448)\n",
      "Epoch: 33 | Batch_idx: 200 |  Loss: (0.3566) | Acc: (87.83%) (22597/25728)\n",
      "Epoch: 33 | Batch_idx: 210 |  Loss: (0.3575) | Acc: (87.75%) (23700/27008)\n",
      "Epoch: 33 | Batch_idx: 220 |  Loss: (0.3574) | Acc: (87.73%) (24817/28288)\n",
      "Epoch: 33 | Batch_idx: 230 |  Loss: (0.3580) | Acc: (87.70%) (25931/29568)\n",
      "Epoch: 33 | Batch_idx: 240 |  Loss: (0.3580) | Acc: (87.69%) (27052/30848)\n",
      "Epoch: 33 | Batch_idx: 250 |  Loss: (0.3579) | Acc: (87.66%) (28165/32128)\n",
      "Epoch: 33 | Batch_idx: 260 |  Loss: (0.3564) | Acc: (87.72%) (29305/33408)\n",
      "Epoch: 33 | Batch_idx: 270 |  Loss: (0.3567) | Acc: (87.71%) (30425/34688)\n",
      "Epoch: 33 | Batch_idx: 280 |  Loss: (0.3568) | Acc: (87.71%) (31546/35968)\n",
      "Epoch: 33 | Batch_idx: 290 |  Loss: (0.3583) | Acc: (87.67%) (32657/37248)\n",
      "Epoch: 33 | Batch_idx: 300 |  Loss: (0.3583) | Acc: (87.65%) (33769/38528)\n",
      "Epoch: 33 | Batch_idx: 310 |  Loss: (0.3577) | Acc: (87.66%) (34895/39808)\n",
      "Epoch: 33 | Batch_idx: 320 |  Loss: (0.3591) | Acc: (87.61%) (35998/41088)\n",
      "Epoch: 33 | Batch_idx: 330 |  Loss: (0.3582) | Acc: (87.66%) (37138/42368)\n",
      "Epoch: 33 | Batch_idx: 340 |  Loss: (0.3582) | Acc: (87.63%) (38250/43648)\n",
      "Epoch: 33 | Batch_idx: 350 |  Loss: (0.3584) | Acc: (87.62%) (39367/44928)\n",
      "Epoch: 33 | Batch_idx: 360 |  Loss: (0.3586) | Acc: (87.61%) (40483/46208)\n",
      "Epoch: 33 | Batch_idx: 370 |  Loss: (0.3589) | Acc: (87.60%) (41599/47488)\n",
      "Epoch: 33 | Batch_idx: 380 |  Loss: (0.3582) | Acc: (87.60%) (42723/48768)\n",
      "Epoch: 33 | Batch_idx: 390 |  Loss: (0.3585) | Acc: (87.62%) (43808/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5294) | Acc: (82.52%) (8252/10000)\n",
      "Epoch: 34 | Batch_idx: 0 |  Loss: (0.4312) | Acc: (84.38%) (108/128)\n",
      "Epoch: 34 | Batch_idx: 10 |  Loss: (0.3248) | Acc: (89.06%) (1254/1408)\n",
      "Epoch: 34 | Batch_idx: 20 |  Loss: (0.3391) | Acc: (88.10%) (2368/2688)\n",
      "Epoch: 34 | Batch_idx: 30 |  Loss: (0.3375) | Acc: (88.28%) (3503/3968)\n",
      "Epoch: 34 | Batch_idx: 40 |  Loss: (0.3424) | Acc: (88.26%) (4632/5248)\n",
      "Epoch: 34 | Batch_idx: 50 |  Loss: (0.3410) | Acc: (88.34%) (5767/6528)\n",
      "Epoch: 34 | Batch_idx: 60 |  Loss: (0.3442) | Acc: (88.23%) (6889/7808)\n",
      "Epoch: 34 | Batch_idx: 70 |  Loss: (0.3451) | Acc: (88.22%) (8017/9088)\n",
      "Epoch: 34 | Batch_idx: 80 |  Loss: (0.3438) | Acc: (88.19%) (9144/10368)\n",
      "Epoch: 34 | Batch_idx: 90 |  Loss: (0.3462) | Acc: (88.08%) (10260/11648)\n",
      "Epoch: 34 | Batch_idx: 100 |  Loss: (0.3484) | Acc: (88.04%) (11382/12928)\n",
      "Epoch: 34 | Batch_idx: 110 |  Loss: (0.3500) | Acc: (87.96%) (12498/14208)\n",
      "Epoch: 34 | Batch_idx: 120 |  Loss: (0.3507) | Acc: (87.84%) (13604/15488)\n",
      "Epoch: 34 | Batch_idx: 130 |  Loss: (0.3495) | Acc: (87.89%) (14737/16768)\n",
      "Epoch: 34 | Batch_idx: 140 |  Loss: (0.3549) | Acc: (87.66%) (15821/18048)\n",
      "Epoch: 34 | Batch_idx: 150 |  Loss: (0.3545) | Acc: (87.70%) (16950/19328)\n",
      "Epoch: 34 | Batch_idx: 160 |  Loss: (0.3539) | Acc: (87.75%) (18084/20608)\n",
      "Epoch: 34 | Batch_idx: 170 |  Loss: (0.3541) | Acc: (87.77%) (19212/21888)\n",
      "Epoch: 34 | Batch_idx: 180 |  Loss: (0.3552) | Acc: (87.75%) (20331/23168)\n",
      "Epoch: 34 | Batch_idx: 190 |  Loss: (0.3548) | Acc: (87.77%) (21459/24448)\n",
      "Epoch: 34 | Batch_idx: 200 |  Loss: (0.3547) | Acc: (87.79%) (22586/25728)\n",
      "Epoch: 34 | Batch_idx: 210 |  Loss: (0.3545) | Acc: (87.76%) (23701/27008)\n",
      "Epoch: 34 | Batch_idx: 220 |  Loss: (0.3541) | Acc: (87.79%) (24834/28288)\n",
      "Epoch: 34 | Batch_idx: 230 |  Loss: (0.3548) | Acc: (87.77%) (25951/29568)\n",
      "Epoch: 34 | Batch_idx: 240 |  Loss: (0.3558) | Acc: (87.73%) (27062/30848)\n",
      "Epoch: 34 | Batch_idx: 250 |  Loss: (0.3553) | Acc: (87.76%) (28196/32128)\n",
      "Epoch: 34 | Batch_idx: 260 |  Loss: (0.3555) | Acc: (87.75%) (29315/33408)\n",
      "Epoch: 34 | Batch_idx: 270 |  Loss: (0.3552) | Acc: (87.70%) (30422/34688)\n",
      "Epoch: 34 | Batch_idx: 280 |  Loss: (0.3548) | Acc: (87.71%) (31549/35968)\n",
      "Epoch: 34 | Batch_idx: 290 |  Loss: (0.3535) | Acc: (87.76%) (32687/37248)\n",
      "Epoch: 34 | Batch_idx: 300 |  Loss: (0.3537) | Acc: (87.76%) (33814/38528)\n",
      "Epoch: 34 | Batch_idx: 310 |  Loss: (0.3533) | Acc: (87.78%) (34945/39808)\n",
      "Epoch: 34 | Batch_idx: 320 |  Loss: (0.3531) | Acc: (87.79%) (36073/41088)\n",
      "Epoch: 34 | Batch_idx: 330 |  Loss: (0.3529) | Acc: (87.79%) (37196/42368)\n",
      "Epoch: 34 | Batch_idx: 340 |  Loss: (0.3534) | Acc: (87.78%) (38313/43648)\n",
      "Epoch: 34 | Batch_idx: 350 |  Loss: (0.3533) | Acc: (87.77%) (39433/44928)\n",
      "Epoch: 34 | Batch_idx: 360 |  Loss: (0.3534) | Acc: (87.76%) (40554/46208)\n",
      "Epoch: 34 | Batch_idx: 370 |  Loss: (0.3522) | Acc: (87.79%) (41691/47488)\n",
      "Epoch: 34 | Batch_idx: 380 |  Loss: (0.3529) | Acc: (87.79%) (42811/48768)\n",
      "Epoch: 34 | Batch_idx: 390 |  Loss: (0.3532) | Acc: (87.75%) (43877/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4839) | Acc: (83.62%) (8362/10000)\n",
      "Epoch: 35 | Batch_idx: 0 |  Loss: (0.3159) | Acc: (90.62%) (116/128)\n",
      "Epoch: 35 | Batch_idx: 10 |  Loss: (0.3401) | Acc: (88.00%) (1239/1408)\n",
      "Epoch: 35 | Batch_idx: 20 |  Loss: (0.3354) | Acc: (88.36%) (2375/2688)\n",
      "Epoch: 35 | Batch_idx: 30 |  Loss: (0.3379) | Acc: (88.18%) (3499/3968)\n",
      "Epoch: 35 | Batch_idx: 40 |  Loss: (0.3473) | Acc: (87.84%) (4610/5248)\n",
      "Epoch: 35 | Batch_idx: 50 |  Loss: (0.3449) | Acc: (87.96%) (5742/6528)\n",
      "Epoch: 35 | Batch_idx: 60 |  Loss: (0.3412) | Acc: (88.17%) (6884/7808)\n",
      "Epoch: 35 | Batch_idx: 70 |  Loss: (0.3364) | Acc: (88.31%) (8026/9088)\n",
      "Epoch: 35 | Batch_idx: 80 |  Loss: (0.3367) | Acc: (88.38%) (9163/10368)\n",
      "Epoch: 35 | Batch_idx: 90 |  Loss: (0.3365) | Acc: (88.35%) (10291/11648)\n",
      "Epoch: 35 | Batch_idx: 100 |  Loss: (0.3377) | Acc: (88.31%) (11417/12928)\n",
      "Epoch: 35 | Batch_idx: 110 |  Loss: (0.3384) | Acc: (88.31%) (12547/14208)\n",
      "Epoch: 35 | Batch_idx: 120 |  Loss: (0.3374) | Acc: (88.27%) (13672/15488)\n",
      "Epoch: 35 | Batch_idx: 130 |  Loss: (0.3376) | Acc: (88.22%) (14792/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Batch_idx: 140 |  Loss: (0.3400) | Acc: (88.11%) (15902/18048)\n",
      "Epoch: 35 | Batch_idx: 150 |  Loss: (0.3416) | Acc: (88.04%) (17017/19328)\n",
      "Epoch: 35 | Batch_idx: 160 |  Loss: (0.3422) | Acc: (87.98%) (18131/20608)\n",
      "Epoch: 35 | Batch_idx: 170 |  Loss: (0.3420) | Acc: (88.03%) (19269/21888)\n",
      "Epoch: 35 | Batch_idx: 180 |  Loss: (0.3419) | Acc: (88.05%) (20400/23168)\n",
      "Epoch: 35 | Batch_idx: 190 |  Loss: (0.3435) | Acc: (88.04%) (21524/24448)\n",
      "Epoch: 35 | Batch_idx: 200 |  Loss: (0.3429) | Acc: (88.04%) (22651/25728)\n",
      "Epoch: 35 | Batch_idx: 210 |  Loss: (0.3438) | Acc: (88.03%) (23776/27008)\n",
      "Epoch: 35 | Batch_idx: 220 |  Loss: (0.3445) | Acc: (88.01%) (24896/28288)\n",
      "Epoch: 35 | Batch_idx: 230 |  Loss: (0.3442) | Acc: (87.98%) (26015/29568)\n",
      "Epoch: 35 | Batch_idx: 240 |  Loss: (0.3447) | Acc: (87.97%) (27138/30848)\n",
      "Epoch: 35 | Batch_idx: 250 |  Loss: (0.3435) | Acc: (88.00%) (28273/32128)\n",
      "Epoch: 35 | Batch_idx: 260 |  Loss: (0.3426) | Acc: (88.03%) (29408/33408)\n",
      "Epoch: 35 | Batch_idx: 270 |  Loss: (0.3424) | Acc: (88.00%) (30526/34688)\n",
      "Epoch: 35 | Batch_idx: 280 |  Loss: (0.3433) | Acc: (87.95%) (31635/35968)\n",
      "Epoch: 35 | Batch_idx: 290 |  Loss: (0.3437) | Acc: (87.95%) (32759/37248)\n",
      "Epoch: 35 | Batch_idx: 300 |  Loss: (0.3429) | Acc: (87.95%) (33884/38528)\n",
      "Epoch: 35 | Batch_idx: 310 |  Loss: (0.3432) | Acc: (87.95%) (35011/39808)\n",
      "Epoch: 35 | Batch_idx: 320 |  Loss: (0.3445) | Acc: (87.88%) (36108/41088)\n",
      "Epoch: 35 | Batch_idx: 330 |  Loss: (0.3444) | Acc: (87.91%) (37244/42368)\n",
      "Epoch: 35 | Batch_idx: 340 |  Loss: (0.3443) | Acc: (87.89%) (38364/43648)\n",
      "Epoch: 35 | Batch_idx: 350 |  Loss: (0.3435) | Acc: (87.94%) (39511/44928)\n",
      "Epoch: 35 | Batch_idx: 360 |  Loss: (0.3432) | Acc: (87.95%) (40639/46208)\n",
      "Epoch: 35 | Batch_idx: 370 |  Loss: (0.3433) | Acc: (87.94%) (41759/47488)\n",
      "Epoch: 35 | Batch_idx: 380 |  Loss: (0.3437) | Acc: (87.92%) (42875/48768)\n",
      "Epoch: 35 | Batch_idx: 390 |  Loss: (0.3436) | Acc: (87.92%) (43961/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4974) | Acc: (83.74%) (8374/10000)\n",
      "Epoch: 36 | Batch_idx: 0 |  Loss: (0.3888) | Acc: (89.06%) (114/128)\n",
      "Epoch: 36 | Batch_idx: 10 |  Loss: (0.3452) | Acc: (88.28%) (1243/1408)\n",
      "Epoch: 36 | Batch_idx: 20 |  Loss: (0.3253) | Acc: (88.84%) (2388/2688)\n",
      "Epoch: 36 | Batch_idx: 30 |  Loss: (0.3252) | Acc: (88.73%) (3521/3968)\n",
      "Epoch: 36 | Batch_idx: 40 |  Loss: (0.3158) | Acc: (89.23%) (4683/5248)\n",
      "Epoch: 36 | Batch_idx: 50 |  Loss: (0.3206) | Acc: (88.82%) (5798/6528)\n",
      "Epoch: 36 | Batch_idx: 60 |  Loss: (0.3185) | Acc: (88.93%) (6944/7808)\n",
      "Epoch: 36 | Batch_idx: 70 |  Loss: (0.3176) | Acc: (89.07%) (8095/9088)\n",
      "Epoch: 36 | Batch_idx: 80 |  Loss: (0.3161) | Acc: (89.08%) (9236/10368)\n",
      "Epoch: 36 | Batch_idx: 90 |  Loss: (0.3166) | Acc: (88.99%) (10366/11648)\n",
      "Epoch: 36 | Batch_idx: 100 |  Loss: (0.3183) | Acc: (88.98%) (11503/12928)\n",
      "Epoch: 36 | Batch_idx: 110 |  Loss: (0.3233) | Acc: (88.80%) (12617/14208)\n",
      "Epoch: 36 | Batch_idx: 120 |  Loss: (0.3266) | Acc: (88.70%) (13738/15488)\n",
      "Epoch: 36 | Batch_idx: 130 |  Loss: (0.3274) | Acc: (88.75%) (14881/16768)\n",
      "Epoch: 36 | Batch_idx: 140 |  Loss: (0.3290) | Acc: (88.69%) (16007/18048)\n",
      "Epoch: 36 | Batch_idx: 150 |  Loss: (0.3292) | Acc: (88.68%) (17140/19328)\n",
      "Epoch: 36 | Batch_idx: 160 |  Loss: (0.3303) | Acc: (88.64%) (18266/20608)\n",
      "Epoch: 36 | Batch_idx: 170 |  Loss: (0.3298) | Acc: (88.62%) (19397/21888)\n",
      "Epoch: 36 | Batch_idx: 180 |  Loss: (0.3298) | Acc: (88.61%) (20529/23168)\n",
      "Epoch: 36 | Batch_idx: 190 |  Loss: (0.3310) | Acc: (88.51%) (21640/24448)\n",
      "Epoch: 36 | Batch_idx: 200 |  Loss: (0.3323) | Acc: (88.50%) (22770/25728)\n",
      "Epoch: 36 | Batch_idx: 210 |  Loss: (0.3330) | Acc: (88.51%) (23904/27008)\n",
      "Epoch: 36 | Batch_idx: 220 |  Loss: (0.3320) | Acc: (88.55%) (25050/28288)\n",
      "Epoch: 36 | Batch_idx: 230 |  Loss: (0.3330) | Acc: (88.49%) (26166/29568)\n",
      "Epoch: 36 | Batch_idx: 240 |  Loss: (0.3338) | Acc: (88.42%) (27276/30848)\n",
      "Epoch: 36 | Batch_idx: 250 |  Loss: (0.3349) | Acc: (88.39%) (28397/32128)\n",
      "Epoch: 36 | Batch_idx: 260 |  Loss: (0.3351) | Acc: (88.37%) (29523/33408)\n",
      "Epoch: 36 | Batch_idx: 270 |  Loss: (0.3343) | Acc: (88.39%) (30660/34688)\n",
      "Epoch: 36 | Batch_idx: 280 |  Loss: (0.3342) | Acc: (88.42%) (31803/35968)\n",
      "Epoch: 36 | Batch_idx: 290 |  Loss: (0.3343) | Acc: (88.40%) (32928/37248)\n",
      "Epoch: 36 | Batch_idx: 300 |  Loss: (0.3349) | Acc: (88.38%) (34050/38528)\n",
      "Epoch: 36 | Batch_idx: 310 |  Loss: (0.3358) | Acc: (88.37%) (35178/39808)\n",
      "Epoch: 36 | Batch_idx: 320 |  Loss: (0.3361) | Acc: (88.37%) (36308/41088)\n",
      "Epoch: 36 | Batch_idx: 330 |  Loss: (0.3362) | Acc: (88.36%) (37438/42368)\n",
      "Epoch: 36 | Batch_idx: 340 |  Loss: (0.3364) | Acc: (88.34%) (38558/43648)\n",
      "Epoch: 36 | Batch_idx: 350 |  Loss: (0.3351) | Acc: (88.38%) (39709/44928)\n",
      "Epoch: 36 | Batch_idx: 360 |  Loss: (0.3354) | Acc: (88.39%) (40844/46208)\n",
      "Epoch: 36 | Batch_idx: 370 |  Loss: (0.3348) | Acc: (88.41%) (41983/47488)\n",
      "Epoch: 36 | Batch_idx: 380 |  Loss: (0.3350) | Acc: (88.41%) (43114/48768)\n",
      "Epoch: 36 | Batch_idx: 390 |  Loss: (0.3349) | Acc: (88.41%) (44205/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6251) | Acc: (80.62%) (8062/10000)\n",
      "Epoch: 37 | Batch_idx: 0 |  Loss: (0.3917) | Acc: (89.06%) (114/128)\n",
      "Epoch: 37 | Batch_idx: 10 |  Loss: (0.3271) | Acc: (88.28%) (1243/1408)\n",
      "Epoch: 37 | Batch_idx: 20 |  Loss: (0.3111) | Acc: (89.03%) (2393/2688)\n",
      "Epoch: 37 | Batch_idx: 30 |  Loss: (0.3123) | Acc: (88.91%) (3528/3968)\n",
      "Epoch: 37 | Batch_idx: 40 |  Loss: (0.3128) | Acc: (89.02%) (4672/5248)\n",
      "Epoch: 37 | Batch_idx: 50 |  Loss: (0.3214) | Acc: (88.73%) (5792/6528)\n",
      "Epoch: 37 | Batch_idx: 60 |  Loss: (0.3213) | Acc: (88.67%) (6923/7808)\n",
      "Epoch: 37 | Batch_idx: 70 |  Loss: (0.3200) | Acc: (88.66%) (8057/9088)\n",
      "Epoch: 37 | Batch_idx: 80 |  Loss: (0.3213) | Acc: (88.67%) (9193/10368)\n",
      "Epoch: 37 | Batch_idx: 90 |  Loss: (0.3194) | Acc: (88.69%) (10331/11648)\n",
      "Epoch: 37 | Batch_idx: 100 |  Loss: (0.3194) | Acc: (88.65%) (11461/12928)\n",
      "Epoch: 37 | Batch_idx: 110 |  Loss: (0.3208) | Acc: (88.67%) (12598/14208)\n",
      "Epoch: 37 | Batch_idx: 120 |  Loss: (0.3219) | Acc: (88.64%) (13728/15488)\n",
      "Epoch: 37 | Batch_idx: 130 |  Loss: (0.3227) | Acc: (88.63%) (14862/16768)\n",
      "Epoch: 37 | Batch_idx: 140 |  Loss: (0.3220) | Acc: (88.67%) (16004/18048)\n",
      "Epoch: 37 | Batch_idx: 150 |  Loss: (0.3247) | Acc: (88.60%) (17124/19328)\n",
      "Epoch: 37 | Batch_idx: 160 |  Loss: (0.3275) | Acc: (88.44%) (18225/20608)\n",
      "Epoch: 37 | Batch_idx: 170 |  Loss: (0.3283) | Acc: (88.41%) (19352/21888)\n",
      "Epoch: 37 | Batch_idx: 180 |  Loss: (0.3281) | Acc: (88.42%) (20484/23168)\n",
      "Epoch: 37 | Batch_idx: 190 |  Loss: (0.3270) | Acc: (88.44%) (21623/24448)\n",
      "Epoch: 37 | Batch_idx: 200 |  Loss: (0.3273) | Acc: (88.45%) (22756/25728)\n",
      "Epoch: 37 | Batch_idx: 210 |  Loss: (0.3277) | Acc: (88.44%) (23887/27008)\n",
      "Epoch: 37 | Batch_idx: 220 |  Loss: (0.3261) | Acc: (88.56%) (25051/28288)\n",
      "Epoch: 37 | Batch_idx: 230 |  Loss: (0.3257) | Acc: (88.58%) (26190/29568)\n",
      "Epoch: 37 | Batch_idx: 240 |  Loss: (0.3268) | Acc: (88.51%) (27304/30848)\n",
      "Epoch: 37 | Batch_idx: 250 |  Loss: (0.3266) | Acc: (88.51%) (28436/32128)\n",
      "Epoch: 37 | Batch_idx: 260 |  Loss: (0.3272) | Acc: (88.48%) (29559/33408)\n",
      "Epoch: 37 | Batch_idx: 270 |  Loss: (0.3275) | Acc: (88.51%) (30703/34688)\n",
      "Epoch: 37 | Batch_idx: 280 |  Loss: (0.3275) | Acc: (88.53%) (31841/35968)\n",
      "Epoch: 37 | Batch_idx: 290 |  Loss: (0.3268) | Acc: (88.55%) (32983/37248)\n",
      "Epoch: 37 | Batch_idx: 300 |  Loss: (0.3267) | Acc: (88.58%) (34127/38528)\n",
      "Epoch: 37 | Batch_idx: 310 |  Loss: (0.3270) | Acc: (88.57%) (35258/39808)\n",
      "Epoch: 37 | Batch_idx: 320 |  Loss: (0.3271) | Acc: (88.58%) (36396/41088)\n",
      "Epoch: 37 | Batch_idx: 330 |  Loss: (0.3275) | Acc: (88.55%) (37518/42368)\n",
      "Epoch: 37 | Batch_idx: 340 |  Loss: (0.3275) | Acc: (88.56%) (38654/43648)\n",
      "Epoch: 37 | Batch_idx: 350 |  Loss: (0.3279) | Acc: (88.55%) (39782/44928)\n",
      "Epoch: 37 | Batch_idx: 360 |  Loss: (0.3280) | Acc: (88.54%) (40911/46208)\n",
      "Epoch: 37 | Batch_idx: 370 |  Loss: (0.3282) | Acc: (88.54%) (42046/47488)\n",
      "Epoch: 37 | Batch_idx: 380 |  Loss: (0.3280) | Acc: (88.56%) (43191/48768)\n",
      "Epoch: 37 | Batch_idx: 390 |  Loss: (0.3276) | Acc: (88.56%) (44281/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4894) | Acc: (83.77%) (8377/10000)\n",
      "Epoch: 38 | Batch_idx: 0 |  Loss: (0.3516) | Acc: (85.94%) (110/128)\n",
      "Epoch: 38 | Batch_idx: 10 |  Loss: (0.3307) | Acc: (88.57%) (1247/1408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Batch_idx: 20 |  Loss: (0.3251) | Acc: (88.28%) (2373/2688)\n",
      "Epoch: 38 | Batch_idx: 30 |  Loss: (0.3228) | Acc: (88.43%) (3509/3968)\n",
      "Epoch: 38 | Batch_idx: 40 |  Loss: (0.3217) | Acc: (88.70%) (4655/5248)\n",
      "Epoch: 38 | Batch_idx: 50 |  Loss: (0.3209) | Acc: (88.77%) (5795/6528)\n",
      "Epoch: 38 | Batch_idx: 60 |  Loss: (0.3174) | Acc: (88.77%) (6931/7808)\n",
      "Epoch: 38 | Batch_idx: 70 |  Loss: (0.3200) | Acc: (88.72%) (8063/9088)\n",
      "Epoch: 38 | Batch_idx: 80 |  Loss: (0.3175) | Acc: (88.87%) (9214/10368)\n",
      "Epoch: 38 | Batch_idx: 90 |  Loss: (0.3156) | Acc: (88.93%) (10358/11648)\n",
      "Epoch: 38 | Batch_idx: 100 |  Loss: (0.3181) | Acc: (88.81%) (11482/12928)\n",
      "Epoch: 38 | Batch_idx: 110 |  Loss: (0.3181) | Acc: (88.81%) (12618/14208)\n",
      "Epoch: 38 | Batch_idx: 120 |  Loss: (0.3172) | Acc: (88.86%) (13762/15488)\n",
      "Epoch: 38 | Batch_idx: 130 |  Loss: (0.3167) | Acc: (88.85%) (14899/16768)\n",
      "Epoch: 38 | Batch_idx: 140 |  Loss: (0.3174) | Acc: (88.85%) (16035/18048)\n",
      "Epoch: 38 | Batch_idx: 150 |  Loss: (0.3171) | Acc: (88.86%) (17175/19328)\n",
      "Epoch: 38 | Batch_idx: 160 |  Loss: (0.3190) | Acc: (88.83%) (18306/20608)\n",
      "Epoch: 38 | Batch_idx: 170 |  Loss: (0.3171) | Acc: (88.88%) (19455/21888)\n",
      "Epoch: 38 | Batch_idx: 180 |  Loss: (0.3182) | Acc: (88.88%) (20592/23168)\n",
      "Epoch: 38 | Batch_idx: 190 |  Loss: (0.3183) | Acc: (88.90%) (21735/24448)\n",
      "Epoch: 38 | Batch_idx: 200 |  Loss: (0.3199) | Acc: (88.84%) (22856/25728)\n",
      "Epoch: 38 | Batch_idx: 210 |  Loss: (0.3175) | Acc: (88.94%) (24020/27008)\n",
      "Epoch: 38 | Batch_idx: 220 |  Loss: (0.3177) | Acc: (88.96%) (25164/28288)\n",
      "Epoch: 38 | Batch_idx: 230 |  Loss: (0.3189) | Acc: (88.92%) (26293/29568)\n",
      "Epoch: 38 | Batch_idx: 240 |  Loss: (0.3186) | Acc: (88.92%) (27429/30848)\n",
      "Epoch: 38 | Batch_idx: 250 |  Loss: (0.3205) | Acc: (88.85%) (28547/32128)\n",
      "Epoch: 38 | Batch_idx: 260 |  Loss: (0.3221) | Acc: (88.80%) (29665/33408)\n",
      "Epoch: 38 | Batch_idx: 270 |  Loss: (0.3215) | Acc: (88.79%) (30798/34688)\n",
      "Epoch: 38 | Batch_idx: 280 |  Loss: (0.3209) | Acc: (88.80%) (31940/35968)\n",
      "Epoch: 38 | Batch_idx: 290 |  Loss: (0.3208) | Acc: (88.76%) (33062/37248)\n",
      "Epoch: 38 | Batch_idx: 300 |  Loss: (0.3215) | Acc: (88.75%) (34193/38528)\n",
      "Epoch: 38 | Batch_idx: 310 |  Loss: (0.3220) | Acc: (88.72%) (35318/39808)\n",
      "Epoch: 38 | Batch_idx: 320 |  Loss: (0.3221) | Acc: (88.71%) (36449/41088)\n",
      "Epoch: 38 | Batch_idx: 330 |  Loss: (0.3225) | Acc: (88.73%) (37592/42368)\n",
      "Epoch: 38 | Batch_idx: 340 |  Loss: (0.3228) | Acc: (88.70%) (38715/43648)\n",
      "Epoch: 38 | Batch_idx: 350 |  Loss: (0.3225) | Acc: (88.70%) (39851/44928)\n",
      "Epoch: 38 | Batch_idx: 360 |  Loss: (0.3224) | Acc: (88.72%) (40994/46208)\n",
      "Epoch: 38 | Batch_idx: 370 |  Loss: (0.3229) | Acc: (88.71%) (42126/47488)\n",
      "Epoch: 38 | Batch_idx: 380 |  Loss: (0.3228) | Acc: (88.71%) (43263/48768)\n",
      "Epoch: 38 | Batch_idx: 390 |  Loss: (0.3216) | Acc: (88.76%) (44378/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4863) | Acc: (84.31%) (8431/10000)\n",
      "Epoch: 39 | Batch_idx: 0 |  Loss: (0.2579) | Acc: (92.19%) (118/128)\n",
      "Epoch: 39 | Batch_idx: 10 |  Loss: (0.3014) | Acc: (90.62%) (1276/1408)\n",
      "Epoch: 39 | Batch_idx: 20 |  Loss: (0.2890) | Acc: (90.14%) (2423/2688)\n",
      "Epoch: 39 | Batch_idx: 30 |  Loss: (0.2923) | Acc: (89.72%) (3560/3968)\n",
      "Epoch: 39 | Batch_idx: 40 |  Loss: (0.2990) | Acc: (89.79%) (4712/5248)\n",
      "Epoch: 39 | Batch_idx: 50 |  Loss: (0.3060) | Acc: (89.52%) (5844/6528)\n",
      "Epoch: 39 | Batch_idx: 60 |  Loss: (0.3077) | Acc: (89.41%) (6981/7808)\n",
      "Epoch: 39 | Batch_idx: 70 |  Loss: (0.3054) | Acc: (89.38%) (8123/9088)\n",
      "Epoch: 39 | Batch_idx: 80 |  Loss: (0.3095) | Acc: (89.17%) (9245/10368)\n",
      "Epoch: 39 | Batch_idx: 90 |  Loss: (0.3105) | Acc: (89.09%) (10377/11648)\n",
      "Epoch: 39 | Batch_idx: 100 |  Loss: (0.3158) | Acc: (88.88%) (11491/12928)\n",
      "Epoch: 39 | Batch_idx: 110 |  Loss: (0.3164) | Acc: (88.84%) (12623/14208)\n",
      "Epoch: 39 | Batch_idx: 120 |  Loss: (0.3161) | Acc: (88.86%) (13762/15488)\n",
      "Epoch: 39 | Batch_idx: 130 |  Loss: (0.3180) | Acc: (88.86%) (14900/16768)\n",
      "Epoch: 39 | Batch_idx: 140 |  Loss: (0.3206) | Acc: (88.74%) (16015/18048)\n",
      "Epoch: 39 | Batch_idx: 150 |  Loss: (0.3199) | Acc: (88.76%) (17156/19328)\n",
      "Epoch: 39 | Batch_idx: 160 |  Loss: (0.3198) | Acc: (88.77%) (18294/20608)\n",
      "Epoch: 39 | Batch_idx: 170 |  Loss: (0.3204) | Acc: (88.85%) (19447/21888)\n",
      "Epoch: 39 | Batch_idx: 180 |  Loss: (0.3189) | Acc: (88.89%) (20594/23168)\n",
      "Epoch: 39 | Batch_idx: 190 |  Loss: (0.3191) | Acc: (88.94%) (21744/24448)\n",
      "Epoch: 39 | Batch_idx: 200 |  Loss: (0.3170) | Acc: (89.07%) (22916/25728)\n",
      "Epoch: 39 | Batch_idx: 210 |  Loss: (0.3144) | Acc: (89.18%) (24085/27008)\n",
      "Epoch: 39 | Batch_idx: 220 |  Loss: (0.3130) | Acc: (89.22%) (25239/28288)\n",
      "Epoch: 39 | Batch_idx: 230 |  Loss: (0.3141) | Acc: (89.18%) (26369/29568)\n",
      "Epoch: 39 | Batch_idx: 240 |  Loss: (0.3138) | Acc: (89.17%) (27508/30848)\n",
      "Epoch: 39 | Batch_idx: 250 |  Loss: (0.3149) | Acc: (89.11%) (28630/32128)\n",
      "Epoch: 39 | Batch_idx: 260 |  Loss: (0.3145) | Acc: (89.18%) (29792/33408)\n",
      "Epoch: 39 | Batch_idx: 270 |  Loss: (0.3136) | Acc: (89.19%) (30939/34688)\n",
      "Epoch: 39 | Batch_idx: 280 |  Loss: (0.3145) | Acc: (89.16%) (32068/35968)\n",
      "Epoch: 39 | Batch_idx: 290 |  Loss: (0.3146) | Acc: (89.16%) (33212/37248)\n",
      "Epoch: 39 | Batch_idx: 300 |  Loss: (0.3155) | Acc: (89.10%) (34330/38528)\n",
      "Epoch: 39 | Batch_idx: 310 |  Loss: (0.3151) | Acc: (89.10%) (35468/39808)\n",
      "Epoch: 39 | Batch_idx: 320 |  Loss: (0.3146) | Acc: (89.09%) (36607/41088)\n",
      "Epoch: 39 | Batch_idx: 330 |  Loss: (0.3144) | Acc: (89.10%) (37752/42368)\n",
      "Epoch: 39 | Batch_idx: 340 |  Loss: (0.3135) | Acc: (89.11%) (38894/43648)\n",
      "Epoch: 39 | Batch_idx: 350 |  Loss: (0.3144) | Acc: (89.07%) (40017/44928)\n",
      "Epoch: 39 | Batch_idx: 360 |  Loss: (0.3148) | Acc: (89.07%) (41156/46208)\n",
      "Epoch: 39 | Batch_idx: 370 |  Loss: (0.3143) | Acc: (89.06%) (42295/47488)\n",
      "Epoch: 39 | Batch_idx: 380 |  Loss: (0.3140) | Acc: (89.07%) (43438/48768)\n",
      "Epoch: 39 | Batch_idx: 390 |  Loss: (0.3137) | Acc: (89.07%) (44534/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5087) | Acc: (83.44%) (8344/10000)\n",
      "Epoch: 40 | Batch_idx: 0 |  Loss: (0.2500) | Acc: (92.19%) (118/128)\n",
      "Epoch: 40 | Batch_idx: 10 |  Loss: (0.3044) | Acc: (88.92%) (1252/1408)\n",
      "Epoch: 40 | Batch_idx: 20 |  Loss: (0.3101) | Acc: (88.80%) (2387/2688)\n",
      "Epoch: 40 | Batch_idx: 30 |  Loss: (0.3010) | Acc: (89.16%) (3538/3968)\n",
      "Epoch: 40 | Batch_idx: 40 |  Loss: (0.2990) | Acc: (89.25%) (4684/5248)\n",
      "Epoch: 40 | Batch_idx: 50 |  Loss: (0.3028) | Acc: (89.17%) (5821/6528)\n",
      "Epoch: 40 | Batch_idx: 60 |  Loss: (0.3090) | Acc: (89.02%) (6951/7808)\n",
      "Epoch: 40 | Batch_idx: 70 |  Loss: (0.3065) | Acc: (89.11%) (8098/9088)\n",
      "Epoch: 40 | Batch_idx: 80 |  Loss: (0.3051) | Acc: (89.13%) (9241/10368)\n",
      "Epoch: 40 | Batch_idx: 90 |  Loss: (0.3042) | Acc: (89.26%) (10397/11648)\n",
      "Epoch: 40 | Batch_idx: 100 |  Loss: (0.3056) | Acc: (89.22%) (11535/12928)\n",
      "Epoch: 40 | Batch_idx: 110 |  Loss: (0.3068) | Acc: (89.21%) (12675/14208)\n",
      "Epoch: 40 | Batch_idx: 120 |  Loss: (0.3041) | Acc: (89.29%) (13829/15488)\n",
      "Epoch: 40 | Batch_idx: 130 |  Loss: (0.3031) | Acc: (89.32%) (14977/16768)\n",
      "Epoch: 40 | Batch_idx: 140 |  Loss: (0.3047) | Acc: (89.30%) (16116/18048)\n",
      "Epoch: 40 | Batch_idx: 150 |  Loss: (0.3068) | Acc: (89.19%) (17239/19328)\n",
      "Epoch: 40 | Batch_idx: 160 |  Loss: (0.3071) | Acc: (89.18%) (18379/20608)\n",
      "Epoch: 40 | Batch_idx: 170 |  Loss: (0.3064) | Acc: (89.19%) (19523/21888)\n",
      "Epoch: 40 | Batch_idx: 180 |  Loss: (0.3083) | Acc: (89.17%) (20658/23168)\n",
      "Epoch: 40 | Batch_idx: 190 |  Loss: (0.3088) | Acc: (89.11%) (21786/24448)\n",
      "Epoch: 40 | Batch_idx: 200 |  Loss: (0.3073) | Acc: (89.19%) (22947/25728)\n",
      "Epoch: 40 | Batch_idx: 210 |  Loss: (0.3059) | Acc: (89.31%) (24120/27008)\n",
      "Epoch: 40 | Batch_idx: 220 |  Loss: (0.3074) | Acc: (89.23%) (25242/28288)\n",
      "Epoch: 40 | Batch_idx: 230 |  Loss: (0.3090) | Acc: (89.19%) (26372/29568)\n",
      "Epoch: 40 | Batch_idx: 240 |  Loss: (0.3100) | Acc: (89.13%) (27496/30848)\n",
      "Epoch: 40 | Batch_idx: 250 |  Loss: (0.3104) | Acc: (89.13%) (28635/32128)\n",
      "Epoch: 40 | Batch_idx: 260 |  Loss: (0.3104) | Acc: (89.13%) (29778/33408)\n",
      "Epoch: 40 | Batch_idx: 270 |  Loss: (0.3104) | Acc: (89.15%) (30924/34688)\n",
      "Epoch: 40 | Batch_idx: 280 |  Loss: (0.3093) | Acc: (89.22%) (32089/35968)\n",
      "Epoch: 40 | Batch_idx: 290 |  Loss: (0.3097) | Acc: (89.18%) (33218/37248)\n",
      "Epoch: 40 | Batch_idx: 300 |  Loss: (0.3086) | Acc: (89.22%) (34373/38528)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Batch_idx: 310 |  Loss: (0.3079) | Acc: (89.25%) (35528/39808)\n",
      "Epoch: 40 | Batch_idx: 320 |  Loss: (0.3091) | Acc: (89.19%) (36646/41088)\n",
      "Epoch: 40 | Batch_idx: 330 |  Loss: (0.3090) | Acc: (89.21%) (37798/42368)\n",
      "Epoch: 40 | Batch_idx: 340 |  Loss: (0.3093) | Acc: (89.22%) (38944/43648)\n",
      "Epoch: 40 | Batch_idx: 350 |  Loss: (0.3089) | Acc: (89.24%) (40094/44928)\n",
      "Epoch: 40 | Batch_idx: 360 |  Loss: (0.3095) | Acc: (89.24%) (41235/46208)\n",
      "Epoch: 40 | Batch_idx: 370 |  Loss: (0.3091) | Acc: (89.27%) (42394/47488)\n",
      "Epoch: 40 | Batch_idx: 380 |  Loss: (0.3096) | Acc: (89.27%) (43534/48768)\n",
      "Epoch: 40 | Batch_idx: 390 |  Loss: (0.3093) | Acc: (89.28%) (44642/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5037) | Acc: (83.91%) (8391/10000)\n",
      "Epoch: 41 | Batch_idx: 0 |  Loss: (0.2569) | Acc: (89.84%) (115/128)\n",
      "Epoch: 41 | Batch_idx: 10 |  Loss: (0.2966) | Acc: (90.41%) (1273/1408)\n",
      "Epoch: 41 | Batch_idx: 20 |  Loss: (0.2861) | Acc: (90.14%) (2423/2688)\n",
      "Epoch: 41 | Batch_idx: 30 |  Loss: (0.2893) | Acc: (89.69%) (3559/3968)\n",
      "Epoch: 41 | Batch_idx: 40 |  Loss: (0.2942) | Acc: (89.44%) (4694/5248)\n",
      "Epoch: 41 | Batch_idx: 50 |  Loss: (0.2997) | Acc: (89.45%) (5839/6528)\n",
      "Epoch: 41 | Batch_idx: 60 |  Loss: (0.2968) | Acc: (89.50%) (6988/7808)\n",
      "Epoch: 41 | Batch_idx: 70 |  Loss: (0.2978) | Acc: (89.44%) (8128/9088)\n",
      "Epoch: 41 | Batch_idx: 80 |  Loss: (0.2936) | Acc: (89.68%) (9298/10368)\n",
      "Epoch: 41 | Batch_idx: 90 |  Loss: (0.2943) | Acc: (89.68%) (10446/11648)\n",
      "Epoch: 41 | Batch_idx: 100 |  Loss: (0.2909) | Acc: (89.75%) (11603/12928)\n",
      "Epoch: 41 | Batch_idx: 110 |  Loss: (0.2962) | Acc: (89.59%) (12729/14208)\n",
      "Epoch: 41 | Batch_idx: 120 |  Loss: (0.2969) | Acc: (89.57%) (13873/15488)\n",
      "Epoch: 41 | Batch_idx: 130 |  Loss: (0.2971) | Acc: (89.55%) (15015/16768)\n",
      "Epoch: 41 | Batch_idx: 140 |  Loss: (0.2973) | Acc: (89.48%) (16150/18048)\n",
      "Epoch: 41 | Batch_idx: 150 |  Loss: (0.2960) | Acc: (89.61%) (17320/19328)\n",
      "Epoch: 41 | Batch_idx: 160 |  Loss: (0.2961) | Acc: (89.61%) (18467/20608)\n",
      "Epoch: 41 | Batch_idx: 170 |  Loss: (0.2969) | Acc: (89.63%) (19619/21888)\n",
      "Epoch: 41 | Batch_idx: 180 |  Loss: (0.2972) | Acc: (89.64%) (20767/23168)\n",
      "Epoch: 41 | Batch_idx: 190 |  Loss: (0.2955) | Acc: (89.71%) (21933/24448)\n",
      "Epoch: 41 | Batch_idx: 200 |  Loss: (0.2969) | Acc: (89.66%) (23069/25728)\n",
      "Epoch: 41 | Batch_idx: 210 |  Loss: (0.2977) | Acc: (89.67%) (24218/27008)\n",
      "Epoch: 41 | Batch_idx: 220 |  Loss: (0.2990) | Acc: (89.68%) (25368/28288)\n",
      "Epoch: 41 | Batch_idx: 230 |  Loss: (0.3008) | Acc: (89.55%) (26479/29568)\n",
      "Epoch: 41 | Batch_idx: 240 |  Loss: (0.2999) | Acc: (89.60%) (27641/30848)\n",
      "Epoch: 41 | Batch_idx: 250 |  Loss: (0.3003) | Acc: (89.62%) (28792/32128)\n",
      "Epoch: 41 | Batch_idx: 260 |  Loss: (0.3004) | Acc: (89.64%) (29947/33408)\n",
      "Epoch: 41 | Batch_idx: 270 |  Loss: (0.3006) | Acc: (89.65%) (31099/34688)\n",
      "Epoch: 41 | Batch_idx: 280 |  Loss: (0.3009) | Acc: (89.64%) (32243/35968)\n",
      "Epoch: 41 | Batch_idx: 290 |  Loss: (0.3007) | Acc: (89.66%) (33395/37248)\n",
      "Epoch: 41 | Batch_idx: 300 |  Loss: (0.3005) | Acc: (89.65%) (34539/38528)\n",
      "Epoch: 41 | Batch_idx: 310 |  Loss: (0.3009) | Acc: (89.63%) (35680/39808)\n",
      "Epoch: 41 | Batch_idx: 320 |  Loss: (0.3017) | Acc: (89.61%) (36820/41088)\n",
      "Epoch: 41 | Batch_idx: 330 |  Loss: (0.3014) | Acc: (89.63%) (37976/42368)\n",
      "Epoch: 41 | Batch_idx: 340 |  Loss: (0.3025) | Acc: (89.60%) (39109/43648)\n",
      "Epoch: 41 | Batch_idx: 350 |  Loss: (0.3022) | Acc: (89.61%) (40259/44928)\n",
      "Epoch: 41 | Batch_idx: 360 |  Loss: (0.3017) | Acc: (89.62%) (41413/46208)\n",
      "Epoch: 41 | Batch_idx: 370 |  Loss: (0.3011) | Acc: (89.65%) (42573/47488)\n",
      "Epoch: 41 | Batch_idx: 380 |  Loss: (0.3019) | Acc: (89.60%) (43696/48768)\n",
      "Epoch: 41 | Batch_idx: 390 |  Loss: (0.3016) | Acc: (89.62%) (44810/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5644) | Acc: (82.73%) (8273/10000)\n",
      "Epoch: 42 | Batch_idx: 0 |  Loss: (0.3252) | Acc: (87.50%) (112/128)\n",
      "Epoch: 42 | Batch_idx: 10 |  Loss: (0.3171) | Acc: (88.92%) (1252/1408)\n",
      "Epoch: 42 | Batch_idx: 20 |  Loss: (0.2980) | Acc: (89.81%) (2414/2688)\n",
      "Epoch: 42 | Batch_idx: 30 |  Loss: (0.2880) | Acc: (90.22%) (3580/3968)\n",
      "Epoch: 42 | Batch_idx: 40 |  Loss: (0.2930) | Acc: (89.65%) (4705/5248)\n",
      "Epoch: 42 | Batch_idx: 50 |  Loss: (0.2903) | Acc: (89.86%) (5866/6528)\n",
      "Epoch: 42 | Batch_idx: 60 |  Loss: (0.2918) | Acc: (89.88%) (7018/7808)\n",
      "Epoch: 42 | Batch_idx: 70 |  Loss: (0.2908) | Acc: (89.88%) (8168/9088)\n",
      "Epoch: 42 | Batch_idx: 80 |  Loss: (0.2916) | Acc: (89.84%) (9315/10368)\n",
      "Epoch: 42 | Batch_idx: 90 |  Loss: (0.2903) | Acc: (89.92%) (10474/11648)\n",
      "Epoch: 42 | Batch_idx: 100 |  Loss: (0.2904) | Acc: (89.82%) (11612/12928)\n",
      "Epoch: 42 | Batch_idx: 110 |  Loss: (0.2888) | Acc: (89.87%) (12769/14208)\n",
      "Epoch: 42 | Batch_idx: 120 |  Loss: (0.2882) | Acc: (89.86%) (13917/15488)\n",
      "Epoch: 42 | Batch_idx: 130 |  Loss: (0.2907) | Acc: (89.75%) (15050/16768)\n",
      "Epoch: 42 | Batch_idx: 140 |  Loss: (0.2899) | Acc: (89.77%) (16202/18048)\n",
      "Epoch: 42 | Batch_idx: 150 |  Loss: (0.2886) | Acc: (89.82%) (17361/19328)\n",
      "Epoch: 42 | Batch_idx: 160 |  Loss: (0.2896) | Acc: (89.75%) (18496/20608)\n",
      "Epoch: 42 | Batch_idx: 170 |  Loss: (0.2884) | Acc: (89.83%) (19661/21888)\n",
      "Epoch: 42 | Batch_idx: 180 |  Loss: (0.2904) | Acc: (89.74%) (20792/23168)\n",
      "Epoch: 42 | Batch_idx: 190 |  Loss: (0.2902) | Acc: (89.76%) (21944/24448)\n",
      "Epoch: 42 | Batch_idx: 200 |  Loss: (0.2891) | Acc: (89.82%) (23108/25728)\n",
      "Epoch: 42 | Batch_idx: 210 |  Loss: (0.2896) | Acc: (89.82%) (24258/27008)\n",
      "Epoch: 42 | Batch_idx: 220 |  Loss: (0.2904) | Acc: (89.80%) (25402/28288)\n",
      "Epoch: 42 | Batch_idx: 230 |  Loss: (0.2908) | Acc: (89.81%) (26554/29568)\n",
      "Epoch: 42 | Batch_idx: 240 |  Loss: (0.2920) | Acc: (89.75%) (27686/30848)\n",
      "Epoch: 42 | Batch_idx: 250 |  Loss: (0.2920) | Acc: (89.76%) (28837/32128)\n",
      "Epoch: 42 | Batch_idx: 260 |  Loss: (0.2931) | Acc: (89.75%) (29983/33408)\n",
      "Epoch: 42 | Batch_idx: 270 |  Loss: (0.2945) | Acc: (89.70%) (31114/34688)\n",
      "Epoch: 42 | Batch_idx: 280 |  Loss: (0.2955) | Acc: (89.67%) (32252/35968)\n",
      "Epoch: 42 | Batch_idx: 290 |  Loss: (0.2949) | Acc: (89.66%) (33397/37248)\n",
      "Epoch: 42 | Batch_idx: 300 |  Loss: (0.2957) | Acc: (89.64%) (34536/38528)\n",
      "Epoch: 42 | Batch_idx: 310 |  Loss: (0.2958) | Acc: (89.65%) (35686/39808)\n",
      "Epoch: 42 | Batch_idx: 320 |  Loss: (0.2950) | Acc: (89.70%) (36855/41088)\n",
      "Epoch: 42 | Batch_idx: 330 |  Loss: (0.2946) | Acc: (89.72%) (38013/42368)\n",
      "Epoch: 42 | Batch_idx: 340 |  Loss: (0.2942) | Acc: (89.75%) (39173/43648)\n",
      "Epoch: 42 | Batch_idx: 350 |  Loss: (0.2951) | Acc: (89.73%) (40315/44928)\n",
      "Epoch: 42 | Batch_idx: 360 |  Loss: (0.2948) | Acc: (89.73%) (41464/46208)\n",
      "Epoch: 42 | Batch_idx: 370 |  Loss: (0.2948) | Acc: (89.72%) (42606/47488)\n",
      "Epoch: 42 | Batch_idx: 380 |  Loss: (0.2950) | Acc: (89.71%) (43750/48768)\n",
      "Epoch: 42 | Batch_idx: 390 |  Loss: (0.2948) | Acc: (89.70%) (44851/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5041) | Acc: (83.93%) (8393/10000)\n",
      "Epoch: 43 | Batch_idx: 0 |  Loss: (0.3152) | Acc: (85.94%) (110/128)\n",
      "Epoch: 43 | Batch_idx: 10 |  Loss: (0.2631) | Acc: (90.98%) (1281/1408)\n",
      "Epoch: 43 | Batch_idx: 20 |  Loss: (0.2695) | Acc: (90.62%) (2436/2688)\n",
      "Epoch: 43 | Batch_idx: 30 |  Loss: (0.2649) | Acc: (90.83%) (3604/3968)\n",
      "Epoch: 43 | Batch_idx: 40 |  Loss: (0.2718) | Acc: (90.80%) (4765/5248)\n",
      "Epoch: 43 | Batch_idx: 50 |  Loss: (0.2782) | Acc: (90.46%) (5905/6528)\n",
      "Epoch: 43 | Batch_idx: 60 |  Loss: (0.2795) | Acc: (90.47%) (7064/7808)\n",
      "Epoch: 43 | Batch_idx: 70 |  Loss: (0.2765) | Acc: (90.50%) (8225/9088)\n",
      "Epoch: 43 | Batch_idx: 80 |  Loss: (0.2768) | Acc: (90.44%) (9377/10368)\n",
      "Epoch: 43 | Batch_idx: 90 |  Loss: (0.2793) | Acc: (90.37%) (10526/11648)\n",
      "Epoch: 43 | Batch_idx: 100 |  Loss: (0.2839) | Acc: (90.16%) (11656/12928)\n",
      "Epoch: 43 | Batch_idx: 110 |  Loss: (0.2854) | Acc: (90.08%) (12799/14208)\n",
      "Epoch: 43 | Batch_idx: 120 |  Loss: (0.2834) | Acc: (90.15%) (13963/15488)\n",
      "Epoch: 43 | Batch_idx: 130 |  Loss: (0.2843) | Acc: (90.08%) (15104/16768)\n",
      "Epoch: 43 | Batch_idx: 140 |  Loss: (0.2820) | Acc: (90.11%) (16263/18048)\n",
      "Epoch: 43 | Batch_idx: 150 |  Loss: (0.2800) | Acc: (90.22%) (17437/19328)\n",
      "Epoch: 43 | Batch_idx: 160 |  Loss: (0.2801) | Acc: (90.24%) (18596/20608)\n",
      "Epoch: 43 | Batch_idx: 170 |  Loss: (0.2794) | Acc: (90.28%) (19760/21888)\n",
      "Epoch: 43 | Batch_idx: 180 |  Loss: (0.2790) | Acc: (90.29%) (20918/23168)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Batch_idx: 190 |  Loss: (0.2796) | Acc: (90.29%) (22073/24448)\n",
      "Epoch: 43 | Batch_idx: 200 |  Loss: (0.2795) | Acc: (90.28%) (23227/25728)\n",
      "Epoch: 43 | Batch_idx: 210 |  Loss: (0.2808) | Acc: (90.27%) (24380/27008)\n",
      "Epoch: 43 | Batch_idx: 220 |  Loss: (0.2802) | Acc: (90.28%) (25538/28288)\n",
      "Epoch: 43 | Batch_idx: 230 |  Loss: (0.2797) | Acc: (90.28%) (26695/29568)\n",
      "Epoch: 43 | Batch_idx: 240 |  Loss: (0.2814) | Acc: (90.25%) (27841/30848)\n",
      "Epoch: 43 | Batch_idx: 250 |  Loss: (0.2819) | Acc: (90.24%) (28992/32128)\n",
      "Epoch: 43 | Batch_idx: 260 |  Loss: (0.2830) | Acc: (90.17%) (30124/33408)\n",
      "Epoch: 43 | Batch_idx: 270 |  Loss: (0.2837) | Acc: (90.14%) (31267/34688)\n",
      "Epoch: 43 | Batch_idx: 280 |  Loss: (0.2844) | Acc: (90.12%) (32414/35968)\n",
      "Epoch: 43 | Batch_idx: 290 |  Loss: (0.2847) | Acc: (90.12%) (33567/37248)\n",
      "Epoch: 43 | Batch_idx: 300 |  Loss: (0.2846) | Acc: (90.12%) (34722/38528)\n",
      "Epoch: 43 | Batch_idx: 310 |  Loss: (0.2842) | Acc: (90.13%) (35877/39808)\n",
      "Epoch: 43 | Batch_idx: 320 |  Loss: (0.2843) | Acc: (90.12%) (37028/41088)\n",
      "Epoch: 43 | Batch_idx: 330 |  Loss: (0.2846) | Acc: (90.15%) (38193/42368)\n",
      "Epoch: 43 | Batch_idx: 340 |  Loss: (0.2841) | Acc: (90.15%) (39347/43648)\n",
      "Epoch: 43 | Batch_idx: 350 |  Loss: (0.2844) | Acc: (90.13%) (40495/44928)\n",
      "Epoch: 43 | Batch_idx: 360 |  Loss: (0.2863) | Acc: (90.08%) (41625/46208)\n",
      "Epoch: 43 | Batch_idx: 370 |  Loss: (0.2859) | Acc: (90.11%) (42793/47488)\n",
      "Epoch: 43 | Batch_idx: 380 |  Loss: (0.2872) | Acc: (90.10%) (43941/48768)\n",
      "Epoch: 43 | Batch_idx: 390 |  Loss: (0.2870) | Acc: (90.11%) (45056/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5799) | Acc: (82.20%) (8220/10000)\n",
      "Epoch: 44 | Batch_idx: 0 |  Loss: (0.2533) | Acc: (91.41%) (117/128)\n",
      "Epoch: 44 | Batch_idx: 10 |  Loss: (0.2938) | Acc: (89.77%) (1264/1408)\n",
      "Epoch: 44 | Batch_idx: 20 |  Loss: (0.2843) | Acc: (90.25%) (2426/2688)\n",
      "Epoch: 44 | Batch_idx: 30 |  Loss: (0.2695) | Acc: (90.68%) (3598/3968)\n",
      "Epoch: 44 | Batch_idx: 40 |  Loss: (0.2801) | Acc: (90.05%) (4726/5248)\n",
      "Epoch: 44 | Batch_idx: 50 |  Loss: (0.2806) | Acc: (90.13%) (5884/6528)\n",
      "Epoch: 44 | Batch_idx: 60 |  Loss: (0.2818) | Acc: (90.10%) (7035/7808)\n",
      "Epoch: 44 | Batch_idx: 70 |  Loss: (0.2823) | Acc: (90.07%) (8186/9088)\n",
      "Epoch: 44 | Batch_idx: 80 |  Loss: (0.2811) | Acc: (90.16%) (9348/10368)\n",
      "Epoch: 44 | Batch_idx: 90 |  Loss: (0.2833) | Acc: (90.14%) (10500/11648)\n",
      "Epoch: 44 | Batch_idx: 100 |  Loss: (0.2833) | Acc: (90.13%) (11652/12928)\n",
      "Epoch: 44 | Batch_idx: 110 |  Loss: (0.2811) | Acc: (90.31%) (12831/14208)\n",
      "Epoch: 44 | Batch_idx: 120 |  Loss: (0.2818) | Acc: (90.28%) (13982/15488)\n",
      "Epoch: 44 | Batch_idx: 130 |  Loss: (0.2831) | Acc: (90.23%) (15129/16768)\n",
      "Epoch: 44 | Batch_idx: 140 |  Loss: (0.2830) | Acc: (90.23%) (16284/18048)\n",
      "Epoch: 44 | Batch_idx: 150 |  Loss: (0.2824) | Acc: (90.23%) (17440/19328)\n",
      "Epoch: 44 | Batch_idx: 160 |  Loss: (0.2843) | Acc: (90.20%) (18589/20608)\n",
      "Epoch: 44 | Batch_idx: 170 |  Loss: (0.2858) | Acc: (90.16%) (19734/21888)\n",
      "Epoch: 44 | Batch_idx: 180 |  Loss: (0.2845) | Acc: (90.24%) (20907/23168)\n",
      "Epoch: 44 | Batch_idx: 190 |  Loss: (0.2839) | Acc: (90.29%) (22074/24448)\n",
      "Epoch: 44 | Batch_idx: 200 |  Loss: (0.2847) | Acc: (90.25%) (23220/25728)\n",
      "Epoch: 44 | Batch_idx: 210 |  Loss: (0.2842) | Acc: (90.31%) (24392/27008)\n",
      "Epoch: 44 | Batch_idx: 220 |  Loss: (0.2834) | Acc: (90.36%) (25561/28288)\n",
      "Epoch: 44 | Batch_idx: 230 |  Loss: (0.2839) | Acc: (90.33%) (26710/29568)\n",
      "Epoch: 44 | Batch_idx: 240 |  Loss: (0.2836) | Acc: (90.33%) (27865/30848)\n",
      "Epoch: 44 | Batch_idx: 250 |  Loss: (0.2836) | Acc: (90.35%) (29027/32128)\n",
      "Epoch: 44 | Batch_idx: 260 |  Loss: (0.2826) | Acc: (90.36%) (30187/33408)\n",
      "Epoch: 44 | Batch_idx: 270 |  Loss: (0.2822) | Acc: (90.41%) (31361/34688)\n",
      "Epoch: 44 | Batch_idx: 280 |  Loss: (0.2812) | Acc: (90.45%) (32532/35968)\n",
      "Epoch: 44 | Batch_idx: 290 |  Loss: (0.2805) | Acc: (90.43%) (33683/37248)\n",
      "Epoch: 44 | Batch_idx: 300 |  Loss: (0.2814) | Acc: (90.38%) (34822/38528)\n",
      "Epoch: 44 | Batch_idx: 310 |  Loss: (0.2805) | Acc: (90.40%) (35987/39808)\n",
      "Epoch: 44 | Batch_idx: 320 |  Loss: (0.2818) | Acc: (90.38%) (37134/41088)\n",
      "Epoch: 44 | Batch_idx: 330 |  Loss: (0.2815) | Acc: (90.37%) (38288/42368)\n",
      "Epoch: 44 | Batch_idx: 340 |  Loss: (0.2826) | Acc: (90.34%) (39432/43648)\n",
      "Epoch: 44 | Batch_idx: 350 |  Loss: (0.2825) | Acc: (90.36%) (40595/44928)\n",
      "Epoch: 44 | Batch_idx: 360 |  Loss: (0.2826) | Acc: (90.35%) (41750/46208)\n",
      "Epoch: 44 | Batch_idx: 370 |  Loss: (0.2810) | Acc: (90.41%) (42936/47488)\n",
      "Epoch: 44 | Batch_idx: 380 |  Loss: (0.2806) | Acc: (90.42%) (44098/48768)\n",
      "Epoch: 44 | Batch_idx: 390 |  Loss: (0.2800) | Acc: (90.43%) (45217/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5042) | Acc: (84.31%) (8431/10000)\n",
      "Epoch: 45 | Batch_idx: 0 |  Loss: (0.1912) | Acc: (93.75%) (120/128)\n",
      "Epoch: 45 | Batch_idx: 10 |  Loss: (0.2809) | Acc: (90.84%) (1279/1408)\n",
      "Epoch: 45 | Batch_idx: 20 |  Loss: (0.2752) | Acc: (90.70%) (2438/2688)\n",
      "Epoch: 45 | Batch_idx: 30 |  Loss: (0.2707) | Acc: (91.08%) (3614/3968)\n",
      "Epoch: 45 | Batch_idx: 40 |  Loss: (0.2615) | Acc: (91.27%) (4790/5248)\n",
      "Epoch: 45 | Batch_idx: 50 |  Loss: (0.2694) | Acc: (90.84%) (5930/6528)\n",
      "Epoch: 45 | Batch_idx: 60 |  Loss: (0.2676) | Acc: (90.83%) (7092/7808)\n",
      "Epoch: 45 | Batch_idx: 70 |  Loss: (0.2710) | Acc: (90.69%) (8242/9088)\n",
      "Epoch: 45 | Batch_idx: 80 |  Loss: (0.2705) | Acc: (90.68%) (9402/10368)\n",
      "Epoch: 45 | Batch_idx: 90 |  Loss: (0.2699) | Acc: (90.59%) (10552/11648)\n",
      "Epoch: 45 | Batch_idx: 100 |  Loss: (0.2674) | Acc: (90.72%) (11728/12928)\n",
      "Epoch: 45 | Batch_idx: 110 |  Loss: (0.2690) | Acc: (90.67%) (12882/14208)\n",
      "Epoch: 45 | Batch_idx: 120 |  Loss: (0.2703) | Acc: (90.61%) (14033/15488)\n",
      "Epoch: 45 | Batch_idx: 130 |  Loss: (0.2709) | Acc: (90.60%) (15192/16768)\n",
      "Epoch: 45 | Batch_idx: 140 |  Loss: (0.2719) | Acc: (90.60%) (16352/18048)\n",
      "Epoch: 45 | Batch_idx: 150 |  Loss: (0.2732) | Acc: (90.55%) (17501/19328)\n",
      "Epoch: 45 | Batch_idx: 160 |  Loss: (0.2728) | Acc: (90.52%) (18654/20608)\n",
      "Epoch: 45 | Batch_idx: 170 |  Loss: (0.2718) | Acc: (90.53%) (19816/21888)\n",
      "Epoch: 45 | Batch_idx: 180 |  Loss: (0.2731) | Acc: (90.54%) (20976/23168)\n",
      "Epoch: 45 | Batch_idx: 190 |  Loss: (0.2748) | Acc: (90.45%) (22112/24448)\n",
      "Epoch: 45 | Batch_idx: 200 |  Loss: (0.2741) | Acc: (90.49%) (23280/25728)\n",
      "Epoch: 45 | Batch_idx: 210 |  Loss: (0.2743) | Acc: (90.50%) (24443/27008)\n",
      "Epoch: 45 | Batch_idx: 220 |  Loss: (0.2758) | Acc: (90.46%) (25588/28288)\n",
      "Epoch: 45 | Batch_idx: 230 |  Loss: (0.2765) | Acc: (90.41%) (26733/29568)\n",
      "Epoch: 45 | Batch_idx: 240 |  Loss: (0.2772) | Acc: (90.39%) (27884/30848)\n",
      "Epoch: 45 | Batch_idx: 250 |  Loss: (0.2762) | Acc: (90.42%) (29051/32128)\n",
      "Epoch: 45 | Batch_idx: 260 |  Loss: (0.2767) | Acc: (90.40%) (30202/33408)\n",
      "Epoch: 45 | Batch_idx: 270 |  Loss: (0.2762) | Acc: (90.43%) (31368/34688)\n",
      "Epoch: 45 | Batch_idx: 280 |  Loss: (0.2762) | Acc: (90.43%) (32525/35968)\n",
      "Epoch: 45 | Batch_idx: 290 |  Loss: (0.2768) | Acc: (90.40%) (33671/37248)\n",
      "Epoch: 45 | Batch_idx: 300 |  Loss: (0.2766) | Acc: (90.40%) (34831/38528)\n",
      "Epoch: 45 | Batch_idx: 310 |  Loss: (0.2762) | Acc: (90.44%) (36001/39808)\n",
      "Epoch: 45 | Batch_idx: 320 |  Loss: (0.2763) | Acc: (90.45%) (37166/41088)\n",
      "Epoch: 45 | Batch_idx: 330 |  Loss: (0.2767) | Acc: (90.44%) (38317/42368)\n",
      "Epoch: 45 | Batch_idx: 340 |  Loss: (0.2768) | Acc: (90.42%) (39467/43648)\n",
      "Epoch: 45 | Batch_idx: 350 |  Loss: (0.2773) | Acc: (90.40%) (40616/44928)\n",
      "Epoch: 45 | Batch_idx: 360 |  Loss: (0.2772) | Acc: (90.36%) (41754/46208)\n",
      "Epoch: 45 | Batch_idx: 370 |  Loss: (0.2778) | Acc: (90.35%) (42906/47488)\n",
      "Epoch: 45 | Batch_idx: 380 |  Loss: (0.2775) | Acc: (90.39%) (44079/48768)\n",
      "Epoch: 45 | Batch_idx: 390 |  Loss: (0.2779) | Acc: (90.37%) (45184/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4447) | Acc: (85.82%) (8582/10000)\n",
      "Epoch: 46 | Batch_idx: 0 |  Loss: (0.2344) | Acc: (92.97%) (119/128)\n",
      "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2906) | Acc: (90.62%) (1276/1408)\n",
      "Epoch: 46 | Batch_idx: 20 |  Loss: (0.2782) | Acc: (90.48%) (2432/2688)\n",
      "Epoch: 46 | Batch_idx: 30 |  Loss: (0.2658) | Acc: (90.80%) (3603/3968)\n",
      "Epoch: 46 | Batch_idx: 40 |  Loss: (0.2620) | Acc: (90.78%) (4764/5248)\n",
      "Epoch: 46 | Batch_idx: 50 |  Loss: (0.2595) | Acc: (90.98%) (5939/6528)\n",
      "Epoch: 46 | Batch_idx: 60 |  Loss: (0.2590) | Acc: (91.15%) (7117/7808)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Batch_idx: 70 |  Loss: (0.2571) | Acc: (91.30%) (8297/9088)\n",
      "Epoch: 46 | Batch_idx: 80 |  Loss: (0.2630) | Acc: (91.05%) (9440/10368)\n",
      "Epoch: 46 | Batch_idx: 90 |  Loss: (0.2641) | Acc: (91.03%) (10603/11648)\n",
      "Epoch: 46 | Batch_idx: 100 |  Loss: (0.2651) | Acc: (90.99%) (11763/12928)\n",
      "Epoch: 46 | Batch_idx: 110 |  Loss: (0.2661) | Acc: (90.89%) (12914/14208)\n",
      "Epoch: 46 | Batch_idx: 120 |  Loss: (0.2689) | Acc: (90.75%) (14056/15488)\n",
      "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2679) | Acc: (90.79%) (15223/16768)\n",
      "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2683) | Acc: (90.77%) (16383/18048)\n",
      "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2673) | Acc: (90.81%) (17551/19328)\n",
      "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2677) | Acc: (90.79%) (18710/20608)\n",
      "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2702) | Acc: (90.70%) (19853/21888)\n",
      "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2703) | Acc: (90.69%) (21012/23168)\n",
      "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2715) | Acc: (90.62%) (22154/24448)\n",
      "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2718) | Acc: (90.57%) (23301/25728)\n",
      "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2713) | Acc: (90.60%) (24468/27008)\n",
      "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2733) | Acc: (90.55%) (25614/28288)\n",
      "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2749) | Acc: (90.50%) (26758/29568)\n",
      "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2738) | Acc: (90.55%) (27934/30848)\n",
      "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2735) | Acc: (90.60%) (29107/32128)\n",
      "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2740) | Acc: (90.57%) (30256/33408)\n",
      "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2737) | Acc: (90.57%) (31416/34688)\n",
      "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2734) | Acc: (90.56%) (32572/35968)\n",
      "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2740) | Acc: (90.51%) (33715/37248)\n",
      "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2738) | Acc: (90.54%) (34883/38528)\n",
      "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2741) | Acc: (90.51%) (36032/39808)\n",
      "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2740) | Acc: (90.51%) (37190/41088)\n",
      "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2733) | Acc: (90.51%) (38348/42368)\n",
      "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2729) | Acc: (90.50%) (39503/43648)\n",
      "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2736) | Acc: (90.48%) (40652/44928)\n",
      "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2738) | Acc: (90.46%) (41799/46208)\n",
      "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2735) | Acc: (90.45%) (42954/47488)\n",
      "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2738) | Acc: (90.45%) (44112/48768)\n",
      "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2735) | Acc: (90.46%) (45230/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4973) | Acc: (84.70%) (8470/10000)\n",
      "Epoch: 47 | Batch_idx: 0 |  Loss: (0.2395) | Acc: (92.19%) (118/128)\n",
      "Epoch: 47 | Batch_idx: 10 |  Loss: (0.2536) | Acc: (91.34%) (1286/1408)\n",
      "Epoch: 47 | Batch_idx: 20 |  Loss: (0.2546) | Acc: (91.33%) (2455/2688)\n",
      "Epoch: 47 | Batch_idx: 30 |  Loss: (0.2562) | Acc: (91.56%) (3633/3968)\n",
      "Epoch: 47 | Batch_idx: 40 |  Loss: (0.2444) | Acc: (91.94%) (4825/5248)\n",
      "Epoch: 47 | Batch_idx: 50 |  Loss: (0.2454) | Acc: (91.87%) (5997/6528)\n",
      "Epoch: 47 | Batch_idx: 60 |  Loss: (0.2460) | Acc: (91.96%) (7180/7808)\n",
      "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2495) | Acc: (91.89%) (8351/9088)\n",
      "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2574) | Acc: (91.46%) (9483/10368)\n",
      "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2588) | Acc: (91.32%) (10637/11648)\n",
      "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2608) | Acc: (91.25%) (11797/12928)\n",
      "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2629) | Acc: (91.17%) (12953/14208)\n",
      "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2617) | Acc: (91.15%) (14118/15488)\n",
      "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2611) | Acc: (91.15%) (15284/16768)\n",
      "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2618) | Acc: (91.10%) (16442/18048)\n",
      "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2632) | Acc: (91.04%) (17596/19328)\n",
      "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2631) | Acc: (91.01%) (18756/20608)\n",
      "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2637) | Acc: (90.93%) (19902/21888)\n",
      "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2631) | Acc: (90.93%) (21066/23168)\n",
      "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2637) | Acc: (90.90%) (22224/24448)\n",
      "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2641) | Acc: (90.92%) (23393/25728)\n",
      "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2640) | Acc: (90.93%) (24558/27008)\n",
      "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2642) | Acc: (90.89%) (25711/28288)\n",
      "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2651) | Acc: (90.86%) (26866/29568)\n",
      "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2654) | Acc: (90.89%) (28037/30848)\n",
      "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2653) | Acc: (90.86%) (29193/32128)\n",
      "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2649) | Acc: (90.90%) (30367/33408)\n",
      "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2652) | Acc: (90.86%) (31518/34688)\n",
      "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2668) | Acc: (90.79%) (32654/35968)\n",
      "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2658) | Acc: (90.82%) (33828/37248)\n",
      "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2657) | Acc: (90.82%) (34991/38528)\n",
      "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2655) | Acc: (90.83%) (36158/39808)\n",
      "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2658) | Acc: (90.83%) (37319/41088)\n",
      "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2664) | Acc: (90.84%) (38486/42368)\n",
      "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2667) | Acc: (90.80%) (39634/43648)\n",
      "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2670) | Acc: (90.78%) (40786/44928)\n",
      "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2673) | Acc: (90.77%) (41941/46208)\n",
      "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2678) | Acc: (90.75%) (43094/47488)\n",
      "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2667) | Acc: (90.78%) (44272/48768)\n",
      "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2659) | Acc: (90.80%) (45399/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6470) | Acc: (81.45%) (8145/10000)\n",
      "Epoch: 48 | Batch_idx: 0 |  Loss: (0.2330) | Acc: (91.41%) (117/128)\n",
      "Epoch: 48 | Batch_idx: 10 |  Loss: (0.2329) | Acc: (91.48%) (1288/1408)\n",
      "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2368) | Acc: (91.29%) (2454/2688)\n",
      "Epoch: 48 | Batch_idx: 30 |  Loss: (0.2449) | Acc: (90.98%) (3610/3968)\n",
      "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2441) | Acc: (91.14%) (4783/5248)\n",
      "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2447) | Acc: (91.18%) (5952/6528)\n",
      "Epoch: 48 | Batch_idx: 60 |  Loss: (0.2500) | Acc: (90.96%) (7102/7808)\n",
      "Epoch: 48 | Batch_idx: 70 |  Loss: (0.2490) | Acc: (91.08%) (8277/9088)\n",
      "Epoch: 48 | Batch_idx: 80 |  Loss: (0.2496) | Acc: (91.08%) (9443/10368)\n",
      "Epoch: 48 | Batch_idx: 90 |  Loss: (0.2488) | Acc: (91.11%) (10612/11648)\n",
      "Epoch: 48 | Batch_idx: 100 |  Loss: (0.2492) | Acc: (91.09%) (11776/12928)\n",
      "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2535) | Acc: (90.94%) (12921/14208)\n",
      "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2542) | Acc: (90.92%) (14081/15488)\n",
      "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2543) | Acc: (90.91%) (15244/16768)\n",
      "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2542) | Acc: (90.87%) (16401/18048)\n",
      "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2544) | Acc: (90.86%) (17561/19328)\n",
      "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2533) | Acc: (90.95%) (18742/20608)\n",
      "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2540) | Acc: (90.91%) (19898/21888)\n",
      "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2542) | Acc: (90.94%) (21068/23168)\n",
      "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2538) | Acc: (90.97%) (22240/24448)\n",
      "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2556) | Acc: (90.92%) (23393/25728)\n",
      "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2554) | Acc: (90.94%) (24562/27008)\n",
      "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2556) | Acc: (90.94%) (25724/28288)\n",
      "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2562) | Acc: (90.92%) (26882/29568)\n",
      "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2563) | Acc: (90.91%) (28045/30848)\n",
      "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2562) | Acc: (90.89%) (29201/32128)\n",
      "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2551) | Acc: (90.93%) (30378/33408)\n",
      "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2553) | Acc: (90.92%) (31539/34688)\n",
      "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2561) | Acc: (90.88%) (32687/35968)\n",
      "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2560) | Acc: (90.89%) (33855/37248)\n",
      "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2560) | Acc: (90.87%) (35011/38528)\n",
      "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2561) | Acc: (90.86%) (36170/39808)\n",
      "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2565) | Acc: (90.86%) (37333/41088)\n",
      "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2564) | Acc: (90.88%) (38505/42368)\n",
      "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2569) | Acc: (90.88%) (39667/43648)\n",
      "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2570) | Acc: (90.89%) (40835/44928)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2576) | Acc: (90.88%) (41996/46208)\n",
      "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2580) | Acc: (90.88%) (43158/47488)\n",
      "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2580) | Acc: (90.87%) (44317/48768)\n",
      "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2577) | Acc: (90.89%) (45447/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4750) | Acc: (85.01%) (8501/10000)\n",
      "Epoch: 49 | Batch_idx: 0 |  Loss: (0.2167) | Acc: (93.75%) (120/128)\n",
      "Epoch: 49 | Batch_idx: 10 |  Loss: (0.2741) | Acc: (90.91%) (1280/1408)\n",
      "Epoch: 49 | Batch_idx: 20 |  Loss: (0.2547) | Acc: (91.52%) (2460/2688)\n",
      "Epoch: 49 | Batch_idx: 30 |  Loss: (0.2470) | Acc: (91.94%) (3648/3968)\n",
      "Epoch: 49 | Batch_idx: 40 |  Loss: (0.2547) | Acc: (91.54%) (4804/5248)\n",
      "Epoch: 49 | Batch_idx: 50 |  Loss: (0.2560) | Acc: (91.42%) (5968/6528)\n",
      "Epoch: 49 | Batch_idx: 60 |  Loss: (0.2527) | Acc: (91.51%) (7145/7808)\n",
      "Epoch: 49 | Batch_idx: 70 |  Loss: (0.2518) | Acc: (91.41%) (8307/9088)\n",
      "Epoch: 49 | Batch_idx: 80 |  Loss: (0.2514) | Acc: (91.47%) (9484/10368)\n",
      "Epoch: 49 | Batch_idx: 90 |  Loss: (0.2519) | Acc: (91.43%) (10650/11648)\n",
      "Epoch: 49 | Batch_idx: 100 |  Loss: (0.2529) | Acc: (91.41%) (11817/12928)\n",
      "Epoch: 49 | Batch_idx: 110 |  Loss: (0.2514) | Acc: (91.39%) (12984/14208)\n",
      "Epoch: 49 | Batch_idx: 120 |  Loss: (0.2521) | Acc: (91.32%) (14143/15488)\n",
      "Epoch: 49 | Batch_idx: 130 |  Loss: (0.2532) | Acc: (91.28%) (15305/16768)\n",
      "Epoch: 49 | Batch_idx: 140 |  Loss: (0.2531) | Acc: (91.25%) (16469/18048)\n",
      "Epoch: 49 | Batch_idx: 150 |  Loss: (0.2533) | Acc: (91.22%) (17631/19328)\n",
      "Epoch: 49 | Batch_idx: 160 |  Loss: (0.2514) | Acc: (91.33%) (18822/20608)\n",
      "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2523) | Acc: (91.31%) (19986/21888)\n",
      "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2513) | Acc: (91.33%) (21159/23168)\n",
      "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2515) | Acc: (91.31%) (22324/24448)\n",
      "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2517) | Acc: (91.33%) (23497/25728)\n",
      "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2512) | Acc: (91.31%) (24662/27008)\n",
      "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2512) | Acc: (91.30%) (25828/28288)\n",
      "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2514) | Acc: (91.29%) (26994/29568)\n",
      "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2514) | Acc: (91.28%) (28158/30848)\n",
      "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2525) | Acc: (91.23%) (29310/32128)\n",
      "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2513) | Acc: (91.28%) (30495/33408)\n",
      "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2505) | Acc: (91.32%) (31677/34688)\n",
      "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2510) | Acc: (91.30%) (32840/35968)\n",
      "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2511) | Acc: (91.31%) (34012/37248)\n",
      "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2504) | Acc: (91.35%) (35194/38528)\n",
      "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2512) | Acc: (91.35%) (36364/39808)\n",
      "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2516) | Acc: (91.36%) (37536/41088)\n",
      "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2518) | Acc: (91.34%) (38701/42368)\n",
      "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2524) | Acc: (91.32%) (39861/43648)\n",
      "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2518) | Acc: (91.33%) (41031/44928)\n",
      "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2519) | Acc: (91.31%) (42193/46208)\n",
      "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2528) | Acc: (91.27%) (43342/47488)\n",
      "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2527) | Acc: (91.25%) (44503/48768)\n",
      "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2525) | Acc: (91.26%) (45631/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4916) | Acc: (84.10%) (8410/10000)\n",
      "Epoch: 50 | Batch_idx: 0 |  Loss: (0.1918) | Acc: (92.97%) (119/128)\n",
      "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2296) | Acc: (92.40%) (1301/1408)\n",
      "Epoch: 50 | Batch_idx: 20 |  Loss: (0.2379) | Acc: (92.15%) (2477/2688)\n",
      "Epoch: 50 | Batch_idx: 30 |  Loss: (0.2379) | Acc: (92.26%) (3661/3968)\n",
      "Epoch: 50 | Batch_idx: 40 |  Loss: (0.2460) | Acc: (92.11%) (4834/5248)\n",
      "Epoch: 50 | Batch_idx: 50 |  Loss: (0.2504) | Acc: (91.74%) (5989/6528)\n",
      "Epoch: 50 | Batch_idx: 60 |  Loss: (0.2466) | Acc: (91.87%) (7173/7808)\n",
      "Epoch: 50 | Batch_idx: 70 |  Loss: (0.2471) | Acc: (91.95%) (8356/9088)\n",
      "Epoch: 50 | Batch_idx: 80 |  Loss: (0.2443) | Acc: (92.00%) (9539/10368)\n",
      "Epoch: 50 | Batch_idx: 90 |  Loss: (0.2422) | Acc: (92.08%) (10726/11648)\n",
      "Epoch: 50 | Batch_idx: 100 |  Loss: (0.2392) | Acc: (92.09%) (11905/12928)\n",
      "Epoch: 50 | Batch_idx: 110 |  Loss: (0.2416) | Acc: (91.97%) (13067/14208)\n",
      "Epoch: 50 | Batch_idx: 120 |  Loss: (0.2398) | Acc: (91.97%) (14244/15488)\n",
      "Epoch: 50 | Batch_idx: 130 |  Loss: (0.2412) | Acc: (91.93%) (15415/16768)\n",
      "Epoch: 50 | Batch_idx: 140 |  Loss: (0.2415) | Acc: (91.94%) (16594/18048)\n",
      "Epoch: 50 | Batch_idx: 150 |  Loss: (0.2421) | Acc: (91.89%) (17761/19328)\n",
      "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2425) | Acc: (91.88%) (18935/20608)\n",
      "Epoch: 50 | Batch_idx: 170 |  Loss: (0.2440) | Acc: (91.82%) (20098/21888)\n",
      "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2440) | Acc: (91.80%) (21268/23168)\n",
      "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2441) | Acc: (91.77%) (22437/24448)\n",
      "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2427) | Acc: (91.81%) (23622/25728)\n",
      "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2439) | Acc: (91.74%) (24778/27008)\n",
      "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2440) | Acc: (91.72%) (25945/28288)\n",
      "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2431) | Acc: (91.74%) (27127/29568)\n",
      "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2438) | Acc: (91.73%) (28296/30848)\n",
      "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2441) | Acc: (91.70%) (29460/32128)\n",
      "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2440) | Acc: (91.69%) (30631/33408)\n",
      "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2445) | Acc: (91.65%) (31792/34688)\n",
      "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2446) | Acc: (91.66%) (32969/35968)\n",
      "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2452) | Acc: (91.63%) (34132/37248)\n",
      "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2449) | Acc: (91.63%) (35302/38528)\n",
      "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2457) | Acc: (91.60%) (36463/39808)\n",
      "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2465) | Acc: (91.55%) (37617/41088)\n",
      "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2475) | Acc: (91.52%) (38776/42368)\n",
      "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2481) | Acc: (91.52%) (39945/43648)\n",
      "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2477) | Acc: (91.51%) (41115/44928)\n",
      "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2485) | Acc: (91.49%) (42277/46208)\n",
      "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2488) | Acc: (91.47%) (43439/47488)\n",
      "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2485) | Acc: (91.48%) (44611/48768)\n",
      "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2481) | Acc: (91.49%) (45745/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5571) | Acc: (82.91%) (8291/10000)\n",
      "Epoch: 51 | Batch_idx: 0 |  Loss: (0.2454) | Acc: (90.62%) (116/128)\n",
      "Epoch: 51 | Batch_idx: 10 |  Loss: (0.2319) | Acc: (91.48%) (1288/1408)\n",
      "Epoch: 51 | Batch_idx: 20 |  Loss: (0.2349) | Acc: (91.44%) (2458/2688)\n",
      "Epoch: 51 | Batch_idx: 30 |  Loss: (0.2393) | Acc: (91.26%) (3621/3968)\n",
      "Epoch: 51 | Batch_idx: 40 |  Loss: (0.2433) | Acc: (91.22%) (4787/5248)\n",
      "Epoch: 51 | Batch_idx: 50 |  Loss: (0.2461) | Acc: (91.16%) (5951/6528)\n",
      "Epoch: 51 | Batch_idx: 60 |  Loss: (0.2450) | Acc: (91.28%) (7127/7808)\n",
      "Epoch: 51 | Batch_idx: 70 |  Loss: (0.2475) | Acc: (91.16%) (8285/9088)\n",
      "Epoch: 51 | Batch_idx: 80 |  Loss: (0.2505) | Acc: (91.11%) (9446/10368)\n",
      "Epoch: 51 | Batch_idx: 90 |  Loss: (0.2499) | Acc: (91.13%) (10615/11648)\n",
      "Epoch: 51 | Batch_idx: 100 |  Loss: (0.2502) | Acc: (91.20%) (11790/12928)\n",
      "Epoch: 51 | Batch_idx: 110 |  Loss: (0.2471) | Acc: (91.30%) (12972/14208)\n",
      "Epoch: 51 | Batch_idx: 120 |  Loss: (0.2469) | Acc: (91.35%) (14149/15488)\n",
      "Epoch: 51 | Batch_idx: 130 |  Loss: (0.2455) | Acc: (91.38%) (15322/16768)\n",
      "Epoch: 51 | Batch_idx: 140 |  Loss: (0.2447) | Acc: (91.43%) (16501/18048)\n",
      "Epoch: 51 | Batch_idx: 150 |  Loss: (0.2420) | Acc: (91.54%) (17692/19328)\n",
      "Epoch: 51 | Batch_idx: 160 |  Loss: (0.2426) | Acc: (91.54%) (18865/20608)\n",
      "Epoch: 51 | Batch_idx: 170 |  Loss: (0.2419) | Acc: (91.57%) (20043/21888)\n",
      "Epoch: 51 | Batch_idx: 180 |  Loss: (0.2411) | Acc: (91.61%) (21225/23168)\n",
      "Epoch: 51 | Batch_idx: 190 |  Loss: (0.2404) | Acc: (91.65%) (22407/24448)\n",
      "Epoch: 51 | Batch_idx: 200 |  Loss: (0.2405) | Acc: (91.62%) (23571/25728)\n",
      "Epoch: 51 | Batch_idx: 210 |  Loss: (0.2400) | Acc: (91.65%) (24752/27008)\n",
      "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2393) | Acc: (91.71%) (25943/28288)\n",
      "Epoch: 51 | Batch_idx: 230 |  Loss: (0.2400) | Acc: (91.67%) (27106/29568)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2399) | Acc: (91.67%) (28278/30848)\n",
      "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2401) | Acc: (91.67%) (29451/32128)\n",
      "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2413) | Acc: (91.62%) (30609/33408)\n",
      "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2416) | Acc: (91.62%) (31780/34688)\n",
      "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2410) | Acc: (91.64%) (32960/35968)\n",
      "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2399) | Acc: (91.67%) (34147/37248)\n",
      "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2409) | Acc: (91.65%) (35312/38528)\n",
      "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2418) | Acc: (91.61%) (36468/39808)\n",
      "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2424) | Acc: (91.60%) (37637/41088)\n",
      "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2429) | Acc: (91.58%) (38800/42368)\n",
      "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2437) | Acc: (91.53%) (39953/43648)\n",
      "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2434) | Acc: (91.57%) (41141/44928)\n",
      "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2429) | Acc: (91.59%) (42322/46208)\n",
      "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2428) | Acc: (91.60%) (43499/47488)\n",
      "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2425) | Acc: (91.61%) (44675/48768)\n",
      "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2431) | Acc: (91.56%) (45781/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5116) | Acc: (84.50%) (8450/10000)\n",
      "Epoch: 52 | Batch_idx: 0 |  Loss: (0.2029) | Acc: (94.53%) (121/128)\n",
      "Epoch: 52 | Batch_idx: 10 |  Loss: (0.2044) | Acc: (93.18%) (1312/1408)\n",
      "Epoch: 52 | Batch_idx: 20 |  Loss: (0.2228) | Acc: (92.49%) (2486/2688)\n",
      "Epoch: 52 | Batch_idx: 30 |  Loss: (0.2329) | Acc: (92.21%) (3659/3968)\n",
      "Epoch: 52 | Batch_idx: 40 |  Loss: (0.2345) | Acc: (92.15%) (4836/5248)\n",
      "Epoch: 52 | Batch_idx: 50 |  Loss: (0.2373) | Acc: (92.11%) (6013/6528)\n",
      "Epoch: 52 | Batch_idx: 60 |  Loss: (0.2390) | Acc: (92.05%) (7187/7808)\n",
      "Epoch: 52 | Batch_idx: 70 |  Loss: (0.2369) | Acc: (92.07%) (8367/9088)\n",
      "Epoch: 52 | Batch_idx: 80 |  Loss: (0.2350) | Acc: (92.09%) (9548/10368)\n",
      "Epoch: 52 | Batch_idx: 90 |  Loss: (0.2367) | Acc: (92.02%) (10718/11648)\n",
      "Epoch: 52 | Batch_idx: 100 |  Loss: (0.2386) | Acc: (91.86%) (11876/12928)\n",
      "Epoch: 52 | Batch_idx: 110 |  Loss: (0.2367) | Acc: (91.94%) (13063/14208)\n",
      "Epoch: 52 | Batch_idx: 120 |  Loss: (0.2368) | Acc: (91.90%) (14234/15488)\n",
      "Epoch: 52 | Batch_idx: 130 |  Loss: (0.2345) | Acc: (92.03%) (15432/16768)\n",
      "Epoch: 52 | Batch_idx: 140 |  Loss: (0.2352) | Acc: (92.01%) (16606/18048)\n",
      "Epoch: 52 | Batch_idx: 150 |  Loss: (0.2362) | Acc: (91.93%) (17768/19328)\n",
      "Epoch: 52 | Batch_idx: 160 |  Loss: (0.2347) | Acc: (91.95%) (18949/20608)\n",
      "Epoch: 52 | Batch_idx: 170 |  Loss: (0.2366) | Acc: (91.86%) (20106/21888)\n",
      "Epoch: 52 | Batch_idx: 180 |  Loss: (0.2370) | Acc: (91.86%) (21282/23168)\n",
      "Epoch: 52 | Batch_idx: 190 |  Loss: (0.2377) | Acc: (91.81%) (22446/24448)\n",
      "Epoch: 52 | Batch_idx: 200 |  Loss: (0.2380) | Acc: (91.81%) (23622/25728)\n",
      "Epoch: 52 | Batch_idx: 210 |  Loss: (0.2377) | Acc: (91.82%) (24800/27008)\n",
      "Epoch: 52 | Batch_idx: 220 |  Loss: (0.2375) | Acc: (91.85%) (25983/28288)\n",
      "Epoch: 52 | Batch_idx: 230 |  Loss: (0.2371) | Acc: (91.85%) (27158/29568)\n",
      "Epoch: 52 | Batch_idx: 240 |  Loss: (0.2380) | Acc: (91.80%) (28317/30848)\n",
      "Epoch: 52 | Batch_idx: 250 |  Loss: (0.2370) | Acc: (91.81%) (29497/32128)\n",
      "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2377) | Acc: (91.82%) (30674/33408)\n",
      "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2386) | Acc: (91.79%) (31841/34688)\n",
      "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2372) | Acc: (91.85%) (33037/35968)\n",
      "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2372) | Acc: (91.85%) (34214/37248)\n",
      "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2369) | Acc: (91.88%) (35399/38528)\n",
      "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2364) | Acc: (91.90%) (36583/39808)\n",
      "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2363) | Acc: (91.90%) (37758/41088)\n",
      "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2364) | Acc: (91.89%) (38933/42368)\n",
      "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2372) | Acc: (91.85%) (40092/43648)\n",
      "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2374) | Acc: (91.86%) (41273/44928)\n",
      "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2369) | Acc: (91.88%) (42457/46208)\n",
      "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2364) | Acc: (91.89%) (43636/47488)\n",
      "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2364) | Acc: (91.86%) (44800/48768)\n",
      "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2366) | Acc: (91.85%) (45924/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4275) | Acc: (86.50%) (8650/10000)\n",
      "Epoch: 53 | Batch_idx: 0 |  Loss: (0.2135) | Acc: (89.84%) (115/128)\n",
      "Epoch: 53 | Batch_idx: 10 |  Loss: (0.1940) | Acc: (93.04%) (1310/1408)\n",
      "Epoch: 53 | Batch_idx: 20 |  Loss: (0.2168) | Acc: (92.60%) (2489/2688)\n",
      "Epoch: 53 | Batch_idx: 30 |  Loss: (0.2188) | Acc: (92.41%) (3667/3968)\n",
      "Epoch: 53 | Batch_idx: 40 |  Loss: (0.2186) | Acc: (92.53%) (4856/5248)\n",
      "Epoch: 53 | Batch_idx: 50 |  Loss: (0.2158) | Acc: (92.54%) (6041/6528)\n",
      "Epoch: 53 | Batch_idx: 60 |  Loss: (0.2228) | Acc: (92.25%) (7203/7808)\n",
      "Epoch: 53 | Batch_idx: 70 |  Loss: (0.2228) | Acc: (92.31%) (8389/9088)\n",
      "Epoch: 53 | Batch_idx: 80 |  Loss: (0.2234) | Acc: (92.28%) (9568/10368)\n",
      "Epoch: 53 | Batch_idx: 90 |  Loss: (0.2249) | Acc: (92.21%) (10741/11648)\n",
      "Epoch: 53 | Batch_idx: 100 |  Loss: (0.2260) | Acc: (92.25%) (11926/12928)\n",
      "Epoch: 53 | Batch_idx: 110 |  Loss: (0.2226) | Acc: (92.41%) (13130/14208)\n",
      "Epoch: 53 | Batch_idx: 120 |  Loss: (0.2224) | Acc: (92.46%) (14320/15488)\n",
      "Epoch: 53 | Batch_idx: 130 |  Loss: (0.2239) | Acc: (92.44%) (15501/16768)\n",
      "Epoch: 53 | Batch_idx: 140 |  Loss: (0.2261) | Acc: (92.38%) (16673/18048)\n",
      "Epoch: 53 | Batch_idx: 150 |  Loss: (0.2275) | Acc: (92.28%) (17835/19328)\n",
      "Epoch: 53 | Batch_idx: 160 |  Loss: (0.2275) | Acc: (92.29%) (19019/20608)\n",
      "Epoch: 53 | Batch_idx: 170 |  Loss: (0.2301) | Acc: (92.16%) (20172/21888)\n",
      "Epoch: 53 | Batch_idx: 180 |  Loss: (0.2290) | Acc: (92.18%) (21356/23168)\n",
      "Epoch: 53 | Batch_idx: 190 |  Loss: (0.2295) | Acc: (92.13%) (22525/24448)\n",
      "Epoch: 53 | Batch_idx: 200 |  Loss: (0.2286) | Acc: (92.18%) (23715/25728)\n",
      "Epoch: 53 | Batch_idx: 210 |  Loss: (0.2296) | Acc: (92.08%) (24869/27008)\n",
      "Epoch: 53 | Batch_idx: 220 |  Loss: (0.2296) | Acc: (92.07%) (26046/28288)\n",
      "Epoch: 53 | Batch_idx: 230 |  Loss: (0.2288) | Acc: (92.09%) (27228/29568)\n",
      "Epoch: 53 | Batch_idx: 240 |  Loss: (0.2298) | Acc: (92.06%) (28400/30848)\n",
      "Epoch: 53 | Batch_idx: 250 |  Loss: (0.2302) | Acc: (92.04%) (29572/32128)\n",
      "Epoch: 53 | Batch_idx: 260 |  Loss: (0.2305) | Acc: (92.02%) (30743/33408)\n",
      "Epoch: 53 | Batch_idx: 270 |  Loss: (0.2304) | Acc: (92.00%) (31914/34688)\n",
      "Epoch: 53 | Batch_idx: 280 |  Loss: (0.2299) | Acc: (92.02%) (33098/35968)\n",
      "Epoch: 53 | Batch_idx: 290 |  Loss: (0.2303) | Acc: (92.01%) (34272/37248)\n",
      "Epoch: 53 | Batch_idx: 300 |  Loss: (0.2301) | Acc: (92.02%) (35454/38528)\n",
      "Epoch: 53 | Batch_idx: 310 |  Loss: (0.2299) | Acc: (92.03%) (36636/39808)\n",
      "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2298) | Acc: (92.04%) (37818/41088)\n",
      "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2300) | Acc: (92.03%) (38992/42368)\n",
      "Epoch: 53 | Batch_idx: 340 |  Loss: (0.2300) | Acc: (92.01%) (40160/43648)\n",
      "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2305) | Acc: (92.01%) (41337/44928)\n",
      "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2319) | Acc: (91.94%) (42482/46208)\n",
      "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2316) | Acc: (91.95%) (43667/47488)\n",
      "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2314) | Acc: (91.97%) (44851/48768)\n",
      "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2318) | Acc: (91.96%) (45979/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4847) | Acc: (85.37%) (8537/10000)\n",
      "Epoch: 54 | Batch_idx: 0 |  Loss: (0.1834) | Acc: (92.97%) (119/128)\n",
      "Epoch: 54 | Batch_idx: 10 |  Loss: (0.2274) | Acc: (92.19%) (1298/1408)\n",
      "Epoch: 54 | Batch_idx: 20 |  Loss: (0.2351) | Acc: (91.82%) (2468/2688)\n",
      "Epoch: 54 | Batch_idx: 30 |  Loss: (0.2359) | Acc: (91.91%) (3647/3968)\n",
      "Epoch: 54 | Batch_idx: 40 |  Loss: (0.2348) | Acc: (91.86%) (4821/5248)\n",
      "Epoch: 54 | Batch_idx: 50 |  Loss: (0.2353) | Acc: (91.76%) (5990/6528)\n",
      "Epoch: 54 | Batch_idx: 60 |  Loss: (0.2367) | Acc: (91.66%) (7157/7808)\n",
      "Epoch: 54 | Batch_idx: 70 |  Loss: (0.2349) | Acc: (91.75%) (8338/9088)\n",
      "Epoch: 54 | Batch_idx: 80 |  Loss: (0.2344) | Acc: (91.75%) (9513/10368)\n",
      "Epoch: 54 | Batch_idx: 90 |  Loss: (0.2375) | Acc: (91.62%) (10672/11648)\n",
      "Epoch: 54 | Batch_idx: 100 |  Loss: (0.2361) | Acc: (91.69%) (11854/12928)\n",
      "Epoch: 54 | Batch_idx: 110 |  Loss: (0.2366) | Acc: (91.69%) (13028/14208)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 | Batch_idx: 120 |  Loss: (0.2364) | Acc: (91.72%) (14205/15488)\n",
      "Epoch: 54 | Batch_idx: 130 |  Loss: (0.2332) | Acc: (91.82%) (15396/16768)\n",
      "Epoch: 54 | Batch_idx: 140 |  Loss: (0.2316) | Acc: (91.85%) (16577/18048)\n",
      "Epoch: 54 | Batch_idx: 150 |  Loss: (0.2344) | Acc: (91.71%) (17726/19328)\n",
      "Epoch: 54 | Batch_idx: 160 |  Loss: (0.2339) | Acc: (91.74%) (18906/20608)\n",
      "Epoch: 54 | Batch_idx: 170 |  Loss: (0.2323) | Acc: (91.77%) (20087/21888)\n",
      "Epoch: 54 | Batch_idx: 180 |  Loss: (0.2317) | Acc: (91.79%) (21267/23168)\n",
      "Epoch: 54 | Batch_idx: 190 |  Loss: (0.2335) | Acc: (91.75%) (22431/24448)\n",
      "Epoch: 54 | Batch_idx: 200 |  Loss: (0.2338) | Acc: (91.72%) (23599/25728)\n",
      "Epoch: 54 | Batch_idx: 210 |  Loss: (0.2348) | Acc: (91.68%) (24762/27008)\n",
      "Epoch: 54 | Batch_idx: 220 |  Loss: (0.2345) | Acc: (91.69%) (25938/28288)\n",
      "Epoch: 54 | Batch_idx: 230 |  Loss: (0.2332) | Acc: (91.72%) (27121/29568)\n",
      "Epoch: 54 | Batch_idx: 240 |  Loss: (0.2326) | Acc: (91.77%) (28309/30848)\n",
      "Epoch: 54 | Batch_idx: 250 |  Loss: (0.2323) | Acc: (91.76%) (29482/32128)\n",
      "Epoch: 54 | Batch_idx: 260 |  Loss: (0.2310) | Acc: (91.83%) (30679/33408)\n",
      "Epoch: 54 | Batch_idx: 270 |  Loss: (0.2308) | Acc: (91.86%) (31866/34688)\n",
      "Epoch: 54 | Batch_idx: 280 |  Loss: (0.2304) | Acc: (91.91%) (33058/35968)\n",
      "Epoch: 54 | Batch_idx: 290 |  Loss: (0.2303) | Acc: (91.92%) (34237/37248)\n",
      "Epoch: 54 | Batch_idx: 300 |  Loss: (0.2307) | Acc: (91.91%) (35410/38528)\n",
      "Epoch: 54 | Batch_idx: 310 |  Loss: (0.2302) | Acc: (91.93%) (36596/39808)\n",
      "Epoch: 54 | Batch_idx: 320 |  Loss: (0.2295) | Acc: (91.94%) (37778/41088)\n",
      "Epoch: 54 | Batch_idx: 330 |  Loss: (0.2300) | Acc: (91.96%) (38960/42368)\n",
      "Epoch: 54 | Batch_idx: 340 |  Loss: (0.2303) | Acc: (91.95%) (40135/43648)\n",
      "Epoch: 54 | Batch_idx: 350 |  Loss: (0.2299) | Acc: (91.99%) (41329/44928)\n",
      "Epoch: 54 | Batch_idx: 360 |  Loss: (0.2299) | Acc: (92.00%) (42511/46208)\n",
      "Epoch: 54 | Batch_idx: 370 |  Loss: (0.2301) | Acc: (92.01%) (43693/47488)\n",
      "Epoch: 54 | Batch_idx: 380 |  Loss: (0.2305) | Acc: (92.01%) (44872/48768)\n",
      "Epoch: 54 | Batch_idx: 390 |  Loss: (0.2309) | Acc: (92.01%) (46006/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4487) | Acc: (86.08%) (8608/10000)\n",
      "Epoch: 55 | Batch_idx: 0 |  Loss: (0.1604) | Acc: (93.75%) (120/128)\n",
      "Epoch: 55 | Batch_idx: 10 |  Loss: (0.2227) | Acc: (91.41%) (1287/1408)\n",
      "Epoch: 55 | Batch_idx: 20 |  Loss: (0.2226) | Acc: (91.82%) (2468/2688)\n",
      "Epoch: 55 | Batch_idx: 30 |  Loss: (0.2197) | Acc: (92.29%) (3662/3968)\n",
      "Epoch: 55 | Batch_idx: 40 |  Loss: (0.2135) | Acc: (92.55%) (4857/5248)\n",
      "Epoch: 55 | Batch_idx: 50 |  Loss: (0.2111) | Acc: (92.45%) (6035/6528)\n",
      "Epoch: 55 | Batch_idx: 60 |  Loss: (0.2187) | Acc: (92.24%) (7202/7808)\n",
      "Epoch: 55 | Batch_idx: 70 |  Loss: (0.2178) | Acc: (92.26%) (8385/9088)\n",
      "Epoch: 55 | Batch_idx: 80 |  Loss: (0.2185) | Acc: (92.19%) (9558/10368)\n",
      "Epoch: 55 | Batch_idx: 90 |  Loss: (0.2228) | Acc: (92.03%) (10720/11648)\n",
      "Epoch: 55 | Batch_idx: 100 |  Loss: (0.2218) | Acc: (92.16%) (11914/12928)\n",
      "Epoch: 55 | Batch_idx: 110 |  Loss: (0.2207) | Acc: (92.26%) (13108/14208)\n",
      "Epoch: 55 | Batch_idx: 120 |  Loss: (0.2226) | Acc: (92.19%) (14278/15488)\n",
      "Epoch: 55 | Batch_idx: 130 |  Loss: (0.2230) | Acc: (92.21%) (15461/16768)\n",
      "Epoch: 55 | Batch_idx: 140 |  Loss: (0.2246) | Acc: (92.19%) (16638/18048)\n",
      "Epoch: 55 | Batch_idx: 150 |  Loss: (0.2221) | Acc: (92.24%) (17828/19328)\n",
      "Epoch: 55 | Batch_idx: 160 |  Loss: (0.2228) | Acc: (92.20%) (19000/20608)\n",
      "Epoch: 55 | Batch_idx: 170 |  Loss: (0.2213) | Acc: (92.23%) (20187/21888)\n",
      "Epoch: 55 | Batch_idx: 180 |  Loss: (0.2200) | Acc: (92.32%) (21388/23168)\n",
      "Epoch: 55 | Batch_idx: 190 |  Loss: (0.2206) | Acc: (92.27%) (22559/24448)\n",
      "Epoch: 55 | Batch_idx: 200 |  Loss: (0.2212) | Acc: (92.25%) (23733/25728)\n",
      "Epoch: 55 | Batch_idx: 210 |  Loss: (0.2202) | Acc: (92.29%) (24925/27008)\n",
      "Epoch: 55 | Batch_idx: 220 |  Loss: (0.2191) | Acc: (92.34%) (26121/28288)\n",
      "Epoch: 55 | Batch_idx: 230 |  Loss: (0.2214) | Acc: (92.26%) (27279/29568)\n",
      "Epoch: 55 | Batch_idx: 240 |  Loss: (0.2218) | Acc: (92.26%) (28460/30848)\n",
      "Epoch: 55 | Batch_idx: 250 |  Loss: (0.2219) | Acc: (92.25%) (29639/32128)\n",
      "Epoch: 55 | Batch_idx: 260 |  Loss: (0.2224) | Acc: (92.21%) (30805/33408)\n",
      "Epoch: 55 | Batch_idx: 270 |  Loss: (0.2222) | Acc: (92.22%) (31991/34688)\n",
      "Epoch: 55 | Batch_idx: 280 |  Loss: (0.2234) | Acc: (92.17%) (33152/35968)\n",
      "Epoch: 55 | Batch_idx: 290 |  Loss: (0.2227) | Acc: (92.20%) (34344/37248)\n",
      "Epoch: 55 | Batch_idx: 300 |  Loss: (0.2225) | Acc: (92.20%) (35521/38528)\n",
      "Epoch: 55 | Batch_idx: 310 |  Loss: (0.2234) | Acc: (92.15%) (36682/39808)\n",
      "Epoch: 55 | Batch_idx: 320 |  Loss: (0.2240) | Acc: (92.13%) (37855/41088)\n",
      "Epoch: 55 | Batch_idx: 330 |  Loss: (0.2246) | Acc: (92.14%) (39037/42368)\n",
      "Epoch: 55 | Batch_idx: 340 |  Loss: (0.2251) | Acc: (92.09%) (40197/43648)\n",
      "Epoch: 55 | Batch_idx: 350 |  Loss: (0.2253) | Acc: (92.08%) (41370/44928)\n",
      "Epoch: 55 | Batch_idx: 360 |  Loss: (0.2255) | Acc: (92.08%) (42549/46208)\n",
      "Epoch: 55 | Batch_idx: 370 |  Loss: (0.2256) | Acc: (92.07%) (43722/47488)\n",
      "Epoch: 55 | Batch_idx: 380 |  Loss: (0.2265) | Acc: (92.05%) (44891/48768)\n",
      "Epoch: 55 | Batch_idx: 390 |  Loss: (0.2265) | Acc: (92.06%) (46030/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5551) | Acc: (83.97%) (8397/10000)\n",
      "Epoch: 56 | Batch_idx: 0 |  Loss: (0.2013) | Acc: (92.19%) (118/128)\n",
      "Epoch: 56 | Batch_idx: 10 |  Loss: (0.2335) | Acc: (92.19%) (1298/1408)\n",
      "Epoch: 56 | Batch_idx: 20 |  Loss: (0.2272) | Acc: (92.37%) (2483/2688)\n",
      "Epoch: 56 | Batch_idx: 30 |  Loss: (0.2214) | Acc: (92.36%) (3665/3968)\n",
      "Epoch: 56 | Batch_idx: 40 |  Loss: (0.2217) | Acc: (92.23%) (4840/5248)\n",
      "Epoch: 56 | Batch_idx: 50 |  Loss: (0.2211) | Acc: (92.28%) (6024/6528)\n",
      "Epoch: 56 | Batch_idx: 60 |  Loss: (0.2205) | Acc: (92.33%) (7209/7808)\n",
      "Epoch: 56 | Batch_idx: 70 |  Loss: (0.2201) | Acc: (92.36%) (8394/9088)\n",
      "Epoch: 56 | Batch_idx: 80 |  Loss: (0.2175) | Acc: (92.47%) (9587/10368)\n",
      "Epoch: 56 | Batch_idx: 90 |  Loss: (0.2134) | Acc: (92.65%) (10792/11648)\n",
      "Epoch: 56 | Batch_idx: 100 |  Loss: (0.2142) | Acc: (92.58%) (11969/12928)\n",
      "Epoch: 56 | Batch_idx: 110 |  Loss: (0.2123) | Acc: (92.71%) (13172/14208)\n",
      "Epoch: 56 | Batch_idx: 120 |  Loss: (0.2127) | Acc: (92.70%) (14357/15488)\n",
      "Epoch: 56 | Batch_idx: 130 |  Loss: (0.2123) | Acc: (92.68%) (15541/16768)\n",
      "Epoch: 56 | Batch_idx: 140 |  Loss: (0.2123) | Acc: (92.72%) (16734/18048)\n",
      "Epoch: 56 | Batch_idx: 150 |  Loss: (0.2135) | Acc: (92.69%) (17916/19328)\n",
      "Epoch: 56 | Batch_idx: 160 |  Loss: (0.2125) | Acc: (92.71%) (19106/20608)\n",
      "Epoch: 56 | Batch_idx: 170 |  Loss: (0.2131) | Acc: (92.67%) (20283/21888)\n",
      "Epoch: 56 | Batch_idx: 180 |  Loss: (0.2143) | Acc: (92.60%) (21454/23168)\n",
      "Epoch: 56 | Batch_idx: 190 |  Loss: (0.2147) | Acc: (92.60%) (22640/24448)\n",
      "Epoch: 56 | Batch_idx: 200 |  Loss: (0.2142) | Acc: (92.63%) (23831/25728)\n",
      "Epoch: 56 | Batch_idx: 210 |  Loss: (0.2148) | Acc: (92.60%) (25009/27008)\n",
      "Epoch: 56 | Batch_idx: 220 |  Loss: (0.2158) | Acc: (92.52%) (26172/28288)\n",
      "Epoch: 56 | Batch_idx: 230 |  Loss: (0.2144) | Acc: (92.55%) (27364/29568)\n",
      "Epoch: 56 | Batch_idx: 240 |  Loss: (0.2146) | Acc: (92.54%) (28548/30848)\n",
      "Epoch: 56 | Batch_idx: 250 |  Loss: (0.2147) | Acc: (92.55%) (29736/32128)\n",
      "Epoch: 56 | Batch_idx: 260 |  Loss: (0.2149) | Acc: (92.55%) (30918/33408)\n",
      "Epoch: 56 | Batch_idx: 270 |  Loss: (0.2151) | Acc: (92.57%) (32110/34688)\n",
      "Epoch: 56 | Batch_idx: 280 |  Loss: (0.2173) | Acc: (92.48%) (33265/35968)\n",
      "Epoch: 56 | Batch_idx: 290 |  Loss: (0.2169) | Acc: (92.50%) (34456/37248)\n",
      "Epoch: 56 | Batch_idx: 300 |  Loss: (0.2174) | Acc: (92.50%) (35637/38528)\n",
      "Epoch: 56 | Batch_idx: 310 |  Loss: (0.2175) | Acc: (92.49%) (36819/39808)\n",
      "Epoch: 56 | Batch_idx: 320 |  Loss: (0.2170) | Acc: (92.50%) (38007/41088)\n",
      "Epoch: 56 | Batch_idx: 330 |  Loss: (0.2165) | Acc: (92.53%) (39204/42368)\n",
      "Epoch: 56 | Batch_idx: 340 |  Loss: (0.2169) | Acc: (92.53%) (40388/43648)\n",
      "Epoch: 56 | Batch_idx: 350 |  Loss: (0.2180) | Acc: (92.50%) (41560/44928)\n",
      "Epoch: 56 | Batch_idx: 360 |  Loss: (0.2180) | Acc: (92.53%) (42755/46208)\n",
      "Epoch: 56 | Batch_idx: 370 |  Loss: (0.2184) | Acc: (92.51%) (43929/47488)\n",
      "Epoch: 56 | Batch_idx: 380 |  Loss: (0.2191) | Acc: (92.48%) (45100/48768)\n",
      "Epoch: 56 | Batch_idx: 390 |  Loss: (0.2196) | Acc: (92.44%) (46219/50000)\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TEST : Loss: (0.4989) | Acc: (85.07%) (8507/10000)\n",
      "Epoch: 57 | Batch_idx: 0 |  Loss: (0.2775) | Acc: (92.19%) (118/128)\n",
      "Epoch: 57 | Batch_idx: 10 |  Loss: (0.2283) | Acc: (91.76%) (1292/1408)\n",
      "Epoch: 57 | Batch_idx: 20 |  Loss: (0.2159) | Acc: (92.34%) (2482/2688)\n",
      "Epoch: 57 | Batch_idx: 30 |  Loss: (0.2087) | Acc: (92.72%) (3679/3968)\n",
      "Epoch: 57 | Batch_idx: 40 |  Loss: (0.2077) | Acc: (92.95%) (4878/5248)\n",
      "Epoch: 57 | Batch_idx: 50 |  Loss: (0.2097) | Acc: (92.88%) (6063/6528)\n",
      "Epoch: 57 | Batch_idx: 60 |  Loss: (0.2127) | Acc: (92.71%) (7239/7808)\n",
      "Epoch: 57 | Batch_idx: 70 |  Loss: (0.2113) | Acc: (92.79%) (8433/9088)\n",
      "Epoch: 57 | Batch_idx: 80 |  Loss: (0.2142) | Acc: (92.63%) (9604/10368)\n",
      "Epoch: 57 | Batch_idx: 90 |  Loss: (0.2162) | Acc: (92.61%) (10787/11648)\n",
      "Epoch: 57 | Batch_idx: 100 |  Loss: (0.2136) | Acc: (92.66%) (11979/12928)\n",
      "Epoch: 57 | Batch_idx: 110 |  Loss: (0.2142) | Acc: (92.70%) (13171/14208)\n",
      "Epoch: 57 | Batch_idx: 120 |  Loss: (0.2133) | Acc: (92.70%) (14358/15488)\n",
      "Epoch: 57 | Batch_idx: 130 |  Loss: (0.2110) | Acc: (92.77%) (15556/16768)\n",
      "Epoch: 57 | Batch_idx: 140 |  Loss: (0.2110) | Acc: (92.79%) (16746/18048)\n",
      "Epoch: 57 | Batch_idx: 150 |  Loss: (0.2107) | Acc: (92.79%) (17935/19328)\n",
      "Epoch: 57 | Batch_idx: 160 |  Loss: (0.2083) | Acc: (92.83%) (19131/20608)\n",
      "Epoch: 57 | Batch_idx: 170 |  Loss: (0.2067) | Acc: (92.88%) (20330/21888)\n",
      "Epoch: 57 | Batch_idx: 180 |  Loss: (0.2064) | Acc: (92.87%) (21515/23168)\n",
      "Epoch: 57 | Batch_idx: 190 |  Loss: (0.2065) | Acc: (92.84%) (22697/24448)\n",
      "Epoch: 57 | Batch_idx: 200 |  Loss: (0.2057) | Acc: (92.92%) (23906/25728)\n",
      "Epoch: 57 | Batch_idx: 210 |  Loss: (0.2067) | Acc: (92.90%) (25091/27008)\n",
      "Epoch: 57 | Batch_idx: 220 |  Loss: (0.2068) | Acc: (92.91%) (26281/28288)\n",
      "Epoch: 57 | Batch_idx: 230 |  Loss: (0.2070) | Acc: (92.91%) (27471/29568)\n",
      "Epoch: 57 | Batch_idx: 240 |  Loss: (0.2094) | Acc: (92.84%) (28639/30848)\n",
      "Epoch: 57 | Batch_idx: 250 |  Loss: (0.2107) | Acc: (92.79%) (29812/32128)\n",
      "Epoch: 57 | Batch_idx: 260 |  Loss: (0.2109) | Acc: (92.80%) (31004/33408)\n",
      "Epoch: 57 | Batch_idx: 270 |  Loss: (0.2109) | Acc: (92.82%) (32196/34688)\n",
      "Epoch: 57 | Batch_idx: 280 |  Loss: (0.2110) | Acc: (92.84%) (33393/35968)\n",
      "Epoch: 57 | Batch_idx: 290 |  Loss: (0.2114) | Acc: (92.82%) (34574/37248)\n",
      "Epoch: 57 | Batch_idx: 300 |  Loss: (0.2116) | Acc: (92.79%) (35752/38528)\n",
      "Epoch: 57 | Batch_idx: 310 |  Loss: (0.2109) | Acc: (92.81%) (36946/39808)\n",
      "Epoch: 57 | Batch_idx: 320 |  Loss: (0.2116) | Acc: (92.78%) (38123/41088)\n",
      "Epoch: 57 | Batch_idx: 330 |  Loss: (0.2116) | Acc: (92.77%) (39305/42368)\n",
      "Epoch: 57 | Batch_idx: 340 |  Loss: (0.2117) | Acc: (92.76%) (40488/43648)\n",
      "Epoch: 57 | Batch_idx: 350 |  Loss: (0.2116) | Acc: (92.75%) (41672/44928)\n",
      "Epoch: 57 | Batch_idx: 360 |  Loss: (0.2122) | Acc: (92.70%) (42836/46208)\n",
      "Epoch: 57 | Batch_idx: 370 |  Loss: (0.2121) | Acc: (92.71%) (44025/47488)\n",
      "Epoch: 57 | Batch_idx: 380 |  Loss: (0.2130) | Acc: (92.68%) (45199/48768)\n",
      "Epoch: 57 | Batch_idx: 390 |  Loss: (0.2127) | Acc: (92.70%) (46350/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4645) | Acc: (85.46%) (8546/10000)\n",
      "Epoch: 58 | Batch_idx: 0 |  Loss: (0.1382) | Acc: (96.88%) (124/128)\n",
      "Epoch: 58 | Batch_idx: 10 |  Loss: (0.2018) | Acc: (92.97%) (1309/1408)\n",
      "Epoch: 58 | Batch_idx: 20 |  Loss: (0.2170) | Acc: (92.30%) (2481/2688)\n",
      "Epoch: 58 | Batch_idx: 30 |  Loss: (0.2089) | Acc: (92.92%) (3687/3968)\n",
      "Epoch: 58 | Batch_idx: 40 |  Loss: (0.2071) | Acc: (93.01%) (4881/5248)\n",
      "Epoch: 58 | Batch_idx: 50 |  Loss: (0.2094) | Acc: (92.78%) (6057/6528)\n",
      "Epoch: 58 | Batch_idx: 60 |  Loss: (0.2078) | Acc: (92.80%) (7246/7808)\n",
      "Epoch: 58 | Batch_idx: 70 |  Loss: (0.2021) | Acc: (92.91%) (8444/9088)\n",
      "Epoch: 58 | Batch_idx: 80 |  Loss: (0.1998) | Acc: (93.02%) (9644/10368)\n",
      "Epoch: 58 | Batch_idx: 90 |  Loss: (0.2010) | Acc: (93.01%) (10834/11648)\n",
      "Epoch: 58 | Batch_idx: 100 |  Loss: (0.2025) | Acc: (92.91%) (12012/12928)\n",
      "Epoch: 58 | Batch_idx: 110 |  Loss: (0.2026) | Acc: (92.87%) (13195/14208)\n",
      "Epoch: 58 | Batch_idx: 120 |  Loss: (0.2035) | Acc: (92.87%) (14383/15488)\n",
      "Epoch: 58 | Batch_idx: 130 |  Loss: (0.2033) | Acc: (92.87%) (15572/16768)\n",
      "Epoch: 58 | Batch_idx: 140 |  Loss: (0.2056) | Acc: (92.74%) (16738/18048)\n",
      "Epoch: 58 | Batch_idx: 150 |  Loss: (0.2069) | Acc: (92.69%) (17915/19328)\n",
      "Epoch: 58 | Batch_idx: 160 |  Loss: (0.2066) | Acc: (92.72%) (19107/20608)\n",
      "Epoch: 58 | Batch_idx: 170 |  Loss: (0.2066) | Acc: (92.69%) (20288/21888)\n",
      "Epoch: 58 | Batch_idx: 180 |  Loss: (0.2071) | Acc: (92.67%) (21470/23168)\n",
      "Epoch: 58 | Batch_idx: 190 |  Loss: (0.2076) | Acc: (92.63%) (22646/24448)\n",
      "Epoch: 58 | Batch_idx: 200 |  Loss: (0.2078) | Acc: (92.65%) (23838/25728)\n",
      "Epoch: 58 | Batch_idx: 210 |  Loss: (0.2086) | Acc: (92.65%) (25022/27008)\n",
      "Epoch: 58 | Batch_idx: 220 |  Loss: (0.2078) | Acc: (92.68%) (26216/28288)\n",
      "Epoch: 58 | Batch_idx: 230 |  Loss: (0.2076) | Acc: (92.68%) (27403/29568)\n",
      "Epoch: 58 | Batch_idx: 240 |  Loss: (0.2078) | Acc: (92.66%) (28585/30848)\n",
      "Epoch: 58 | Batch_idx: 250 |  Loss: (0.2078) | Acc: (92.66%) (29771/32128)\n",
      "Epoch: 58 | Batch_idx: 260 |  Loss: (0.2085) | Acc: (92.62%) (30944/33408)\n",
      "Epoch: 58 | Batch_idx: 270 |  Loss: (0.2070) | Acc: (92.69%) (32152/34688)\n",
      "Epoch: 58 | Batch_idx: 280 |  Loss: (0.2070) | Acc: (92.68%) (33334/35968)\n",
      "Epoch: 58 | Batch_idx: 290 |  Loss: (0.2067) | Acc: (92.70%) (34529/37248)\n",
      "Epoch: 58 | Batch_idx: 300 |  Loss: (0.2074) | Acc: (92.68%) (35709/38528)\n",
      "Epoch: 58 | Batch_idx: 310 |  Loss: (0.2085) | Acc: (92.63%) (36875/39808)\n",
      "Epoch: 58 | Batch_idx: 320 |  Loss: (0.2093) | Acc: (92.61%) (38050/41088)\n",
      "Epoch: 58 | Batch_idx: 330 |  Loss: (0.2103) | Acc: (92.60%) (39232/42368)\n",
      "Epoch: 58 | Batch_idx: 340 |  Loss: (0.2097) | Acc: (92.62%) (40426/43648)\n",
      "Epoch: 58 | Batch_idx: 350 |  Loss: (0.2102) | Acc: (92.59%) (41601/44928)\n",
      "Epoch: 58 | Batch_idx: 360 |  Loss: (0.2096) | Acc: (92.61%) (42795/46208)\n",
      "Epoch: 58 | Batch_idx: 370 |  Loss: (0.2087) | Acc: (92.64%) (43995/47488)\n",
      "Epoch: 58 | Batch_idx: 380 |  Loss: (0.2090) | Acc: (92.63%) (45172/48768)\n",
      "Epoch: 58 | Batch_idx: 390 |  Loss: (0.2099) | Acc: (92.60%) (46301/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4763) | Acc: (84.96%) (8496/10000)\n",
      "Epoch: 59 | Batch_idx: 0 |  Loss: (0.2567) | Acc: (87.50%) (112/128)\n",
      "Epoch: 59 | Batch_idx: 10 |  Loss: (0.1980) | Acc: (93.11%) (1311/1408)\n",
      "Epoch: 59 | Batch_idx: 20 |  Loss: (0.1954) | Acc: (93.30%) (2508/2688)\n",
      "Epoch: 59 | Batch_idx: 30 |  Loss: (0.1879) | Acc: (93.37%) (3705/3968)\n",
      "Epoch: 59 | Batch_idx: 40 |  Loss: (0.1830) | Acc: (93.52%) (4908/5248)\n",
      "Epoch: 59 | Batch_idx: 50 |  Loss: (0.1847) | Acc: (93.38%) (6096/6528)\n",
      "Epoch: 59 | Batch_idx: 60 |  Loss: (0.1914) | Acc: (93.14%) (7272/7808)\n",
      "Epoch: 59 | Batch_idx: 70 |  Loss: (0.1935) | Acc: (93.10%) (8461/9088)\n",
      "Epoch: 59 | Batch_idx: 80 |  Loss: (0.1945) | Acc: (92.98%) (9640/10368)\n",
      "Epoch: 59 | Batch_idx: 90 |  Loss: (0.1962) | Acc: (92.90%) (10821/11648)\n",
      "Epoch: 59 | Batch_idx: 100 |  Loss: (0.1978) | Acc: (92.88%) (12007/12928)\n",
      "Epoch: 59 | Batch_idx: 110 |  Loss: (0.1950) | Acc: (92.95%) (13207/14208)\n",
      "Epoch: 59 | Batch_idx: 120 |  Loss: (0.1926) | Acc: (93.08%) (14416/15488)\n",
      "Epoch: 59 | Batch_idx: 130 |  Loss: (0.1919) | Acc: (93.12%) (15614/16768)\n",
      "Epoch: 59 | Batch_idx: 140 |  Loss: (0.1922) | Acc: (93.19%) (16819/18048)\n",
      "Epoch: 59 | Batch_idx: 150 |  Loss: (0.1923) | Acc: (93.23%) (18020/19328)\n",
      "Epoch: 59 | Batch_idx: 160 |  Loss: (0.1939) | Acc: (93.22%) (19211/20608)\n",
      "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1950) | Acc: (93.17%) (20392/21888)\n",
      "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1946) | Acc: (93.18%) (21589/23168)\n",
      "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1956) | Acc: (93.13%) (22768/24448)\n",
      "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1956) | Acc: (93.12%) (23957/25728)\n",
      "Epoch: 59 | Batch_idx: 210 |  Loss: (0.1965) | Acc: (93.11%) (25146/27008)\n",
      "Epoch: 59 | Batch_idx: 220 |  Loss: (0.1991) | Acc: (92.99%) (26306/28288)\n",
      "Epoch: 59 | Batch_idx: 230 |  Loss: (0.1994) | Acc: (92.96%) (27487/29568)\n",
      "Epoch: 59 | Batch_idx: 240 |  Loss: (0.1984) | Acc: (93.02%) (28694/30848)\n",
      "Epoch: 59 | Batch_idx: 250 |  Loss: (0.1973) | Acc: (93.08%) (29904/32128)\n",
      "Epoch: 59 | Batch_idx: 260 |  Loss: (0.1971) | Acc: (93.09%) (31099/33408)\n",
      "Epoch: 59 | Batch_idx: 270 |  Loss: (0.1985) | Acc: (93.05%) (32277/34688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 | Batch_idx: 280 |  Loss: (0.1985) | Acc: (93.05%) (33468/35968)\n",
      "Epoch: 59 | Batch_idx: 290 |  Loss: (0.1984) | Acc: (93.05%) (34658/37248)\n",
      "Epoch: 59 | Batch_idx: 300 |  Loss: (0.1990) | Acc: (93.02%) (35837/38528)\n",
      "Epoch: 59 | Batch_idx: 310 |  Loss: (0.1996) | Acc: (93.02%) (37029/39808)\n",
      "Epoch: 59 | Batch_idx: 320 |  Loss: (0.1990) | Acc: (93.05%) (38233/41088)\n",
      "Epoch: 59 | Batch_idx: 330 |  Loss: (0.1991) | Acc: (93.07%) (39430/42368)\n",
      "Epoch: 59 | Batch_idx: 340 |  Loss: (0.1993) | Acc: (93.05%) (40613/43648)\n",
      "Epoch: 59 | Batch_idx: 350 |  Loss: (0.1991) | Acc: (93.06%) (41810/44928)\n",
      "Epoch: 59 | Batch_idx: 360 |  Loss: (0.1995) | Acc: (93.09%) (43013/46208)\n",
      "Epoch: 59 | Batch_idx: 370 |  Loss: (0.2000) | Acc: (93.07%) (44195/47488)\n",
      "Epoch: 59 | Batch_idx: 380 |  Loss: (0.2001) | Acc: (93.06%) (45384/48768)\n",
      "Epoch: 59 | Batch_idx: 390 |  Loss: (0.2007) | Acc: (93.06%) (46532/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4835) | Acc: (85.71%) (8571/10000)\n",
      "Epoch: 60 | Batch_idx: 0 |  Loss: (0.2265) | Acc: (92.19%) (118/128)\n",
      "Epoch: 60 | Batch_idx: 10 |  Loss: (0.2092) | Acc: (92.90%) (1308/1408)\n",
      "Epoch: 60 | Batch_idx: 20 |  Loss: (0.2094) | Acc: (92.82%) (2495/2688)\n",
      "Epoch: 60 | Batch_idx: 30 |  Loss: (0.1972) | Acc: (93.35%) (3704/3968)\n",
      "Epoch: 60 | Batch_idx: 40 |  Loss: (0.1971) | Acc: (93.35%) (4899/5248)\n",
      "Epoch: 60 | Batch_idx: 50 |  Loss: (0.1926) | Acc: (93.41%) (6098/6528)\n",
      "Epoch: 60 | Batch_idx: 60 |  Loss: (0.1914) | Acc: (93.33%) (7287/7808)\n",
      "Epoch: 60 | Batch_idx: 70 |  Loss: (0.1902) | Acc: (93.23%) (8473/9088)\n",
      "Epoch: 60 | Batch_idx: 80 |  Loss: (0.1902) | Acc: (93.27%) (9670/10368)\n",
      "Epoch: 60 | Batch_idx: 90 |  Loss: (0.1914) | Acc: (93.22%) (10858/11648)\n",
      "Epoch: 60 | Batch_idx: 100 |  Loss: (0.1920) | Acc: (93.18%) (12046/12928)\n",
      "Epoch: 60 | Batch_idx: 110 |  Loss: (0.1925) | Acc: (93.20%) (13242/14208)\n",
      "Epoch: 60 | Batch_idx: 120 |  Loss: (0.1924) | Acc: (93.17%) (14430/15488)\n",
      "Epoch: 60 | Batch_idx: 130 |  Loss: (0.1940) | Acc: (93.10%) (15611/16768)\n",
      "Epoch: 60 | Batch_idx: 140 |  Loss: (0.1954) | Acc: (93.02%) (16788/18048)\n",
      "Epoch: 60 | Batch_idx: 150 |  Loss: (0.1951) | Acc: (93.04%) (17983/19328)\n",
      "Epoch: 60 | Batch_idx: 160 |  Loss: (0.1963) | Acc: (93.05%) (19175/20608)\n",
      "Epoch: 60 | Batch_idx: 170 |  Loss: (0.1961) | Acc: (93.09%) (20375/21888)\n",
      "Epoch: 60 | Batch_idx: 180 |  Loss: (0.1949) | Acc: (93.14%) (21578/23168)\n",
      "Epoch: 60 | Batch_idx: 190 |  Loss: (0.1946) | Acc: (93.14%) (22772/24448)\n",
      "Epoch: 60 | Batch_idx: 200 |  Loss: (0.1954) | Acc: (93.16%) (23969/25728)\n",
      "Epoch: 60 | Batch_idx: 210 |  Loss: (0.1937) | Acc: (93.24%) (25183/27008)\n",
      "Epoch: 60 | Batch_idx: 220 |  Loss: (0.1940) | Acc: (93.22%) (26371/28288)\n",
      "Epoch: 60 | Batch_idx: 230 |  Loss: (0.1942) | Acc: (93.21%) (27559/29568)\n",
      "Epoch: 60 | Batch_idx: 240 |  Loss: (0.1943) | Acc: (93.20%) (28751/30848)\n",
      "Epoch: 60 | Batch_idx: 250 |  Loss: (0.1948) | Acc: (93.21%) (29947/32128)\n",
      "Epoch: 60 | Batch_idx: 260 |  Loss: (0.1946) | Acc: (93.22%) (31143/33408)\n",
      "Epoch: 60 | Batch_idx: 270 |  Loss: (0.1955) | Acc: (93.14%) (32309/34688)\n",
      "Epoch: 60 | Batch_idx: 280 |  Loss: (0.1958) | Acc: (93.12%) (33493/35968)\n",
      "Epoch: 60 | Batch_idx: 290 |  Loss: (0.1966) | Acc: (93.07%) (34665/37248)\n",
      "Epoch: 60 | Batch_idx: 300 |  Loss: (0.1964) | Acc: (93.07%) (35859/38528)\n",
      "Epoch: 60 | Batch_idx: 310 |  Loss: (0.1968) | Acc: (93.06%) (37047/39808)\n",
      "Epoch: 60 | Batch_idx: 320 |  Loss: (0.1969) | Acc: (93.08%) (38244/41088)\n",
      "Epoch: 60 | Batch_idx: 330 |  Loss: (0.1968) | Acc: (93.08%) (39436/42368)\n",
      "Epoch: 60 | Batch_idx: 340 |  Loss: (0.1975) | Acc: (93.04%) (40608/43648)\n",
      "Epoch: 60 | Batch_idx: 350 |  Loss: (0.1974) | Acc: (93.04%) (41803/44928)\n",
      "Epoch: 60 | Batch_idx: 360 |  Loss: (0.1978) | Acc: (93.04%) (42994/46208)\n",
      "Epoch: 60 | Batch_idx: 370 |  Loss: (0.1981) | Acc: (93.04%) (44181/47488)\n",
      "Epoch: 60 | Batch_idx: 380 |  Loss: (0.1977) | Acc: (93.05%) (45381/48768)\n",
      "Epoch: 60 | Batch_idx: 390 |  Loss: (0.1980) | Acc: (93.03%) (46517/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4788) | Acc: (85.14%) (8514/10000)\n",
      "Epoch: 61 | Batch_idx: 0 |  Loss: (0.2058) | Acc: (93.75%) (120/128)\n",
      "Epoch: 61 | Batch_idx: 10 |  Loss: (0.2043) | Acc: (93.39%) (1315/1408)\n",
      "Epoch: 61 | Batch_idx: 20 |  Loss: (0.2002) | Acc: (93.71%) (2519/2688)\n",
      "Epoch: 61 | Batch_idx: 30 |  Loss: (0.2005) | Acc: (93.42%) (3707/3968)\n",
      "Epoch: 61 | Batch_idx: 40 |  Loss: (0.2086) | Acc: (93.10%) (4886/5248)\n",
      "Epoch: 61 | Batch_idx: 50 |  Loss: (0.2027) | Acc: (93.18%) (6083/6528)\n",
      "Epoch: 61 | Batch_idx: 60 |  Loss: (0.2011) | Acc: (93.28%) (7283/7808)\n",
      "Epoch: 61 | Batch_idx: 70 |  Loss: (0.1999) | Acc: (93.31%) (8480/9088)\n",
      "Epoch: 61 | Batch_idx: 80 |  Loss: (0.1974) | Acc: (93.32%) (9675/10368)\n",
      "Epoch: 61 | Batch_idx: 90 |  Loss: (0.1981) | Acc: (93.24%) (10861/11648)\n",
      "Epoch: 61 | Batch_idx: 100 |  Loss: (0.1964) | Acc: (93.30%) (12062/12928)\n",
      "Epoch: 61 | Batch_idx: 110 |  Loss: (0.1978) | Acc: (93.31%) (13257/14208)\n",
      "Epoch: 61 | Batch_idx: 120 |  Loss: (0.1977) | Acc: (93.30%) (14450/15488)\n",
      "Epoch: 61 | Batch_idx: 130 |  Loss: (0.1963) | Acc: (93.34%) (15652/16768)\n",
      "Epoch: 61 | Batch_idx: 140 |  Loss: (0.1964) | Acc: (93.37%) (16852/18048)\n",
      "Epoch: 61 | Batch_idx: 150 |  Loss: (0.1978) | Acc: (93.30%) (18033/19328)\n",
      "Epoch: 61 | Batch_idx: 160 |  Loss: (0.1979) | Acc: (93.33%) (19233/20608)\n",
      "Epoch: 61 | Batch_idx: 170 |  Loss: (0.1992) | Acc: (93.30%) (20421/21888)\n",
      "Epoch: 61 | Batch_idx: 180 |  Loss: (0.2001) | Acc: (93.28%) (21612/23168)\n",
      "Epoch: 61 | Batch_idx: 190 |  Loss: (0.2003) | Acc: (93.27%) (22802/24448)\n",
      "Epoch: 61 | Batch_idx: 200 |  Loss: (0.1995) | Acc: (93.24%) (23990/25728)\n",
      "Epoch: 61 | Batch_idx: 210 |  Loss: (0.1995) | Acc: (93.24%) (25181/27008)\n",
      "Epoch: 61 | Batch_idx: 220 |  Loss: (0.1985) | Acc: (93.27%) (26384/28288)\n",
      "Epoch: 61 | Batch_idx: 230 |  Loss: (0.1992) | Acc: (93.27%) (27577/29568)\n",
      "Epoch: 61 | Batch_idx: 240 |  Loss: (0.1991) | Acc: (93.24%) (28762/30848)\n",
      "Epoch: 61 | Batch_idx: 250 |  Loss: (0.1996) | Acc: (93.19%) (29940/32128)\n",
      "Epoch: 61 | Batch_idx: 260 |  Loss: (0.1988) | Acc: (93.21%) (31140/33408)\n",
      "Epoch: 61 | Batch_idx: 270 |  Loss: (0.1994) | Acc: (93.18%) (32323/34688)\n",
      "Epoch: 61 | Batch_idx: 280 |  Loss: (0.1989) | Acc: (93.20%) (33522/35968)\n",
      "Epoch: 61 | Batch_idx: 290 |  Loss: (0.1998) | Acc: (93.16%) (34701/37248)\n",
      "Epoch: 61 | Batch_idx: 300 |  Loss: (0.2008) | Acc: (93.13%) (35880/38528)\n",
      "Epoch: 61 | Batch_idx: 310 |  Loss: (0.2013) | Acc: (93.08%) (37054/39808)\n",
      "Epoch: 61 | Batch_idx: 320 |  Loss: (0.2010) | Acc: (93.10%) (38252/41088)\n",
      "Epoch: 61 | Batch_idx: 330 |  Loss: (0.2013) | Acc: (93.08%) (39437/42368)\n",
      "Epoch: 61 | Batch_idx: 340 |  Loss: (0.2012) | Acc: (93.06%) (40621/43648)\n",
      "Epoch: 61 | Batch_idx: 350 |  Loss: (0.2013) | Acc: (93.06%) (41808/44928)\n",
      "Epoch: 61 | Batch_idx: 360 |  Loss: (0.2014) | Acc: (93.05%) (42997/46208)\n",
      "Epoch: 61 | Batch_idx: 370 |  Loss: (0.2008) | Acc: (93.07%) (44195/47488)\n",
      "Epoch: 61 | Batch_idx: 380 |  Loss: (0.2005) | Acc: (93.07%) (45386/48768)\n",
      "Epoch: 61 | Batch_idx: 390 |  Loss: (0.2005) | Acc: (93.08%) (46539/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4467) | Acc: (86.14%) (8614/10000)\n",
      "Epoch: 62 | Batch_idx: 0 |  Loss: (0.1901) | Acc: (93.75%) (120/128)\n",
      "Epoch: 62 | Batch_idx: 10 |  Loss: (0.1827) | Acc: (94.25%) (1327/1408)\n",
      "Epoch: 62 | Batch_idx: 20 |  Loss: (0.1842) | Acc: (93.64%) (2517/2688)\n",
      "Epoch: 62 | Batch_idx: 30 |  Loss: (0.1829) | Acc: (93.70%) (3718/3968)\n",
      "Epoch: 62 | Batch_idx: 40 |  Loss: (0.1927) | Acc: (93.27%) (4895/5248)\n",
      "Epoch: 62 | Batch_idx: 50 |  Loss: (0.1973) | Acc: (93.21%) (6085/6528)\n",
      "Epoch: 62 | Batch_idx: 60 |  Loss: (0.1930) | Acc: (93.40%) (7293/7808)\n",
      "Epoch: 62 | Batch_idx: 70 |  Loss: (0.1926) | Acc: (93.43%) (8491/9088)\n",
      "Epoch: 62 | Batch_idx: 80 |  Loss: (0.1932) | Acc: (93.31%) (9674/10368)\n",
      "Epoch: 62 | Batch_idx: 90 |  Loss: (0.1913) | Acc: (93.37%) (10876/11648)\n",
      "Epoch: 62 | Batch_idx: 100 |  Loss: (0.1891) | Acc: (93.44%) (12080/12928)\n",
      "Epoch: 62 | Batch_idx: 110 |  Loss: (0.1866) | Acc: (93.54%) (13290/14208)\n",
      "Epoch: 62 | Batch_idx: 120 |  Loss: (0.1853) | Acc: (93.61%) (14499/15488)\n",
      "Epoch: 62 | Batch_idx: 130 |  Loss: (0.1884) | Acc: (93.54%) (15684/16768)\n",
      "Epoch: 62 | Batch_idx: 140 |  Loss: (0.1915) | Acc: (93.40%) (16857/18048)\n",
      "Epoch: 62 | Batch_idx: 150 |  Loss: (0.1917) | Acc: (93.39%) (18050/19328)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | Batch_idx: 160 |  Loss: (0.1916) | Acc: (93.35%) (19238/20608)\n",
      "Epoch: 62 | Batch_idx: 170 |  Loss: (0.1913) | Acc: (93.31%) (20424/21888)\n",
      "Epoch: 62 | Batch_idx: 180 |  Loss: (0.1915) | Acc: (93.29%) (21613/23168)\n",
      "Epoch: 62 | Batch_idx: 190 |  Loss: (0.1944) | Acc: (93.21%) (22787/24448)\n",
      "Epoch: 62 | Batch_idx: 200 |  Loss: (0.1941) | Acc: (93.22%) (23984/25728)\n",
      "Epoch: 62 | Batch_idx: 210 |  Loss: (0.1943) | Acc: (93.20%) (25172/27008)\n",
      "Epoch: 62 | Batch_idx: 220 |  Loss: (0.1948) | Acc: (93.18%) (26359/28288)\n",
      "Epoch: 62 | Batch_idx: 230 |  Loss: (0.1938) | Acc: (93.19%) (27554/29568)\n",
      "Epoch: 62 | Batch_idx: 240 |  Loss: (0.1938) | Acc: (93.21%) (28752/30848)\n",
      "Epoch: 62 | Batch_idx: 250 |  Loss: (0.1944) | Acc: (93.18%) (29937/32128)\n",
      "Epoch: 62 | Batch_idx: 260 |  Loss: (0.1943) | Acc: (93.19%) (31132/33408)\n",
      "Epoch: 62 | Batch_idx: 270 |  Loss: (0.1943) | Acc: (93.17%) (32319/34688)\n",
      "Epoch: 62 | Batch_idx: 280 |  Loss: (0.1938) | Acc: (93.20%) (33521/35968)\n",
      "Epoch: 62 | Batch_idx: 290 |  Loss: (0.1934) | Acc: (93.20%) (34716/37248)\n",
      "Epoch: 62 | Batch_idx: 300 |  Loss: (0.1931) | Acc: (93.23%) (35918/38528)\n",
      "Epoch: 62 | Batch_idx: 310 |  Loss: (0.1940) | Acc: (93.21%) (37106/39808)\n",
      "Epoch: 62 | Batch_idx: 320 |  Loss: (0.1940) | Acc: (93.20%) (38293/41088)\n",
      "Epoch: 62 | Batch_idx: 330 |  Loss: (0.1942) | Acc: (93.19%) (39484/42368)\n",
      "Epoch: 62 | Batch_idx: 340 |  Loss: (0.1942) | Acc: (93.20%) (40678/43648)\n",
      "Epoch: 62 | Batch_idx: 350 |  Loss: (0.1933) | Acc: (93.22%) (41881/44928)\n",
      "Epoch: 62 | Batch_idx: 360 |  Loss: (0.1929) | Acc: (93.24%) (43083/46208)\n",
      "Epoch: 62 | Batch_idx: 370 |  Loss: (0.1935) | Acc: (93.22%) (44268/47488)\n",
      "Epoch: 62 | Batch_idx: 380 |  Loss: (0.1937) | Acc: (93.21%) (45456/48768)\n",
      "Epoch: 62 | Batch_idx: 390 |  Loss: (0.1953) | Acc: (93.15%) (46573/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4999) | Acc: (84.84%) (8484/10000)\n",
      "Epoch: 63 | Batch_idx: 0 |  Loss: (0.2454) | Acc: (92.97%) (119/128)\n",
      "Epoch: 63 | Batch_idx: 10 |  Loss: (0.1996) | Acc: (93.32%) (1314/1408)\n",
      "Epoch: 63 | Batch_idx: 20 |  Loss: (0.1839) | Acc: (94.08%) (2529/2688)\n",
      "Epoch: 63 | Batch_idx: 30 |  Loss: (0.1744) | Acc: (94.41%) (3746/3968)\n",
      "Epoch: 63 | Batch_idx: 40 |  Loss: (0.1827) | Acc: (93.81%) (4923/5248)\n",
      "Epoch: 63 | Batch_idx: 50 |  Loss: (0.1786) | Acc: (94.03%) (6138/6528)\n",
      "Epoch: 63 | Batch_idx: 60 |  Loss: (0.1796) | Acc: (93.99%) (7339/7808)\n",
      "Epoch: 63 | Batch_idx: 70 |  Loss: (0.1777) | Acc: (93.98%) (8541/9088)\n",
      "Epoch: 63 | Batch_idx: 80 |  Loss: (0.1804) | Acc: (93.95%) (9741/10368)\n",
      "Epoch: 63 | Batch_idx: 90 |  Loss: (0.1768) | Acc: (94.08%) (10959/11648)\n",
      "Epoch: 63 | Batch_idx: 100 |  Loss: (0.1770) | Acc: (94.07%) (12161/12928)\n",
      "Epoch: 63 | Batch_idx: 110 |  Loss: (0.1769) | Acc: (94.05%) (13363/14208)\n",
      "Epoch: 63 | Batch_idx: 120 |  Loss: (0.1757) | Acc: (94.09%) (14573/15488)\n",
      "Epoch: 63 | Batch_idx: 130 |  Loss: (0.1780) | Acc: (94.00%) (15762/16768)\n",
      "Epoch: 63 | Batch_idx: 140 |  Loss: (0.1787) | Acc: (94.01%) (16967/18048)\n",
      "Epoch: 63 | Batch_idx: 150 |  Loss: (0.1800) | Acc: (93.94%) (18157/19328)\n",
      "Epoch: 63 | Batch_idx: 160 |  Loss: (0.1796) | Acc: (93.92%) (19356/20608)\n",
      "Epoch: 63 | Batch_idx: 170 |  Loss: (0.1799) | Acc: (93.90%) (20553/21888)\n",
      "Epoch: 63 | Batch_idx: 180 |  Loss: (0.1833) | Acc: (93.78%) (21726/23168)\n",
      "Epoch: 63 | Batch_idx: 190 |  Loss: (0.1838) | Acc: (93.75%) (22919/24448)\n",
      "Epoch: 63 | Batch_idx: 200 |  Loss: (0.1830) | Acc: (93.78%) (24127/25728)\n",
      "Epoch: 63 | Batch_idx: 210 |  Loss: (0.1826) | Acc: (93.81%) (25336/27008)\n",
      "Epoch: 63 | Batch_idx: 220 |  Loss: (0.1832) | Acc: (93.76%) (26524/28288)\n",
      "Epoch: 63 | Batch_idx: 230 |  Loss: (0.1828) | Acc: (93.76%) (27722/29568)\n",
      "Epoch: 63 | Batch_idx: 240 |  Loss: (0.1842) | Acc: (93.71%) (28907/30848)\n",
      "Epoch: 63 | Batch_idx: 250 |  Loss: (0.1843) | Acc: (93.68%) (30098/32128)\n",
      "Epoch: 63 | Batch_idx: 260 |  Loss: (0.1851) | Acc: (93.65%) (31288/33408)\n",
      "Epoch: 63 | Batch_idx: 270 |  Loss: (0.1862) | Acc: (93.61%) (32473/34688)\n",
      "Epoch: 63 | Batch_idx: 280 |  Loss: (0.1868) | Acc: (93.58%) (33658/35968)\n",
      "Epoch: 63 | Batch_idx: 290 |  Loss: (0.1880) | Acc: (93.54%) (34841/37248)\n",
      "Epoch: 63 | Batch_idx: 300 |  Loss: (0.1890) | Acc: (93.49%) (36020/38528)\n",
      "Epoch: 63 | Batch_idx: 310 |  Loss: (0.1898) | Acc: (93.46%) (37204/39808)\n",
      "Epoch: 63 | Batch_idx: 320 |  Loss: (0.1892) | Acc: (93.47%) (38407/41088)\n",
      "Epoch: 63 | Batch_idx: 330 |  Loss: (0.1889) | Acc: (93.49%) (39609/42368)\n",
      "Epoch: 63 | Batch_idx: 340 |  Loss: (0.1899) | Acc: (93.47%) (40799/43648)\n",
      "Epoch: 63 | Batch_idx: 350 |  Loss: (0.1899) | Acc: (93.47%) (41996/44928)\n",
      "Epoch: 63 | Batch_idx: 360 |  Loss: (0.1895) | Acc: (93.49%) (43201/46208)\n",
      "Epoch: 63 | Batch_idx: 370 |  Loss: (0.1897) | Acc: (93.49%) (44395/47488)\n",
      "Epoch: 63 | Batch_idx: 380 |  Loss: (0.1898) | Acc: (93.49%) (45592/48768)\n",
      "Epoch: 63 | Batch_idx: 390 |  Loss: (0.1898) | Acc: (93.50%) (46751/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5663) | Acc: (83.57%) (8357/10000)\n",
      "Epoch: 64 | Batch_idx: 0 |  Loss: (0.1864) | Acc: (92.19%) (118/128)\n",
      "Epoch: 64 | Batch_idx: 10 |  Loss: (0.1948) | Acc: (93.18%) (1312/1408)\n",
      "Epoch: 64 | Batch_idx: 20 |  Loss: (0.1852) | Acc: (93.97%) (2526/2688)\n",
      "Epoch: 64 | Batch_idx: 30 |  Loss: (0.1852) | Acc: (93.98%) (3729/3968)\n",
      "Epoch: 64 | Batch_idx: 40 |  Loss: (0.1830) | Acc: (93.90%) (4928/5248)\n",
      "Epoch: 64 | Batch_idx: 50 |  Loss: (0.1799) | Acc: (93.96%) (6134/6528)\n",
      "Epoch: 64 | Batch_idx: 60 |  Loss: (0.1778) | Acc: (94.07%) (7345/7808)\n",
      "Epoch: 64 | Batch_idx: 70 |  Loss: (0.1762) | Acc: (94.04%) (8546/9088)\n",
      "Epoch: 64 | Batch_idx: 80 |  Loss: (0.1775) | Acc: (93.96%) (9742/10368)\n",
      "Epoch: 64 | Batch_idx: 90 |  Loss: (0.1787) | Acc: (93.92%) (10940/11648)\n",
      "Epoch: 64 | Batch_idx: 100 |  Loss: (0.1789) | Acc: (93.91%) (12141/12928)\n",
      "Epoch: 64 | Batch_idx: 110 |  Loss: (0.1788) | Acc: (93.90%) (13342/14208)\n",
      "Epoch: 64 | Batch_idx: 120 |  Loss: (0.1776) | Acc: (93.95%) (14551/15488)\n",
      "Epoch: 64 | Batch_idx: 130 |  Loss: (0.1791) | Acc: (93.88%) (15742/16768)\n",
      "Epoch: 64 | Batch_idx: 140 |  Loss: (0.1783) | Acc: (93.91%) (16949/18048)\n",
      "Epoch: 64 | Batch_idx: 150 |  Loss: (0.1793) | Acc: (93.87%) (18144/19328)\n",
      "Epoch: 64 | Batch_idx: 160 |  Loss: (0.1807) | Acc: (93.83%) (19336/20608)\n",
      "Epoch: 64 | Batch_idx: 170 |  Loss: (0.1818) | Acc: (93.79%) (20529/21888)\n",
      "Epoch: 64 | Batch_idx: 180 |  Loss: (0.1814) | Acc: (93.78%) (21728/23168)\n",
      "Epoch: 64 | Batch_idx: 190 |  Loss: (0.1811) | Acc: (93.79%) (22929/24448)\n",
      "Epoch: 64 | Batch_idx: 200 |  Loss: (0.1815) | Acc: (93.77%) (24126/25728)\n",
      "Epoch: 64 | Batch_idx: 210 |  Loss: (0.1818) | Acc: (93.73%) (25314/27008)\n",
      "Epoch: 64 | Batch_idx: 220 |  Loss: (0.1825) | Acc: (93.68%) (26499/28288)\n",
      "Epoch: 64 | Batch_idx: 230 |  Loss: (0.1823) | Acc: (93.69%) (27702/29568)\n",
      "Epoch: 64 | Batch_idx: 240 |  Loss: (0.1826) | Acc: (93.68%) (28899/30848)\n",
      "Epoch: 64 | Batch_idx: 250 |  Loss: (0.1829) | Acc: (93.68%) (30099/32128)\n",
      "Epoch: 64 | Batch_idx: 260 |  Loss: (0.1826) | Acc: (93.69%) (31301/33408)\n",
      "Epoch: 64 | Batch_idx: 270 |  Loss: (0.1831) | Acc: (93.68%) (32496/34688)\n",
      "Epoch: 64 | Batch_idx: 280 |  Loss: (0.1838) | Acc: (93.65%) (33685/35968)\n",
      "Epoch: 64 | Batch_idx: 290 |  Loss: (0.1834) | Acc: (93.64%) (34878/37248)\n",
      "Epoch: 64 | Batch_idx: 300 |  Loss: (0.1835) | Acc: (93.63%) (36072/38528)\n",
      "Epoch: 64 | Batch_idx: 310 |  Loss: (0.1840) | Acc: (93.61%) (37266/39808)\n",
      "Epoch: 64 | Batch_idx: 320 |  Loss: (0.1840) | Acc: (93.60%) (38460/41088)\n",
      "Epoch: 64 | Batch_idx: 330 |  Loss: (0.1841) | Acc: (93.60%) (39658/42368)\n",
      "Epoch: 64 | Batch_idx: 340 |  Loss: (0.1846) | Acc: (93.60%) (40853/43648)\n",
      "Epoch: 64 | Batch_idx: 350 |  Loss: (0.1851) | Acc: (93.60%) (42051/44928)\n",
      "Epoch: 64 | Batch_idx: 360 |  Loss: (0.1850) | Acc: (93.60%) (43251/46208)\n",
      "Epoch: 64 | Batch_idx: 370 |  Loss: (0.1853) | Acc: (93.59%) (44443/47488)\n",
      "Epoch: 64 | Batch_idx: 380 |  Loss: (0.1854) | Acc: (93.57%) (45633/48768)\n",
      "Epoch: 64 | Batch_idx: 390 |  Loss: (0.1855) | Acc: (93.55%) (46777/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4425) | Acc: (86.57%) (8657/10000)\n",
      "Epoch: 65 | Batch_idx: 0 |  Loss: (0.2095) | Acc: (91.41%) (117/128)\n",
      "Epoch: 65 | Batch_idx: 10 |  Loss: (0.1717) | Acc: (93.54%) (1317/1408)\n",
      "Epoch: 65 | Batch_idx: 20 |  Loss: (0.1771) | Acc: (93.45%) (2512/2688)\n",
      "Epoch: 65 | Batch_idx: 30 |  Loss: (0.1759) | Acc: (93.50%) (3710/3968)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 | Batch_idx: 40 |  Loss: (0.1727) | Acc: (93.73%) (4919/5248)\n",
      "Epoch: 65 | Batch_idx: 50 |  Loss: (0.1744) | Acc: (93.73%) (6119/6528)\n",
      "Epoch: 65 | Batch_idx: 60 |  Loss: (0.1756) | Acc: (93.80%) (7324/7808)\n",
      "Epoch: 65 | Batch_idx: 70 |  Loss: (0.1756) | Acc: (93.78%) (8523/9088)\n",
      "Epoch: 65 | Batch_idx: 80 |  Loss: (0.1775) | Acc: (93.66%) (9711/10368)\n",
      "Epoch: 65 | Batch_idx: 90 |  Loss: (0.1798) | Acc: (93.60%) (10902/11648)\n",
      "Epoch: 65 | Batch_idx: 100 |  Loss: (0.1789) | Acc: (93.71%) (12115/12928)\n",
      "Epoch: 65 | Batch_idx: 110 |  Loss: (0.1785) | Acc: (93.72%) (13316/14208)\n",
      "Epoch: 65 | Batch_idx: 120 |  Loss: (0.1784) | Acc: (93.72%) (14516/15488)\n",
      "Epoch: 65 | Batch_idx: 130 |  Loss: (0.1786) | Acc: (93.73%) (15717/16768)\n",
      "Epoch: 65 | Batch_idx: 140 |  Loss: (0.1799) | Acc: (93.69%) (16910/18048)\n",
      "Epoch: 65 | Batch_idx: 150 |  Loss: (0.1799) | Acc: (93.73%) (18116/19328)\n",
      "Epoch: 65 | Batch_idx: 160 |  Loss: (0.1789) | Acc: (93.76%) (19323/20608)\n",
      "Epoch: 65 | Batch_idx: 170 |  Loss: (0.1783) | Acc: (93.83%) (20537/21888)\n",
      "Epoch: 65 | Batch_idx: 180 |  Loss: (0.1784) | Acc: (93.82%) (21736/23168)\n",
      "Epoch: 65 | Batch_idx: 190 |  Loss: (0.1790) | Acc: (93.77%) (22926/24448)\n",
      "Epoch: 65 | Batch_idx: 200 |  Loss: (0.1785) | Acc: (93.80%) (24133/25728)\n",
      "Epoch: 65 | Batch_idx: 210 |  Loss: (0.1781) | Acc: (93.79%) (25332/27008)\n",
      "Epoch: 65 | Batch_idx: 220 |  Loss: (0.1780) | Acc: (93.81%) (26536/28288)\n",
      "Epoch: 65 | Batch_idx: 230 |  Loss: (0.1782) | Acc: (93.80%) (27736/29568)\n",
      "Epoch: 65 | Batch_idx: 240 |  Loss: (0.1790) | Acc: (93.78%) (28930/30848)\n",
      "Epoch: 65 | Batch_idx: 250 |  Loss: (0.1784) | Acc: (93.79%) (30133/32128)\n",
      "Epoch: 65 | Batch_idx: 260 |  Loss: (0.1780) | Acc: (93.79%) (31335/33408)\n",
      "Epoch: 65 | Batch_idx: 270 |  Loss: (0.1784) | Acc: (93.78%) (32530/34688)\n",
      "Epoch: 65 | Batch_idx: 280 |  Loss: (0.1785) | Acc: (93.78%) (33730/35968)\n",
      "Epoch: 65 | Batch_idx: 290 |  Loss: (0.1783) | Acc: (93.78%) (34931/37248)\n",
      "Epoch: 65 | Batch_idx: 300 |  Loss: (0.1782) | Acc: (93.78%) (36133/38528)\n",
      "Epoch: 65 | Batch_idx: 310 |  Loss: (0.1782) | Acc: (93.79%) (37334/39808)\n",
      "Epoch: 65 | Batch_idx: 320 |  Loss: (0.1788) | Acc: (93.76%) (38526/41088)\n",
      "Epoch: 65 | Batch_idx: 330 |  Loss: (0.1788) | Acc: (93.76%) (39726/42368)\n",
      "Epoch: 65 | Batch_idx: 340 |  Loss: (0.1788) | Acc: (93.77%) (40928/43648)\n",
      "Epoch: 65 | Batch_idx: 350 |  Loss: (0.1789) | Acc: (93.76%) (42125/44928)\n",
      "Epoch: 65 | Batch_idx: 360 |  Loss: (0.1791) | Acc: (93.76%) (43324/46208)\n",
      "Epoch: 65 | Batch_idx: 370 |  Loss: (0.1796) | Acc: (93.74%) (44515/47488)\n",
      "Epoch: 65 | Batch_idx: 380 |  Loss: (0.1808) | Acc: (93.69%) (45692/48768)\n",
      "Epoch: 65 | Batch_idx: 390 |  Loss: (0.1810) | Acc: (93.69%) (46843/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4490) | Acc: (86.62%) (8662/10000)\n",
      "Epoch: 66 | Batch_idx: 0 |  Loss: (0.1409) | Acc: (96.09%) (123/128)\n",
      "Epoch: 66 | Batch_idx: 10 |  Loss: (0.1710) | Acc: (94.32%) (1328/1408)\n",
      "Epoch: 66 | Batch_idx: 20 |  Loss: (0.1757) | Acc: (93.79%) (2521/2688)\n",
      "Epoch: 66 | Batch_idx: 30 |  Loss: (0.1699) | Acc: (94.08%) (3733/3968)\n",
      "Epoch: 66 | Batch_idx: 40 |  Loss: (0.1677) | Acc: (94.15%) (4941/5248)\n",
      "Epoch: 66 | Batch_idx: 50 |  Loss: (0.1668) | Acc: (94.27%) (6154/6528)\n",
      "Epoch: 66 | Batch_idx: 60 |  Loss: (0.1676) | Acc: (94.25%) (7359/7808)\n",
      "Epoch: 66 | Batch_idx: 70 |  Loss: (0.1651) | Acc: (94.33%) (8573/9088)\n",
      "Epoch: 66 | Batch_idx: 80 |  Loss: (0.1663) | Acc: (94.22%) (9769/10368)\n",
      "Epoch: 66 | Batch_idx: 90 |  Loss: (0.1671) | Acc: (94.20%) (10972/11648)\n",
      "Epoch: 66 | Batch_idx: 100 |  Loss: (0.1671) | Acc: (94.24%) (12183/12928)\n",
      "Epoch: 66 | Batch_idx: 110 |  Loss: (0.1658) | Acc: (94.29%) (13397/14208)\n",
      "Epoch: 66 | Batch_idx: 120 |  Loss: (0.1662) | Acc: (94.25%) (14597/15488)\n",
      "Epoch: 66 | Batch_idx: 130 |  Loss: (0.1654) | Acc: (94.26%) (15805/16768)\n",
      "Epoch: 66 | Batch_idx: 140 |  Loss: (0.1659) | Acc: (94.21%) (17003/18048)\n",
      "Epoch: 66 | Batch_idx: 150 |  Loss: (0.1659) | Acc: (94.24%) (18215/19328)\n",
      "Epoch: 66 | Batch_idx: 160 |  Loss: (0.1666) | Acc: (94.23%) (19419/20608)\n",
      "Epoch: 66 | Batch_idx: 170 |  Loss: (0.1669) | Acc: (94.23%) (20625/21888)\n",
      "Epoch: 66 | Batch_idx: 180 |  Loss: (0.1666) | Acc: (94.27%) (21840/23168)\n",
      "Epoch: 66 | Batch_idx: 190 |  Loss: (0.1669) | Acc: (94.26%) (23044/24448)\n",
      "Epoch: 66 | Batch_idx: 200 |  Loss: (0.1682) | Acc: (94.23%) (24244/25728)\n",
      "Epoch: 66 | Batch_idx: 210 |  Loss: (0.1704) | Acc: (94.14%) (25424/27008)\n",
      "Epoch: 66 | Batch_idx: 220 |  Loss: (0.1711) | Acc: (94.09%) (26616/28288)\n",
      "Epoch: 66 | Batch_idx: 230 |  Loss: (0.1713) | Acc: (94.07%) (27816/29568)\n",
      "Epoch: 66 | Batch_idx: 240 |  Loss: (0.1711) | Acc: (94.07%) (29020/30848)\n",
      "Epoch: 66 | Batch_idx: 250 |  Loss: (0.1711) | Acc: (94.07%) (30224/32128)\n",
      "Epoch: 66 | Batch_idx: 260 |  Loss: (0.1720) | Acc: (94.03%) (31415/33408)\n",
      "Epoch: 66 | Batch_idx: 270 |  Loss: (0.1723) | Acc: (93.98%) (32600/34688)\n",
      "Epoch: 66 | Batch_idx: 280 |  Loss: (0.1730) | Acc: (93.95%) (33792/35968)\n",
      "Epoch: 66 | Batch_idx: 290 |  Loss: (0.1734) | Acc: (93.94%) (34991/37248)\n",
      "Epoch: 66 | Batch_idx: 300 |  Loss: (0.1736) | Acc: (93.93%) (36189/38528)\n",
      "Epoch: 66 | Batch_idx: 310 |  Loss: (0.1745) | Acc: (93.89%) (37375/39808)\n",
      "Epoch: 66 | Batch_idx: 320 |  Loss: (0.1743) | Acc: (93.90%) (38582/41088)\n",
      "Epoch: 66 | Batch_idx: 330 |  Loss: (0.1745) | Acc: (93.91%) (39786/42368)\n",
      "Epoch: 66 | Batch_idx: 340 |  Loss: (0.1754) | Acc: (93.86%) (40968/43648)\n",
      "Epoch: 66 | Batch_idx: 350 |  Loss: (0.1759) | Acc: (93.84%) (42159/44928)\n",
      "Epoch: 66 | Batch_idx: 360 |  Loss: (0.1771) | Acc: (93.81%) (43346/46208)\n",
      "Epoch: 66 | Batch_idx: 370 |  Loss: (0.1771) | Acc: (93.79%) (44537/47488)\n",
      "Epoch: 66 | Batch_idx: 380 |  Loss: (0.1774) | Acc: (93.79%) (45738/48768)\n",
      "Epoch: 66 | Batch_idx: 390 |  Loss: (0.1773) | Acc: (93.79%) (46893/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4737) | Acc: (86.13%) (8613/10000)\n",
      "Epoch: 67 | Batch_idx: 0 |  Loss: (0.1267) | Acc: (95.31%) (122/128)\n",
      "Epoch: 67 | Batch_idx: 10 |  Loss: (0.1665) | Acc: (93.96%) (1323/1408)\n",
      "Epoch: 67 | Batch_idx: 20 |  Loss: (0.1661) | Acc: (93.79%) (2521/2688)\n",
      "Epoch: 67 | Batch_idx: 30 |  Loss: (0.1685) | Acc: (93.70%) (3718/3968)\n",
      "Epoch: 67 | Batch_idx: 40 |  Loss: (0.1670) | Acc: (93.83%) (4924/5248)\n",
      "Epoch: 67 | Batch_idx: 50 |  Loss: (0.1669) | Acc: (93.95%) (6133/6528)\n",
      "Epoch: 67 | Batch_idx: 60 |  Loss: (0.1684) | Acc: (93.88%) (7330/7808)\n",
      "Epoch: 67 | Batch_idx: 70 |  Loss: (0.1647) | Acc: (94.04%) (8546/9088)\n",
      "Epoch: 67 | Batch_idx: 80 |  Loss: (0.1648) | Acc: (94.14%) (9760/10368)\n",
      "Epoch: 67 | Batch_idx: 90 |  Loss: (0.1647) | Acc: (94.23%) (10976/11648)\n",
      "Epoch: 67 | Batch_idx: 100 |  Loss: (0.1645) | Acc: (94.21%) (12180/12928)\n",
      "Epoch: 67 | Batch_idx: 110 |  Loss: (0.1664) | Acc: (94.14%) (13375/14208)\n",
      "Epoch: 67 | Batch_idx: 120 |  Loss: (0.1683) | Acc: (94.11%) (14576/15488)\n",
      "Epoch: 67 | Batch_idx: 130 |  Loss: (0.1694) | Acc: (94.09%) (15777/16768)\n",
      "Epoch: 67 | Batch_idx: 140 |  Loss: (0.1692) | Acc: (94.12%) (16986/18048)\n",
      "Epoch: 67 | Batch_idx: 150 |  Loss: (0.1708) | Acc: (94.10%) (18188/19328)\n",
      "Epoch: 67 | Batch_idx: 160 |  Loss: (0.1707) | Acc: (94.12%) (19396/20608)\n",
      "Epoch: 67 | Batch_idx: 170 |  Loss: (0.1715) | Acc: (94.11%) (20599/21888)\n",
      "Epoch: 67 | Batch_idx: 180 |  Loss: (0.1704) | Acc: (94.17%) (21817/23168)\n",
      "Epoch: 67 | Batch_idx: 190 |  Loss: (0.1699) | Acc: (94.18%) (23025/24448)\n",
      "Epoch: 67 | Batch_idx: 200 |  Loss: (0.1698) | Acc: (94.20%) (24236/25728)\n",
      "Epoch: 67 | Batch_idx: 210 |  Loss: (0.1704) | Acc: (94.17%) (25433/27008)\n",
      "Epoch: 67 | Batch_idx: 220 |  Loss: (0.1697) | Acc: (94.16%) (26637/28288)\n",
      "Epoch: 67 | Batch_idx: 230 |  Loss: (0.1702) | Acc: (94.16%) (27841/29568)\n",
      "Epoch: 67 | Batch_idx: 240 |  Loss: (0.1700) | Acc: (94.20%) (29059/30848)\n",
      "Epoch: 67 | Batch_idx: 250 |  Loss: (0.1697) | Acc: (94.24%) (30278/32128)\n",
      "Epoch: 67 | Batch_idx: 260 |  Loss: (0.1698) | Acc: (94.24%) (31483/33408)\n",
      "Epoch: 67 | Batch_idx: 270 |  Loss: (0.1705) | Acc: (94.23%) (32687/34688)\n",
      "Epoch: 67 | Batch_idx: 280 |  Loss: (0.1709) | Acc: (94.20%) (33881/35968)\n",
      "Epoch: 67 | Batch_idx: 290 |  Loss: (0.1716) | Acc: (94.13%) (35063/37248)\n",
      "Epoch: 67 | Batch_idx: 300 |  Loss: (0.1720) | Acc: (94.11%) (36260/38528)\n",
      "Epoch: 67 | Batch_idx: 310 |  Loss: (0.1721) | Acc: (94.10%) (37458/39808)\n",
      "Epoch: 67 | Batch_idx: 320 |  Loss: (0.1722) | Acc: (94.10%) (38662/41088)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 | Batch_idx: 330 |  Loss: (0.1725) | Acc: (94.07%) (39856/42368)\n",
      "Epoch: 67 | Batch_idx: 340 |  Loss: (0.1728) | Acc: (94.06%) (41055/43648)\n",
      "Epoch: 67 | Batch_idx: 350 |  Loss: (0.1728) | Acc: (94.05%) (42257/44928)\n",
      "Epoch: 67 | Batch_idx: 360 |  Loss: (0.1730) | Acc: (94.06%) (43462/46208)\n",
      "Epoch: 67 | Batch_idx: 370 |  Loss: (0.1731) | Acc: (94.05%) (44661/47488)\n",
      "Epoch: 67 | Batch_idx: 380 |  Loss: (0.1734) | Acc: (94.04%) (45862/48768)\n",
      "Epoch: 67 | Batch_idx: 390 |  Loss: (0.1737) | Acc: (94.03%) (47017/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4661) | Acc: (86.26%) (8626/10000)\n",
      "Epoch: 68 | Batch_idx: 0 |  Loss: (0.2420) | Acc: (94.53%) (121/128)\n",
      "Epoch: 68 | Batch_idx: 10 |  Loss: (0.1950) | Acc: (92.68%) (1305/1408)\n",
      "Epoch: 68 | Batch_idx: 20 |  Loss: (0.1891) | Acc: (93.15%) (2504/2688)\n",
      "Epoch: 68 | Batch_idx: 30 |  Loss: (0.1782) | Acc: (93.72%) (3719/3968)\n",
      "Epoch: 68 | Batch_idx: 40 |  Loss: (0.1744) | Acc: (93.94%) (4930/5248)\n",
      "Epoch: 68 | Batch_idx: 50 |  Loss: (0.1705) | Acc: (94.16%) (6147/6528)\n",
      "Epoch: 68 | Batch_idx: 60 |  Loss: (0.1685) | Acc: (94.19%) (7354/7808)\n",
      "Epoch: 68 | Batch_idx: 70 |  Loss: (0.1702) | Acc: (94.11%) (8553/9088)\n",
      "Epoch: 68 | Batch_idx: 80 |  Loss: (0.1657) | Acc: (94.21%) (9768/10368)\n",
      "Epoch: 68 | Batch_idx: 90 |  Loss: (0.1624) | Acc: (94.29%) (10983/11648)\n",
      "Epoch: 68 | Batch_idx: 100 |  Loss: (0.1621) | Acc: (94.35%) (12197/12928)\n",
      "Epoch: 68 | Batch_idx: 110 |  Loss: (0.1622) | Acc: (94.38%) (13409/14208)\n",
      "Epoch: 68 | Batch_idx: 120 |  Loss: (0.1632) | Acc: (94.34%) (14611/15488)\n",
      "Epoch: 68 | Batch_idx: 130 |  Loss: (0.1643) | Acc: (94.31%) (15814/16768)\n",
      "Epoch: 68 | Batch_idx: 140 |  Loss: (0.1676) | Acc: (94.19%) (16999/18048)\n",
      "Epoch: 68 | Batch_idx: 150 |  Loss: (0.1669) | Acc: (94.21%) (18209/19328)\n",
      "Epoch: 68 | Batch_idx: 160 |  Loss: (0.1659) | Acc: (94.24%) (19421/20608)\n",
      "Epoch: 68 | Batch_idx: 170 |  Loss: (0.1657) | Acc: (94.28%) (20635/21888)\n",
      "Epoch: 68 | Batch_idx: 180 |  Loss: (0.1644) | Acc: (94.30%) (21847/23168)\n",
      "Epoch: 68 | Batch_idx: 190 |  Loss: (0.1640) | Acc: (94.32%) (23060/24448)\n",
      "Epoch: 68 | Batch_idx: 200 |  Loss: (0.1635) | Acc: (94.38%) (24281/25728)\n",
      "Epoch: 68 | Batch_idx: 210 |  Loss: (0.1627) | Acc: (94.38%) (25490/27008)\n",
      "Epoch: 68 | Batch_idx: 220 |  Loss: (0.1637) | Acc: (94.37%) (26696/28288)\n",
      "Epoch: 68 | Batch_idx: 230 |  Loss: (0.1631) | Acc: (94.38%) (27907/29568)\n",
      "Epoch: 68 | Batch_idx: 240 |  Loss: (0.1636) | Acc: (94.36%) (29107/30848)\n",
      "Epoch: 68 | Batch_idx: 250 |  Loss: (0.1641) | Acc: (94.33%) (30306/32128)\n",
      "Epoch: 68 | Batch_idx: 260 |  Loss: (0.1643) | Acc: (94.32%) (31511/33408)\n",
      "Epoch: 68 | Batch_idx: 270 |  Loss: (0.1640) | Acc: (94.34%) (32724/34688)\n",
      "Epoch: 68 | Batch_idx: 280 |  Loss: (0.1641) | Acc: (94.34%) (33933/35968)\n",
      "Epoch: 68 | Batch_idx: 290 |  Loss: (0.1646) | Acc: (94.31%) (35130/37248)\n",
      "Epoch: 68 | Batch_idx: 300 |  Loss: (0.1652) | Acc: (94.28%) (36323/38528)\n",
      "Epoch: 68 | Batch_idx: 310 |  Loss: (0.1653) | Acc: (94.26%) (37525/39808)\n",
      "Epoch: 68 | Batch_idx: 320 |  Loss: (0.1654) | Acc: (94.26%) (38728/41088)\n",
      "Epoch: 68 | Batch_idx: 330 |  Loss: (0.1667) | Acc: (94.22%) (39920/42368)\n",
      "Epoch: 68 | Batch_idx: 340 |  Loss: (0.1671) | Acc: (94.21%) (41121/43648)\n",
      "Epoch: 68 | Batch_idx: 350 |  Loss: (0.1673) | Acc: (94.21%) (42325/44928)\n",
      "Epoch: 68 | Batch_idx: 360 |  Loss: (0.1670) | Acc: (94.21%) (43533/46208)\n",
      "Epoch: 68 | Batch_idx: 370 |  Loss: (0.1681) | Acc: (94.20%) (44736/47488)\n",
      "Epoch: 68 | Batch_idx: 380 |  Loss: (0.1690) | Acc: (94.15%) (45915/48768)\n",
      "Epoch: 68 | Batch_idx: 390 |  Loss: (0.1691) | Acc: (94.14%) (47068/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5073) | Acc: (85.37%) (8537/10000)\n",
      "Epoch: 69 | Batch_idx: 0 |  Loss: (0.1225) | Acc: (95.31%) (122/128)\n",
      "Epoch: 69 | Batch_idx: 10 |  Loss: (0.1705) | Acc: (94.11%) (1325/1408)\n",
      "Epoch: 69 | Batch_idx: 20 |  Loss: (0.1702) | Acc: (94.12%) (2530/2688)\n",
      "Epoch: 69 | Batch_idx: 30 |  Loss: (0.1694) | Acc: (93.98%) (3729/3968)\n",
      "Epoch: 69 | Batch_idx: 40 |  Loss: (0.1633) | Acc: (94.25%) (4946/5248)\n",
      "Epoch: 69 | Batch_idx: 50 |  Loss: (0.1613) | Acc: (94.26%) (6153/6528)\n",
      "Epoch: 69 | Batch_idx: 60 |  Loss: (0.1595) | Acc: (94.31%) (7364/7808)\n",
      "Epoch: 69 | Batch_idx: 70 |  Loss: (0.1600) | Acc: (94.37%) (8576/9088)\n",
      "Epoch: 69 | Batch_idx: 80 |  Loss: (0.1605) | Acc: (94.36%) (9783/10368)\n",
      "Epoch: 69 | Batch_idx: 90 |  Loss: (0.1635) | Acc: (94.31%) (10985/11648)\n",
      "Epoch: 69 | Batch_idx: 100 |  Loss: (0.1647) | Acc: (94.28%) (12188/12928)\n",
      "Epoch: 69 | Batch_idx: 110 |  Loss: (0.1658) | Acc: (94.21%) (13386/14208)\n",
      "Epoch: 69 | Batch_idx: 120 |  Loss: (0.1666) | Acc: (94.16%) (14584/15488)\n",
      "Epoch: 69 | Batch_idx: 130 |  Loss: (0.1680) | Acc: (94.17%) (15790/16768)\n",
      "Epoch: 69 | Batch_idx: 140 |  Loss: (0.1685) | Acc: (94.09%) (16982/18048)\n",
      "Epoch: 69 | Batch_idx: 150 |  Loss: (0.1692) | Acc: (94.08%) (18183/19328)\n",
      "Epoch: 69 | Batch_idx: 160 |  Loss: (0.1702) | Acc: (94.05%) (19382/20608)\n",
      "Epoch: 69 | Batch_idx: 170 |  Loss: (0.1692) | Acc: (94.07%) (20590/21888)\n",
      "Epoch: 69 | Batch_idx: 180 |  Loss: (0.1703) | Acc: (94.03%) (21785/23168)\n",
      "Epoch: 69 | Batch_idx: 190 |  Loss: (0.1699) | Acc: (94.04%) (22991/24448)\n",
      "Epoch: 69 | Batch_idx: 200 |  Loss: (0.1700) | Acc: (94.03%) (24193/25728)\n",
      "Epoch: 69 | Batch_idx: 210 |  Loss: (0.1703) | Acc: (94.03%) (25395/27008)\n",
      "Epoch: 69 | Batch_idx: 220 |  Loss: (0.1700) | Acc: (94.00%) (26592/28288)\n",
      "Epoch: 69 | Batch_idx: 230 |  Loss: (0.1716) | Acc: (93.96%) (27782/29568)\n",
      "Epoch: 69 | Batch_idx: 240 |  Loss: (0.1710) | Acc: (94.00%) (28997/30848)\n",
      "Epoch: 69 | Batch_idx: 250 |  Loss: (0.1718) | Acc: (93.99%) (30196/32128)\n",
      "Epoch: 69 | Batch_idx: 260 |  Loss: (0.1713) | Acc: (94.01%) (31408/33408)\n",
      "Epoch: 69 | Batch_idx: 270 |  Loss: (0.1715) | Acc: (94.00%) (32606/34688)\n",
      "Epoch: 69 | Batch_idx: 280 |  Loss: (0.1710) | Acc: (94.02%) (33818/35968)\n",
      "Epoch: 69 | Batch_idx: 290 |  Loss: (0.1711) | Acc: (94.02%) (35021/37248)\n",
      "Epoch: 69 | Batch_idx: 300 |  Loss: (0.1711) | Acc: (94.02%) (36225/38528)\n",
      "Epoch: 69 | Batch_idx: 310 |  Loss: (0.1724) | Acc: (94.00%) (37420/39808)\n",
      "Epoch: 69 | Batch_idx: 320 |  Loss: (0.1719) | Acc: (94.04%) (38638/41088)\n",
      "Epoch: 69 | Batch_idx: 330 |  Loss: (0.1711) | Acc: (94.07%) (39857/42368)\n",
      "Epoch: 69 | Batch_idx: 340 |  Loss: (0.1711) | Acc: (94.08%) (41063/43648)\n",
      "Epoch: 69 | Batch_idx: 350 |  Loss: (0.1707) | Acc: (94.10%) (42277/44928)\n",
      "Epoch: 69 | Batch_idx: 360 |  Loss: (0.1710) | Acc: (94.10%) (43480/46208)\n",
      "Epoch: 69 | Batch_idx: 370 |  Loss: (0.1710) | Acc: (94.10%) (44686/47488)\n",
      "Epoch: 69 | Batch_idx: 380 |  Loss: (0.1701) | Acc: (94.15%) (45915/48768)\n",
      "Epoch: 69 | Batch_idx: 390 |  Loss: (0.1701) | Acc: (94.14%) (47072/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4444) | Acc: (87.17%) (8717/10000)\n",
      "Epoch: 70 | Batch_idx: 0 |  Loss: (0.1016) | Acc: (96.88%) (124/128)\n",
      "Epoch: 70 | Batch_idx: 10 |  Loss: (0.1762) | Acc: (94.18%) (1326/1408)\n",
      "Epoch: 70 | Batch_idx: 20 |  Loss: (0.1700) | Acc: (94.31%) (2535/2688)\n",
      "Epoch: 70 | Batch_idx: 30 |  Loss: (0.1573) | Acc: (94.66%) (3756/3968)\n",
      "Epoch: 70 | Batch_idx: 40 |  Loss: (0.1571) | Acc: (94.68%) (4969/5248)\n",
      "Epoch: 70 | Batch_idx: 50 |  Loss: (0.1522) | Acc: (94.88%) (6194/6528)\n",
      "Epoch: 70 | Batch_idx: 60 |  Loss: (0.1525) | Acc: (94.90%) (7410/7808)\n",
      "Epoch: 70 | Batch_idx: 70 |  Loss: (0.1537) | Acc: (94.72%) (8608/9088)\n",
      "Epoch: 70 | Batch_idx: 80 |  Loss: (0.1528) | Acc: (94.69%) (9817/10368)\n",
      "Epoch: 70 | Batch_idx: 90 |  Loss: (0.1527) | Acc: (94.67%) (11027/11648)\n",
      "Epoch: 70 | Batch_idx: 100 |  Loss: (0.1545) | Acc: (94.62%) (12233/12928)\n",
      "Epoch: 70 | Batch_idx: 110 |  Loss: (0.1550) | Acc: (94.55%) (13433/14208)\n",
      "Epoch: 70 | Batch_idx: 120 |  Loss: (0.1564) | Acc: (94.52%) (14639/15488)\n",
      "Epoch: 70 | Batch_idx: 130 |  Loss: (0.1578) | Acc: (94.48%) (15842/16768)\n",
      "Epoch: 70 | Batch_idx: 140 |  Loss: (0.1572) | Acc: (94.48%) (17051/18048)\n",
      "Epoch: 70 | Batch_idx: 150 |  Loss: (0.1551) | Acc: (94.53%) (18270/19328)\n",
      "Epoch: 70 | Batch_idx: 160 |  Loss: (0.1564) | Acc: (94.51%) (19476/20608)\n",
      "Epoch: 70 | Batch_idx: 170 |  Loss: (0.1559) | Acc: (94.53%) (20690/21888)\n",
      "Epoch: 70 | Batch_idx: 180 |  Loss: (0.1559) | Acc: (94.53%) (21901/23168)\n",
      "Epoch: 70 | Batch_idx: 190 |  Loss: (0.1564) | Acc: (94.51%) (23106/24448)\n",
      "Epoch: 70 | Batch_idx: 200 |  Loss: (0.1564) | Acc: (94.49%) (24311/25728)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 | Batch_idx: 210 |  Loss: (0.1571) | Acc: (94.47%) (25514/27008)\n",
      "Epoch: 70 | Batch_idx: 220 |  Loss: (0.1572) | Acc: (94.46%) (26722/28288)\n",
      "Epoch: 70 | Batch_idx: 230 |  Loss: (0.1574) | Acc: (94.45%) (27926/29568)\n",
      "Epoch: 70 | Batch_idx: 240 |  Loss: (0.1573) | Acc: (94.48%) (29144/30848)\n",
      "Epoch: 70 | Batch_idx: 250 |  Loss: (0.1575) | Acc: (94.48%) (30353/32128)\n",
      "Epoch: 70 | Batch_idx: 260 |  Loss: (0.1577) | Acc: (94.47%) (31562/33408)\n",
      "Epoch: 70 | Batch_idx: 270 |  Loss: (0.1590) | Acc: (94.42%) (32751/34688)\n",
      "Epoch: 70 | Batch_idx: 280 |  Loss: (0.1582) | Acc: (94.45%) (33972/35968)\n",
      "Epoch: 70 | Batch_idx: 290 |  Loss: (0.1580) | Acc: (94.46%) (35184/37248)\n",
      "Epoch: 70 | Batch_idx: 300 |  Loss: (0.1579) | Acc: (94.46%) (36393/38528)\n",
      "Epoch: 70 | Batch_idx: 310 |  Loss: (0.1586) | Acc: (94.45%) (37597/39808)\n",
      "Epoch: 70 | Batch_idx: 320 |  Loss: (0.1580) | Acc: (94.47%) (38815/41088)\n",
      "Epoch: 70 | Batch_idx: 330 |  Loss: (0.1581) | Acc: (94.47%) (40023/42368)\n",
      "Epoch: 70 | Batch_idx: 340 |  Loss: (0.1586) | Acc: (94.45%) (41226/43648)\n",
      "Epoch: 70 | Batch_idx: 350 |  Loss: (0.1589) | Acc: (94.45%) (42434/44928)\n",
      "Epoch: 70 | Batch_idx: 360 |  Loss: (0.1593) | Acc: (94.43%) (43635/46208)\n",
      "Epoch: 70 | Batch_idx: 370 |  Loss: (0.1603) | Acc: (94.39%) (44826/47488)\n",
      "Epoch: 70 | Batch_idx: 380 |  Loss: (0.1602) | Acc: (94.39%) (46030/48768)\n",
      "Epoch: 70 | Batch_idx: 390 |  Loss: (0.1609) | Acc: (94.36%) (47181/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5187) | Acc: (85.55%) (8555/10000)\n",
      "Epoch: 71 | Batch_idx: 0 |  Loss: (0.1728) | Acc: (95.31%) (122/128)\n",
      "Epoch: 71 | Batch_idx: 10 |  Loss: (0.1553) | Acc: (94.82%) (1335/1408)\n",
      "Epoch: 71 | Batch_idx: 20 |  Loss: (0.1491) | Acc: (95.09%) (2556/2688)\n",
      "Epoch: 71 | Batch_idx: 30 |  Loss: (0.1493) | Acc: (94.93%) (3767/3968)\n",
      "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1486) | Acc: (94.72%) (4971/5248)\n",
      "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1458) | Acc: (94.88%) (6194/6528)\n",
      "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1461) | Acc: (94.89%) (7409/7808)\n",
      "Epoch: 71 | Batch_idx: 70 |  Loss: (0.1459) | Acc: (94.96%) (8630/9088)\n",
      "Epoch: 71 | Batch_idx: 80 |  Loss: (0.1494) | Acc: (94.88%) (9837/10368)\n",
      "Epoch: 71 | Batch_idx: 90 |  Loss: (0.1520) | Acc: (94.84%) (11047/11648)\n",
      "Epoch: 71 | Batch_idx: 100 |  Loss: (0.1519) | Acc: (94.79%) (12254/12928)\n",
      "Epoch: 71 | Batch_idx: 110 |  Loss: (0.1535) | Acc: (94.78%) (13466/14208)\n",
      "Epoch: 71 | Batch_idx: 120 |  Loss: (0.1513) | Acc: (94.86%) (14692/15488)\n",
      "Epoch: 71 | Batch_idx: 130 |  Loss: (0.1519) | Acc: (94.83%) (15901/16768)\n",
      "Epoch: 71 | Batch_idx: 140 |  Loss: (0.1511) | Acc: (94.87%) (17123/18048)\n",
      "Epoch: 71 | Batch_idx: 150 |  Loss: (0.1514) | Acc: (94.87%) (18336/19328)\n",
      "Epoch: 71 | Batch_idx: 160 |  Loss: (0.1509) | Acc: (94.87%) (19550/20608)\n",
      "Epoch: 71 | Batch_idx: 170 |  Loss: (0.1511) | Acc: (94.80%) (20750/21888)\n",
      "Epoch: 71 | Batch_idx: 180 |  Loss: (0.1523) | Acc: (94.74%) (21949/23168)\n",
      "Epoch: 71 | Batch_idx: 190 |  Loss: (0.1525) | Acc: (94.72%) (23157/24448)\n",
      "Epoch: 71 | Batch_idx: 200 |  Loss: (0.1528) | Acc: (94.73%) (24373/25728)\n",
      "Epoch: 71 | Batch_idx: 210 |  Loss: (0.1524) | Acc: (94.71%) (25578/27008)\n",
      "Epoch: 71 | Batch_idx: 220 |  Loss: (0.1518) | Acc: (94.75%) (26804/28288)\n",
      "Epoch: 71 | Batch_idx: 230 |  Loss: (0.1531) | Acc: (94.72%) (28007/29568)\n",
      "Epoch: 71 | Batch_idx: 240 |  Loss: (0.1530) | Acc: (94.74%) (29225/30848)\n",
      "Epoch: 71 | Batch_idx: 250 |  Loss: (0.1522) | Acc: (94.76%) (30446/32128)\n",
      "Epoch: 71 | Batch_idx: 260 |  Loss: (0.1524) | Acc: (94.77%) (31662/33408)\n",
      "Epoch: 71 | Batch_idx: 270 |  Loss: (0.1536) | Acc: (94.76%) (32870/34688)\n",
      "Epoch: 71 | Batch_idx: 280 |  Loss: (0.1549) | Acc: (94.69%) (34057/35968)\n",
      "Epoch: 71 | Batch_idx: 290 |  Loss: (0.1553) | Acc: (94.65%) (35256/37248)\n",
      "Epoch: 71 | Batch_idx: 300 |  Loss: (0.1559) | Acc: (94.63%) (36459/38528)\n",
      "Epoch: 71 | Batch_idx: 310 |  Loss: (0.1567) | Acc: (94.59%) (37654/39808)\n",
      "Epoch: 71 | Batch_idx: 320 |  Loss: (0.1570) | Acc: (94.57%) (38856/41088)\n",
      "Epoch: 71 | Batch_idx: 330 |  Loss: (0.1574) | Acc: (94.56%) (40064/42368)\n",
      "Epoch: 71 | Batch_idx: 340 |  Loss: (0.1586) | Acc: (94.52%) (41256/43648)\n",
      "Epoch: 71 | Batch_idx: 350 |  Loss: (0.1585) | Acc: (94.52%) (42468/44928)\n",
      "Epoch: 71 | Batch_idx: 360 |  Loss: (0.1592) | Acc: (94.51%) (43669/46208)\n",
      "Epoch: 71 | Batch_idx: 370 |  Loss: (0.1595) | Acc: (94.50%) (44875/47488)\n",
      "Epoch: 71 | Batch_idx: 380 |  Loss: (0.1587) | Acc: (94.53%) (46099/48768)\n",
      "Epoch: 71 | Batch_idx: 390 |  Loss: (0.1586) | Acc: (94.52%) (47259/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5639) | Acc: (84.22%) (8422/10000)\n",
      "Epoch: 72 | Batch_idx: 0 |  Loss: (0.2864) | Acc: (92.97%) (119/128)\n",
      "Epoch: 72 | Batch_idx: 10 |  Loss: (0.1754) | Acc: (94.11%) (1325/1408)\n",
      "Epoch: 72 | Batch_idx: 20 |  Loss: (0.1661) | Acc: (94.05%) (2528/2688)\n",
      "Epoch: 72 | Batch_idx: 30 |  Loss: (0.1644) | Acc: (93.95%) (3728/3968)\n",
      "Epoch: 72 | Batch_idx: 40 |  Loss: (0.1621) | Acc: (94.00%) (4933/5248)\n",
      "Epoch: 72 | Batch_idx: 50 |  Loss: (0.1589) | Acc: (94.12%) (6144/6528)\n",
      "Epoch: 72 | Batch_idx: 60 |  Loss: (0.1598) | Acc: (94.13%) (7350/7808)\n",
      "Epoch: 72 | Batch_idx: 70 |  Loss: (0.1591) | Acc: (94.14%) (8555/9088)\n",
      "Epoch: 72 | Batch_idx: 80 |  Loss: (0.1578) | Acc: (94.16%) (9762/10368)\n",
      "Epoch: 72 | Batch_idx: 90 |  Loss: (0.1574) | Acc: (94.20%) (10972/11648)\n",
      "Epoch: 72 | Batch_idx: 100 |  Loss: (0.1570) | Acc: (94.25%) (12185/12928)\n",
      "Epoch: 72 | Batch_idx: 110 |  Loss: (0.1573) | Acc: (94.29%) (13397/14208)\n",
      "Epoch: 72 | Batch_idx: 120 |  Loss: (0.1573) | Acc: (94.32%) (14609/15488)\n",
      "Epoch: 72 | Batch_idx: 130 |  Loss: (0.1595) | Acc: (94.24%) (15803/16768)\n",
      "Epoch: 72 | Batch_idx: 140 |  Loss: (0.1598) | Acc: (94.22%) (17004/18048)\n",
      "Epoch: 72 | Batch_idx: 150 |  Loss: (0.1584) | Acc: (94.29%) (18225/19328)\n",
      "Epoch: 72 | Batch_idx: 160 |  Loss: (0.1575) | Acc: (94.30%) (19434/20608)\n",
      "Epoch: 72 | Batch_idx: 170 |  Loss: (0.1573) | Acc: (94.32%) (20645/21888)\n",
      "Epoch: 72 | Batch_idx: 180 |  Loss: (0.1570) | Acc: (94.36%) (21862/23168)\n",
      "Epoch: 72 | Batch_idx: 190 |  Loss: (0.1558) | Acc: (94.41%) (23081/24448)\n",
      "Epoch: 72 | Batch_idx: 200 |  Loss: (0.1568) | Acc: (94.36%) (24278/25728)\n",
      "Epoch: 72 | Batch_idx: 210 |  Loss: (0.1572) | Acc: (94.38%) (25489/27008)\n",
      "Epoch: 72 | Batch_idx: 220 |  Loss: (0.1577) | Acc: (94.36%) (26692/28288)\n",
      "Epoch: 72 | Batch_idx: 230 |  Loss: (0.1575) | Acc: (94.36%) (27899/29568)\n",
      "Epoch: 72 | Batch_idx: 240 |  Loss: (0.1578) | Acc: (94.36%) (29108/30848)\n",
      "Epoch: 72 | Batch_idx: 250 |  Loss: (0.1576) | Acc: (94.37%) (30318/32128)\n",
      "Epoch: 72 | Batch_idx: 260 |  Loss: (0.1578) | Acc: (94.37%) (31526/33408)\n",
      "Epoch: 72 | Batch_idx: 270 |  Loss: (0.1579) | Acc: (94.37%) (32735/34688)\n",
      "Epoch: 72 | Batch_idx: 280 |  Loss: (0.1578) | Acc: (94.37%) (33944/35968)\n",
      "Epoch: 72 | Batch_idx: 290 |  Loss: (0.1580) | Acc: (94.39%) (35160/37248)\n",
      "Epoch: 72 | Batch_idx: 300 |  Loss: (0.1582) | Acc: (94.40%) (36370/38528)\n",
      "Epoch: 72 | Batch_idx: 310 |  Loss: (0.1584) | Acc: (94.39%) (37575/39808)\n",
      "Epoch: 72 | Batch_idx: 320 |  Loss: (0.1580) | Acc: (94.41%) (38792/41088)\n",
      "Epoch: 72 | Batch_idx: 330 |  Loss: (0.1580) | Acc: (94.41%) (40000/42368)\n",
      "Epoch: 72 | Batch_idx: 340 |  Loss: (0.1579) | Acc: (94.42%) (41213/43648)\n",
      "Epoch: 72 | Batch_idx: 350 |  Loss: (0.1581) | Acc: (94.42%) (42422/44928)\n",
      "Epoch: 72 | Batch_idx: 360 |  Loss: (0.1585) | Acc: (94.40%) (43620/46208)\n",
      "Epoch: 72 | Batch_idx: 370 |  Loss: (0.1585) | Acc: (94.39%) (44823/47488)\n",
      "Epoch: 72 | Batch_idx: 380 |  Loss: (0.1591) | Acc: (94.38%) (46026/48768)\n",
      "Epoch: 72 | Batch_idx: 390 |  Loss: (0.1600) | Acc: (94.34%) (47172/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5084) | Acc: (86.16%) (8616/10000)\n",
      "Epoch: 73 | Batch_idx: 0 |  Loss: (0.1370) | Acc: (93.75%) (120/128)\n",
      "Epoch: 73 | Batch_idx: 10 |  Loss: (0.1468) | Acc: (94.18%) (1326/1408)\n",
      "Epoch: 73 | Batch_idx: 20 |  Loss: (0.1391) | Acc: (94.53%) (2541/2688)\n",
      "Epoch: 73 | Batch_idx: 30 |  Loss: (0.1430) | Acc: (94.68%) (3757/3968)\n",
      "Epoch: 73 | Batch_idx: 40 |  Loss: (0.1490) | Acc: (94.53%) (4961/5248)\n",
      "Epoch: 73 | Batch_idx: 50 |  Loss: (0.1479) | Acc: (94.62%) (6177/6528)\n",
      "Epoch: 73 | Batch_idx: 60 |  Loss: (0.1437) | Acc: (94.79%) (7401/7808)\n",
      "Epoch: 73 | Batch_idx: 70 |  Loss: (0.1453) | Acc: (94.76%) (8612/9088)\n",
      "Epoch: 73 | Batch_idx: 80 |  Loss: (0.1441) | Acc: (94.93%) (9842/10368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 | Batch_idx: 90 |  Loss: (0.1443) | Acc: (94.88%) (11052/11648)\n",
      "Epoch: 73 | Batch_idx: 100 |  Loss: (0.1455) | Acc: (94.82%) (12258/12928)\n",
      "Epoch: 73 | Batch_idx: 110 |  Loss: (0.1451) | Acc: (94.88%) (13481/14208)\n",
      "Epoch: 73 | Batch_idx: 120 |  Loss: (0.1444) | Acc: (94.94%) (14705/15488)\n",
      "Epoch: 73 | Batch_idx: 130 |  Loss: (0.1434) | Acc: (94.97%) (15925/16768)\n",
      "Epoch: 73 | Batch_idx: 140 |  Loss: (0.1435) | Acc: (94.96%) (17138/18048)\n",
      "Epoch: 73 | Batch_idx: 150 |  Loss: (0.1444) | Acc: (94.89%) (18340/19328)\n",
      "Epoch: 73 | Batch_idx: 160 |  Loss: (0.1455) | Acc: (94.83%) (19543/20608)\n",
      "Epoch: 73 | Batch_idx: 170 |  Loss: (0.1471) | Acc: (94.73%) (20735/21888)\n",
      "Epoch: 73 | Batch_idx: 180 |  Loss: (0.1484) | Acc: (94.68%) (21936/23168)\n",
      "Epoch: 73 | Batch_idx: 190 |  Loss: (0.1488) | Acc: (94.67%) (23145/24448)\n",
      "Epoch: 73 | Batch_idx: 200 |  Loss: (0.1493) | Acc: (94.66%) (24354/25728)\n",
      "Epoch: 73 | Batch_idx: 210 |  Loss: (0.1503) | Acc: (94.62%) (25554/27008)\n",
      "Epoch: 73 | Batch_idx: 220 |  Loss: (0.1515) | Acc: (94.56%) (26750/28288)\n",
      "Epoch: 73 | Batch_idx: 230 |  Loss: (0.1516) | Acc: (94.55%) (27956/29568)\n",
      "Epoch: 73 | Batch_idx: 240 |  Loss: (0.1519) | Acc: (94.53%) (29162/30848)\n",
      "Epoch: 73 | Batch_idx: 250 |  Loss: (0.1526) | Acc: (94.50%) (30360/32128)\n",
      "Epoch: 73 | Batch_idx: 260 |  Loss: (0.1527) | Acc: (94.50%) (31571/33408)\n",
      "Epoch: 73 | Batch_idx: 270 |  Loss: (0.1526) | Acc: (94.52%) (32786/34688)\n",
      "Epoch: 73 | Batch_idx: 280 |  Loss: (0.1529) | Acc: (94.51%) (33993/35968)\n",
      "Epoch: 73 | Batch_idx: 290 |  Loss: (0.1536) | Acc: (94.47%) (35188/37248)\n",
      "Epoch: 73 | Batch_idx: 300 |  Loss: (0.1541) | Acc: (94.48%) (36401/38528)\n",
      "Epoch: 73 | Batch_idx: 310 |  Loss: (0.1541) | Acc: (94.48%) (37612/39808)\n",
      "Epoch: 73 | Batch_idx: 320 |  Loss: (0.1544) | Acc: (94.47%) (38814/41088)\n",
      "Epoch: 73 | Batch_idx: 330 |  Loss: (0.1548) | Acc: (94.44%) (40012/42368)\n",
      "Epoch: 73 | Batch_idx: 340 |  Loss: (0.1552) | Acc: (94.42%) (41212/43648)\n",
      "Epoch: 73 | Batch_idx: 350 |  Loss: (0.1558) | Acc: (94.40%) (42411/44928)\n",
      "Epoch: 73 | Batch_idx: 360 |  Loss: (0.1557) | Acc: (94.40%) (43619/46208)\n",
      "Epoch: 73 | Batch_idx: 370 |  Loss: (0.1560) | Acc: (94.40%) (44830/47488)\n",
      "Epoch: 73 | Batch_idx: 380 |  Loss: (0.1564) | Acc: (94.38%) (46025/48768)\n",
      "Epoch: 73 | Batch_idx: 390 |  Loss: (0.1563) | Acc: (94.38%) (47189/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4603) | Acc: (86.83%) (8683/10000)\n",
      "Epoch: 74 | Batch_idx: 0 |  Loss: (0.0646) | Acc: (97.66%) (125/128)\n",
      "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1299) | Acc: (95.31%) (1342/1408)\n",
      "Epoch: 74 | Batch_idx: 20 |  Loss: (0.1368) | Acc: (95.46%) (2566/2688)\n",
      "Epoch: 74 | Batch_idx: 30 |  Loss: (0.1399) | Acc: (95.19%) (3777/3968)\n",
      "Epoch: 74 | Batch_idx: 40 |  Loss: (0.1451) | Acc: (94.93%) (4982/5248)\n",
      "Epoch: 74 | Batch_idx: 50 |  Loss: (0.1435) | Acc: (95.05%) (6205/6528)\n",
      "Epoch: 74 | Batch_idx: 60 |  Loss: (0.1444) | Acc: (95.01%) (7418/7808)\n",
      "Epoch: 74 | Batch_idx: 70 |  Loss: (0.1438) | Acc: (94.99%) (8633/9088)\n",
      "Epoch: 74 | Batch_idx: 80 |  Loss: (0.1413) | Acc: (95.11%) (9861/10368)\n",
      "Epoch: 74 | Batch_idx: 90 |  Loss: (0.1412) | Acc: (95.12%) (11079/11648)\n",
      "Epoch: 74 | Batch_idx: 100 |  Loss: (0.1422) | Acc: (95.13%) (12299/12928)\n",
      "Epoch: 74 | Batch_idx: 110 |  Loss: (0.1432) | Acc: (95.09%) (13511/14208)\n",
      "Epoch: 74 | Batch_idx: 120 |  Loss: (0.1433) | Acc: (95.07%) (14725/15488)\n",
      "Epoch: 74 | Batch_idx: 130 |  Loss: (0.1455) | Acc: (95.04%) (15937/16768)\n",
      "Epoch: 74 | Batch_idx: 140 |  Loss: (0.1453) | Acc: (95.04%) (17153/18048)\n",
      "Epoch: 74 | Batch_idx: 150 |  Loss: (0.1463) | Acc: (94.96%) (18354/19328)\n",
      "Epoch: 74 | Batch_idx: 160 |  Loss: (0.1463) | Acc: (94.98%) (19574/20608)\n",
      "Epoch: 74 | Batch_idx: 170 |  Loss: (0.1465) | Acc: (94.94%) (20781/21888)\n",
      "Epoch: 74 | Batch_idx: 180 |  Loss: (0.1466) | Acc: (94.93%) (21993/23168)\n",
      "Epoch: 74 | Batch_idx: 190 |  Loss: (0.1466) | Acc: (94.93%) (23209/24448)\n",
      "Epoch: 74 | Batch_idx: 200 |  Loss: (0.1473) | Acc: (94.88%) (24411/25728)\n",
      "Epoch: 74 | Batch_idx: 210 |  Loss: (0.1479) | Acc: (94.87%) (25622/27008)\n",
      "Epoch: 74 | Batch_idx: 220 |  Loss: (0.1480) | Acc: (94.86%) (26834/28288)\n",
      "Epoch: 74 | Batch_idx: 230 |  Loss: (0.1477) | Acc: (94.88%) (28053/29568)\n",
      "Epoch: 74 | Batch_idx: 240 |  Loss: (0.1479) | Acc: (94.86%) (29261/30848)\n",
      "Epoch: 74 | Batch_idx: 250 |  Loss: (0.1489) | Acc: (94.83%) (30467/32128)\n",
      "Epoch: 74 | Batch_idx: 260 |  Loss: (0.1499) | Acc: (94.79%) (31667/33408)\n",
      "Epoch: 74 | Batch_idx: 270 |  Loss: (0.1499) | Acc: (94.80%) (32883/34688)\n",
      "Epoch: 74 | Batch_idx: 280 |  Loss: (0.1503) | Acc: (94.76%) (34085/35968)\n",
      "Epoch: 74 | Batch_idx: 290 |  Loss: (0.1502) | Acc: (94.79%) (35306/37248)\n",
      "Epoch: 74 | Batch_idx: 300 |  Loss: (0.1506) | Acc: (94.75%) (36506/38528)\n",
      "Epoch: 74 | Batch_idx: 310 |  Loss: (0.1510) | Acc: (94.74%) (37715/39808)\n",
      "Epoch: 74 | Batch_idx: 320 |  Loss: (0.1509) | Acc: (94.76%) (38934/41088)\n",
      "Epoch: 74 | Batch_idx: 330 |  Loss: (0.1509) | Acc: (94.75%) (40145/42368)\n",
      "Epoch: 74 | Batch_idx: 340 |  Loss: (0.1511) | Acc: (94.75%) (41356/43648)\n",
      "Epoch: 74 | Batch_idx: 350 |  Loss: (0.1516) | Acc: (94.75%) (42568/44928)\n",
      "Epoch: 74 | Batch_idx: 360 |  Loss: (0.1522) | Acc: (94.73%) (43771/46208)\n",
      "Epoch: 74 | Batch_idx: 370 |  Loss: (0.1530) | Acc: (94.68%) (44964/47488)\n",
      "Epoch: 74 | Batch_idx: 380 |  Loss: (0.1529) | Acc: (94.67%) (46171/48768)\n",
      "Epoch: 74 | Batch_idx: 390 |  Loss: (0.1529) | Acc: (94.69%) (47345/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4429) | Acc: (86.88%) (8688/10000)\n",
      "Epoch: 75 | Batch_idx: 0 |  Loss: (0.1222) | Acc: (96.09%) (123/128)\n",
      "Epoch: 75 | Batch_idx: 10 |  Loss: (0.1253) | Acc: (95.53%) (1345/1408)\n",
      "Epoch: 75 | Batch_idx: 20 |  Loss: (0.1231) | Acc: (95.72%) (2573/2688)\n",
      "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1279) | Acc: (95.51%) (3790/3968)\n",
      "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1276) | Acc: (95.58%) (5016/5248)\n",
      "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1344) | Acc: (95.28%) (6220/6528)\n",
      "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1335) | Acc: (95.26%) (7438/7808)\n",
      "Epoch: 75 | Batch_idx: 70 |  Loss: (0.1344) | Acc: (95.19%) (8651/9088)\n",
      "Epoch: 75 | Batch_idx: 80 |  Loss: (0.1376) | Acc: (95.09%) (9859/10368)\n",
      "Epoch: 75 | Batch_idx: 90 |  Loss: (0.1369) | Acc: (95.14%) (11082/11648)\n",
      "Epoch: 75 | Batch_idx: 100 |  Loss: (0.1368) | Acc: (95.13%) (12299/12928)\n",
      "Epoch: 75 | Batch_idx: 110 |  Loss: (0.1362) | Acc: (95.21%) (13527/14208)\n",
      "Epoch: 75 | Batch_idx: 120 |  Loss: (0.1371) | Acc: (95.18%) (14742/15488)\n",
      "Epoch: 75 | Batch_idx: 130 |  Loss: (0.1368) | Acc: (95.24%) (15970/16768)\n",
      "Epoch: 75 | Batch_idx: 140 |  Loss: (0.1373) | Acc: (95.23%) (17188/18048)\n",
      "Epoch: 75 | Batch_idx: 150 |  Loss: (0.1369) | Acc: (95.25%) (18410/19328)\n",
      "Epoch: 75 | Batch_idx: 160 |  Loss: (0.1371) | Acc: (95.18%) (19615/20608)\n",
      "Epoch: 75 | Batch_idx: 170 |  Loss: (0.1376) | Acc: (95.17%) (20831/21888)\n",
      "Epoch: 75 | Batch_idx: 180 |  Loss: (0.1369) | Acc: (95.23%) (22062/23168)\n",
      "Epoch: 75 | Batch_idx: 190 |  Loss: (0.1393) | Acc: (95.13%) (23258/24448)\n",
      "Epoch: 75 | Batch_idx: 200 |  Loss: (0.1404) | Acc: (95.07%) (24460/25728)\n",
      "Epoch: 75 | Batch_idx: 210 |  Loss: (0.1406) | Acc: (95.05%) (25672/27008)\n",
      "Epoch: 75 | Batch_idx: 220 |  Loss: (0.1425) | Acc: (95.02%) (26879/28288)\n",
      "Epoch: 75 | Batch_idx: 230 |  Loss: (0.1436) | Acc: (94.97%) (28081/29568)\n",
      "Epoch: 75 | Batch_idx: 240 |  Loss: (0.1442) | Acc: (94.96%) (29292/30848)\n",
      "Epoch: 75 | Batch_idx: 250 |  Loss: (0.1444) | Acc: (94.95%) (30505/32128)\n",
      "Epoch: 75 | Batch_idx: 260 |  Loss: (0.1451) | Acc: (94.94%) (31716/33408)\n",
      "Epoch: 75 | Batch_idx: 270 |  Loss: (0.1463) | Acc: (94.89%) (32914/34688)\n",
      "Epoch: 75 | Batch_idx: 280 |  Loss: (0.1469) | Acc: (94.86%) (34120/35968)\n",
      "Epoch: 75 | Batch_idx: 290 |  Loss: (0.1470) | Acc: (94.87%) (35338/37248)\n",
      "Epoch: 75 | Batch_idx: 300 |  Loss: (0.1466) | Acc: (94.89%) (36561/38528)\n",
      "Epoch: 75 | Batch_idx: 310 |  Loss: (0.1459) | Acc: (94.92%) (37785/39808)\n",
      "Epoch: 75 | Batch_idx: 320 |  Loss: (0.1457) | Acc: (94.91%) (38998/41088)\n",
      "Epoch: 75 | Batch_idx: 330 |  Loss: (0.1460) | Acc: (94.89%) (40203/42368)\n",
      "Epoch: 75 | Batch_idx: 340 |  Loss: (0.1463) | Acc: (94.88%) (41413/43648)\n",
      "Epoch: 75 | Batch_idx: 350 |  Loss: (0.1466) | Acc: (94.88%) (42627/44928)\n",
      "Epoch: 75 | Batch_idx: 360 |  Loss: (0.1466) | Acc: (94.87%) (43838/46208)\n",
      "Epoch: 75 | Batch_idx: 370 |  Loss: (0.1468) | Acc: (94.85%) (45043/47488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 | Batch_idx: 380 |  Loss: (0.1465) | Acc: (94.86%) (46261/48768)\n",
      "Epoch: 75 | Batch_idx: 390 |  Loss: (0.1468) | Acc: (94.87%) (47434/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4946) | Acc: (86.03%) (8603/10000)\n",
      "Epoch: 76 | Batch_idx: 0 |  Loss: (0.0622) | Acc: (99.22%) (127/128)\n",
      "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1243) | Acc: (95.31%) (1342/1408)\n",
      "Epoch: 76 | Batch_idx: 20 |  Loss: (0.1244) | Acc: (95.54%) (2568/2688)\n",
      "Epoch: 76 | Batch_idx: 30 |  Loss: (0.1327) | Acc: (95.29%) (3781/3968)\n",
      "Epoch: 76 | Batch_idx: 40 |  Loss: (0.1431) | Acc: (94.95%) (4983/5248)\n",
      "Epoch: 76 | Batch_idx: 50 |  Loss: (0.1421) | Acc: (95.10%) (6208/6528)\n",
      "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1446) | Acc: (94.99%) (7417/7808)\n",
      "Epoch: 76 | Batch_idx: 70 |  Loss: (0.1444) | Acc: (95.09%) (8642/9088)\n",
      "Epoch: 76 | Batch_idx: 80 |  Loss: (0.1425) | Acc: (95.06%) (9856/10368)\n",
      "Epoch: 76 | Batch_idx: 90 |  Loss: (0.1420) | Acc: (95.06%) (11073/11648)\n",
      "Epoch: 76 | Batch_idx: 100 |  Loss: (0.1410) | Acc: (95.09%) (12293/12928)\n",
      "Epoch: 76 | Batch_idx: 110 |  Loss: (0.1431) | Acc: (95.01%) (13499/14208)\n",
      "Epoch: 76 | Batch_idx: 120 |  Loss: (0.1424) | Acc: (95.07%) (14725/15488)\n",
      "Epoch: 76 | Batch_idx: 130 |  Loss: (0.1427) | Acc: (95.10%) (15946/16768)\n",
      "Epoch: 76 | Batch_idx: 140 |  Loss: (0.1423) | Acc: (95.10%) (17163/18048)\n",
      "Epoch: 76 | Batch_idx: 150 |  Loss: (0.1426) | Acc: (95.08%) (18378/19328)\n",
      "Epoch: 76 | Batch_idx: 160 |  Loss: (0.1424) | Acc: (95.08%) (19595/20608)\n",
      "Epoch: 76 | Batch_idx: 170 |  Loss: (0.1416) | Acc: (95.11%) (20817/21888)\n",
      "Epoch: 76 | Batch_idx: 180 |  Loss: (0.1414) | Acc: (95.12%) (22038/23168)\n",
      "Epoch: 76 | Batch_idx: 190 |  Loss: (0.1404) | Acc: (95.14%) (23260/24448)\n",
      "Epoch: 76 | Batch_idx: 200 |  Loss: (0.1405) | Acc: (95.13%) (24475/25728)\n",
      "Epoch: 76 | Batch_idx: 210 |  Loss: (0.1400) | Acc: (95.12%) (25691/27008)\n",
      "Epoch: 76 | Batch_idx: 220 |  Loss: (0.1403) | Acc: (95.14%) (26914/28288)\n",
      "Epoch: 76 | Batch_idx: 230 |  Loss: (0.1400) | Acc: (95.16%) (28137/29568)\n",
      "Epoch: 76 | Batch_idx: 240 |  Loss: (0.1411) | Acc: (95.12%) (29342/30848)\n",
      "Epoch: 76 | Batch_idx: 250 |  Loss: (0.1411) | Acc: (95.09%) (30551/32128)\n",
      "Epoch: 76 | Batch_idx: 260 |  Loss: (0.1426) | Acc: (95.03%) (31746/33408)\n",
      "Epoch: 76 | Batch_idx: 270 |  Loss: (0.1424) | Acc: (95.04%) (32969/34688)\n",
      "Epoch: 76 | Batch_idx: 280 |  Loss: (0.1422) | Acc: (95.05%) (34187/35968)\n",
      "Epoch: 76 | Batch_idx: 290 |  Loss: (0.1428) | Acc: (95.01%) (35391/37248)\n",
      "Epoch: 76 | Batch_idx: 300 |  Loss: (0.1425) | Acc: (95.04%) (36616/38528)\n",
      "Epoch: 76 | Batch_idx: 310 |  Loss: (0.1422) | Acc: (95.06%) (37841/39808)\n",
      "Epoch: 76 | Batch_idx: 320 |  Loss: (0.1428) | Acc: (95.02%) (39040/41088)\n",
      "Epoch: 76 | Batch_idx: 330 |  Loss: (0.1426) | Acc: (95.03%) (40262/42368)\n",
      "Epoch: 76 | Batch_idx: 340 |  Loss: (0.1430) | Acc: (95.01%) (41468/43648)\n",
      "Epoch: 76 | Batch_idx: 350 |  Loss: (0.1433) | Acc: (94.99%) (42677/44928)\n",
      "Epoch: 76 | Batch_idx: 360 |  Loss: (0.1435) | Acc: (94.98%) (43888/46208)\n",
      "Epoch: 76 | Batch_idx: 370 |  Loss: (0.1435) | Acc: (94.98%) (45104/47488)\n",
      "Epoch: 76 | Batch_idx: 380 |  Loss: (0.1441) | Acc: (94.97%) (46316/48768)\n",
      "Epoch: 76 | Batch_idx: 390 |  Loss: (0.1442) | Acc: (94.95%) (47474/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5246) | Acc: (85.17%) (8517/10000)\n",
      "Epoch: 77 | Batch_idx: 0 |  Loss: (0.1684) | Acc: (94.53%) (121/128)\n",
      "Epoch: 77 | Batch_idx: 10 |  Loss: (0.1447) | Acc: (94.89%) (1336/1408)\n",
      "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1381) | Acc: (95.24%) (2560/2688)\n",
      "Epoch: 77 | Batch_idx: 30 |  Loss: (0.1321) | Acc: (95.46%) (3788/3968)\n",
      "Epoch: 77 | Batch_idx: 40 |  Loss: (0.1378) | Acc: (95.14%) (4993/5248)\n",
      "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1374) | Acc: (95.17%) (6213/6528)\n",
      "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1375) | Acc: (95.08%) (7424/7808)\n",
      "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1345) | Acc: (95.19%) (8651/9088)\n",
      "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1340) | Acc: (95.18%) (9868/10368)\n",
      "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1341) | Acc: (95.18%) (11086/11648)\n",
      "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1340) | Acc: (95.20%) (12307/12928)\n",
      "Epoch: 77 | Batch_idx: 110 |  Loss: (0.1338) | Acc: (95.22%) (13529/14208)\n",
      "Epoch: 77 | Batch_idx: 120 |  Loss: (0.1337) | Acc: (95.20%) (14745/15488)\n",
      "Epoch: 77 | Batch_idx: 130 |  Loss: (0.1340) | Acc: (95.22%) (15967/16768)\n",
      "Epoch: 77 | Batch_idx: 140 |  Loss: (0.1335) | Acc: (95.28%) (17197/18048)\n",
      "Epoch: 77 | Batch_idx: 150 |  Loss: (0.1330) | Acc: (95.32%) (18424/19328)\n",
      "Epoch: 77 | Batch_idx: 160 |  Loss: (0.1333) | Acc: (95.31%) (19641/20608)\n",
      "Epoch: 77 | Batch_idx: 170 |  Loss: (0.1333) | Acc: (95.30%) (20860/21888)\n",
      "Epoch: 77 | Batch_idx: 180 |  Loss: (0.1332) | Acc: (95.30%) (22079/23168)\n",
      "Epoch: 77 | Batch_idx: 190 |  Loss: (0.1342) | Acc: (95.22%) (23280/24448)\n",
      "Epoch: 77 | Batch_idx: 200 |  Loss: (0.1342) | Acc: (95.20%) (24494/25728)\n",
      "Epoch: 77 | Batch_idx: 210 |  Loss: (0.1350) | Acc: (95.21%) (25714/27008)\n",
      "Epoch: 77 | Batch_idx: 220 |  Loss: (0.1355) | Acc: (95.21%) (26933/28288)\n",
      "Epoch: 77 | Batch_idx: 230 |  Loss: (0.1361) | Acc: (95.17%) (28141/29568)\n",
      "Epoch: 77 | Batch_idx: 240 |  Loss: (0.1369) | Acc: (95.17%) (29357/30848)\n",
      "Epoch: 77 | Batch_idx: 250 |  Loss: (0.1368) | Acc: (95.18%) (30578/32128)\n",
      "Epoch: 77 | Batch_idx: 260 |  Loss: (0.1380) | Acc: (95.15%) (31787/33408)\n",
      "Epoch: 77 | Batch_idx: 270 |  Loss: (0.1378) | Acc: (95.13%) (33000/34688)\n",
      "Epoch: 77 | Batch_idx: 280 |  Loss: (0.1387) | Acc: (95.11%) (34210/35968)\n",
      "Epoch: 77 | Batch_idx: 290 |  Loss: (0.1390) | Acc: (95.10%) (35424/37248)\n",
      "Epoch: 77 | Batch_idx: 300 |  Loss: (0.1388) | Acc: (95.09%) (36638/38528)\n",
      "Epoch: 77 | Batch_idx: 310 |  Loss: (0.1385) | Acc: (95.09%) (37853/39808)\n",
      "Epoch: 77 | Batch_idx: 320 |  Loss: (0.1387) | Acc: (95.09%) (39072/41088)\n",
      "Epoch: 77 | Batch_idx: 330 |  Loss: (0.1404) | Acc: (95.02%) (40259/42368)\n",
      "Epoch: 77 | Batch_idx: 340 |  Loss: (0.1413) | Acc: (95.01%) (41469/43648)\n",
      "Epoch: 77 | Batch_idx: 350 |  Loss: (0.1420) | Acc: (94.99%) (42678/44928)\n",
      "Epoch: 77 | Batch_idx: 360 |  Loss: (0.1424) | Acc: (94.97%) (43886/46208)\n",
      "Epoch: 77 | Batch_idx: 370 |  Loss: (0.1424) | Acc: (94.97%) (45100/47488)\n",
      "Epoch: 77 | Batch_idx: 380 |  Loss: (0.1419) | Acc: (94.97%) (46317/48768)\n",
      "Epoch: 77 | Batch_idx: 390 |  Loss: (0.1417) | Acc: (94.98%) (47492/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4590) | Acc: (87.18%) (8718/10000)\n",
      "Epoch: 78 | Batch_idx: 0 |  Loss: (0.1086) | Acc: (96.88%) (124/128)\n",
      "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1403) | Acc: (95.10%) (1339/1408)\n",
      "Epoch: 78 | Batch_idx: 20 |  Loss: (0.1334) | Acc: (95.20%) (2559/2688)\n",
      "Epoch: 78 | Batch_idx: 30 |  Loss: (0.1382) | Acc: (95.11%) (3774/3968)\n",
      "Epoch: 78 | Batch_idx: 40 |  Loss: (0.1361) | Acc: (95.35%) (5004/5248)\n",
      "Epoch: 78 | Batch_idx: 50 |  Loss: (0.1387) | Acc: (95.33%) (6223/6528)\n",
      "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1330) | Acc: (95.50%) (7457/7808)\n",
      "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1322) | Acc: (95.57%) (8685/9088)\n",
      "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1314) | Acc: (95.58%) (9910/10368)\n",
      "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1331) | Acc: (95.52%) (11126/11648)\n",
      "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1351) | Acc: (95.41%) (12335/12928)\n",
      "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1362) | Acc: (95.38%) (13552/14208)\n",
      "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1377) | Acc: (95.32%) (14763/15488)\n",
      "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1381) | Acc: (95.23%) (15969/16768)\n",
      "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1389) | Acc: (95.17%) (17177/18048)\n",
      "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1381) | Acc: (95.23%) (18407/19328)\n",
      "Epoch: 78 | Batch_idx: 160 |  Loss: (0.1390) | Acc: (95.17%) (19612/20608)\n",
      "Epoch: 78 | Batch_idx: 170 |  Loss: (0.1407) | Acc: (95.14%) (20824/21888)\n",
      "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1408) | Acc: (95.17%) (22050/23168)\n",
      "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1408) | Acc: (95.16%) (23264/24448)\n",
      "Epoch: 78 | Batch_idx: 200 |  Loss: (0.1396) | Acc: (95.21%) (24495/25728)\n",
      "Epoch: 78 | Batch_idx: 210 |  Loss: (0.1394) | Acc: (95.22%) (25718/27008)\n",
      "Epoch: 78 | Batch_idx: 220 |  Loss: (0.1393) | Acc: (95.20%) (26930/28288)\n",
      "Epoch: 78 | Batch_idx: 230 |  Loss: (0.1395) | Acc: (95.20%) (28148/29568)\n",
      "Epoch: 78 | Batch_idx: 240 |  Loss: (0.1394) | Acc: (95.23%) (29377/30848)\n",
      "Epoch: 78 | Batch_idx: 250 |  Loss: (0.1393) | Acc: (95.24%) (30599/32128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 | Batch_idx: 260 |  Loss: (0.1386) | Acc: (95.26%) (31824/33408)\n",
      "Epoch: 78 | Batch_idx: 270 |  Loss: (0.1381) | Acc: (95.27%) (33048/34688)\n",
      "Epoch: 78 | Batch_idx: 280 |  Loss: (0.1376) | Acc: (95.30%) (34276/35968)\n",
      "Epoch: 78 | Batch_idx: 290 |  Loss: (0.1369) | Acc: (95.31%) (35500/37248)\n",
      "Epoch: 78 | Batch_idx: 300 |  Loss: (0.1382) | Acc: (95.25%) (36697/38528)\n",
      "Epoch: 78 | Batch_idx: 310 |  Loss: (0.1384) | Acc: (95.24%) (37915/39808)\n",
      "Epoch: 78 | Batch_idx: 320 |  Loss: (0.1380) | Acc: (95.29%) (39153/41088)\n",
      "Epoch: 78 | Batch_idx: 330 |  Loss: (0.1388) | Acc: (95.25%) (40356/42368)\n",
      "Epoch: 78 | Batch_idx: 340 |  Loss: (0.1389) | Acc: (95.24%) (41570/43648)\n",
      "Epoch: 78 | Batch_idx: 350 |  Loss: (0.1387) | Acc: (95.25%) (42792/44928)\n",
      "Epoch: 78 | Batch_idx: 360 |  Loss: (0.1387) | Acc: (95.24%) (44009/46208)\n",
      "Epoch: 78 | Batch_idx: 370 |  Loss: (0.1388) | Acc: (95.23%) (45221/47488)\n",
      "Epoch: 78 | Batch_idx: 380 |  Loss: (0.1389) | Acc: (95.23%) (46440/48768)\n",
      "Epoch: 78 | Batch_idx: 390 |  Loss: (0.1393) | Acc: (95.20%) (47602/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5034) | Acc: (86.29%) (8629/10000)\n",
      "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1261) | Acc: (95.31%) (122/128)\n",
      "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1432) | Acc: (94.53%) (1331/1408)\n",
      "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1381) | Acc: (94.98%) (2553/2688)\n",
      "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1356) | Acc: (95.11%) (3774/3968)\n",
      "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1386) | Acc: (95.01%) (4986/5248)\n",
      "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1346) | Acc: (95.21%) (6215/6528)\n",
      "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1322) | Acc: (95.39%) (7448/7808)\n",
      "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1289) | Acc: (95.47%) (8676/9088)\n",
      "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1305) | Acc: (95.45%) (9896/10368)\n",
      "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1286) | Acc: (95.48%) (11121/11648)\n",
      "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1278) | Acc: (95.44%) (12339/12928)\n",
      "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1270) | Acc: (95.47%) (13565/14208)\n",
      "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1276) | Acc: (95.43%) (14780/15488)\n",
      "Epoch: 79 | Batch_idx: 130 |  Loss: (0.1278) | Acc: (95.46%) (16007/16768)\n",
      "Epoch: 79 | Batch_idx: 140 |  Loss: (0.1305) | Acc: (95.35%) (17208/18048)\n",
      "Epoch: 79 | Batch_idx: 150 |  Loss: (0.1323) | Acc: (95.27%) (18414/19328)\n",
      "Epoch: 79 | Batch_idx: 160 |  Loss: (0.1329) | Acc: (95.26%) (19631/20608)\n",
      "Epoch: 79 | Batch_idx: 170 |  Loss: (0.1328) | Acc: (95.28%) (20855/21888)\n",
      "Epoch: 79 | Batch_idx: 180 |  Loss: (0.1339) | Acc: (95.25%) (22068/23168)\n",
      "Epoch: 79 | Batch_idx: 190 |  Loss: (0.1336) | Acc: (95.26%) (23289/24448)\n",
      "Epoch: 79 | Batch_idx: 200 |  Loss: (0.1338) | Acc: (95.25%) (24507/25728)\n",
      "Epoch: 79 | Batch_idx: 210 |  Loss: (0.1349) | Acc: (95.23%) (25720/27008)\n",
      "Epoch: 79 | Batch_idx: 220 |  Loss: (0.1348) | Acc: (95.22%) (26936/28288)\n",
      "Epoch: 79 | Batch_idx: 230 |  Loss: (0.1358) | Acc: (95.18%) (28144/29568)\n",
      "Epoch: 79 | Batch_idx: 240 |  Loss: (0.1355) | Acc: (95.18%) (29362/30848)\n",
      "Epoch: 79 | Batch_idx: 250 |  Loss: (0.1356) | Acc: (95.18%) (30581/32128)\n",
      "Epoch: 79 | Batch_idx: 260 |  Loss: (0.1357) | Acc: (95.17%) (31796/33408)\n",
      "Epoch: 79 | Batch_idx: 270 |  Loss: (0.1355) | Acc: (95.19%) (33021/34688)\n",
      "Epoch: 79 | Batch_idx: 280 |  Loss: (0.1356) | Acc: (95.20%) (34242/35968)\n",
      "Epoch: 79 | Batch_idx: 290 |  Loss: (0.1359) | Acc: (95.20%) (35460/37248)\n",
      "Epoch: 79 | Batch_idx: 300 |  Loss: (0.1352) | Acc: (95.23%) (36691/38528)\n",
      "Epoch: 79 | Batch_idx: 310 |  Loss: (0.1358) | Acc: (95.21%) (37902/39808)\n",
      "Epoch: 79 | Batch_idx: 320 |  Loss: (0.1363) | Acc: (95.20%) (39115/41088)\n",
      "Epoch: 79 | Batch_idx: 330 |  Loss: (0.1366) | Acc: (95.20%) (40333/42368)\n",
      "Epoch: 79 | Batch_idx: 340 |  Loss: (0.1362) | Acc: (95.21%) (41559/43648)\n",
      "Epoch: 79 | Batch_idx: 350 |  Loss: (0.1363) | Acc: (95.21%) (42774/44928)\n",
      "Epoch: 79 | Batch_idx: 360 |  Loss: (0.1366) | Acc: (95.21%) (43996/46208)\n",
      "Epoch: 79 | Batch_idx: 370 |  Loss: (0.1368) | Acc: (95.19%) (45206/47488)\n",
      "Epoch: 79 | Batch_idx: 380 |  Loss: (0.1367) | Acc: (95.20%) (46425/48768)\n",
      "Epoch: 79 | Batch_idx: 390 |  Loss: (0.1363) | Acc: (95.23%) (47614/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4617) | Acc: (87.10%) (8710/10000)\n",
      "Epoch: 80 | Batch_idx: 0 |  Loss: (0.1978) | Acc: (93.75%) (120/128)\n",
      "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1443) | Acc: (95.03%) (1338/1408)\n",
      "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1270) | Acc: (95.83%) (2576/2688)\n",
      "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1153) | Acc: (96.32%) (3822/3968)\n",
      "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1123) | Acc: (96.46%) (5062/5248)\n",
      "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1114) | Acc: (96.42%) (6294/6528)\n",
      "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1108) | Acc: (96.44%) (7530/7808)\n",
      "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1096) | Acc: (96.50%) (8770/9088)\n",
      "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1096) | Acc: (96.47%) (10002/10368)\n",
      "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1079) | Acc: (96.56%) (11247/11648)\n",
      "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1083) | Acc: (96.47%) (12471/12928)\n",
      "Epoch: 80 | Batch_idx: 110 |  Loss: (0.1073) | Acc: (96.52%) (13714/14208)\n",
      "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1069) | Acc: (96.56%) (14955/15488)\n",
      "Epoch: 80 | Batch_idx: 130 |  Loss: (0.1052) | Acc: (96.60%) (16198/16768)\n",
      "Epoch: 80 | Batch_idx: 140 |  Loss: (0.1050) | Acc: (96.63%) (17440/18048)\n",
      "Epoch: 80 | Batch_idx: 150 |  Loss: (0.1028) | Acc: (96.72%) (18694/19328)\n",
      "Epoch: 80 | Batch_idx: 160 |  Loss: (0.1014) | Acc: (96.76%) (19941/20608)\n",
      "Epoch: 80 | Batch_idx: 170 |  Loss: (0.1011) | Acc: (96.75%) (21176/21888)\n",
      "Epoch: 80 | Batch_idx: 180 |  Loss: (0.1014) | Acc: (96.69%) (22402/23168)\n",
      "Epoch: 80 | Batch_idx: 190 |  Loss: (0.1005) | Acc: (96.73%) (23649/24448)\n",
      "Epoch: 80 | Batch_idx: 200 |  Loss: (0.1000) | Acc: (96.73%) (24887/25728)\n",
      "Epoch: 80 | Batch_idx: 210 |  Loss: (0.0992) | Acc: (96.76%) (26134/27008)\n",
      "Epoch: 80 | Batch_idx: 220 |  Loss: (0.0989) | Acc: (96.80%) (27383/28288)\n",
      "Epoch: 80 | Batch_idx: 230 |  Loss: (0.0986) | Acc: (96.82%) (28629/29568)\n",
      "Epoch: 80 | Batch_idx: 240 |  Loss: (0.0988) | Acc: (96.81%) (29865/30848)\n",
      "Epoch: 80 | Batch_idx: 250 |  Loss: (0.0987) | Acc: (96.81%) (31103/32128)\n",
      "Epoch: 80 | Batch_idx: 260 |  Loss: (0.0990) | Acc: (96.80%) (32338/33408)\n",
      "Epoch: 80 | Batch_idx: 270 |  Loss: (0.0990) | Acc: (96.78%) (33571/34688)\n",
      "Epoch: 80 | Batch_idx: 280 |  Loss: (0.0983) | Acc: (96.80%) (34818/35968)\n",
      "Epoch: 80 | Batch_idx: 290 |  Loss: (0.0983) | Acc: (96.81%) (36060/37248)\n",
      "Epoch: 80 | Batch_idx: 300 |  Loss: (0.0982) | Acc: (96.81%) (37298/38528)\n",
      "Epoch: 80 | Batch_idx: 310 |  Loss: (0.0982) | Acc: (96.81%) (38539/39808)\n",
      "Epoch: 80 | Batch_idx: 320 |  Loss: (0.0978) | Acc: (96.83%) (39787/41088)\n",
      "Epoch: 80 | Batch_idx: 330 |  Loss: (0.0979) | Acc: (96.83%) (41026/42368)\n",
      "Epoch: 80 | Batch_idx: 340 |  Loss: (0.0981) | Acc: (96.82%) (42261/43648)\n",
      "Epoch: 80 | Batch_idx: 350 |  Loss: (0.0977) | Acc: (96.83%) (43506/44928)\n",
      "Epoch: 80 | Batch_idx: 360 |  Loss: (0.0976) | Acc: (96.84%) (44748/46208)\n",
      "Epoch: 80 | Batch_idx: 370 |  Loss: (0.0975) | Acc: (96.85%) (45992/47488)\n",
      "Epoch: 80 | Batch_idx: 380 |  Loss: (0.0979) | Acc: (96.84%) (47229/48768)\n",
      "Epoch: 80 | Batch_idx: 390 |  Loss: (0.0972) | Acc: (96.87%) (48436/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3698) | Acc: (89.05%) (8905/10000)\n",
      "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0514) | Acc: (98.44%) (126/128)\n",
      "Epoch: 81 | Batch_idx: 10 |  Loss: (0.0837) | Acc: (97.30%) (1370/1408)\n",
      "Epoch: 81 | Batch_idx: 20 |  Loss: (0.0805) | Acc: (97.36%) (2617/2688)\n",
      "Epoch: 81 | Batch_idx: 30 |  Loss: (0.0871) | Acc: (97.18%) (3856/3968)\n",
      "Epoch: 81 | Batch_idx: 40 |  Loss: (0.0844) | Acc: (97.31%) (5107/5248)\n",
      "Epoch: 81 | Batch_idx: 50 |  Loss: (0.0847) | Acc: (97.38%) (6357/6528)\n",
      "Epoch: 81 | Batch_idx: 60 |  Loss: (0.0859) | Acc: (97.34%) (7600/7808)\n",
      "Epoch: 81 | Batch_idx: 70 |  Loss: (0.0857) | Acc: (97.34%) (8846/9088)\n",
      "Epoch: 81 | Batch_idx: 80 |  Loss: (0.0852) | Acc: (97.39%) (10097/10368)\n",
      "Epoch: 81 | Batch_idx: 90 |  Loss: (0.0854) | Acc: (97.36%) (11340/11648)\n",
      "Epoch: 81 | Batch_idx: 100 |  Loss: (0.0849) | Acc: (97.32%) (12582/12928)\n",
      "Epoch: 81 | Batch_idx: 110 |  Loss: (0.0861) | Acc: (97.32%) (13827/14208)\n",
      "Epoch: 81 | Batch_idx: 120 |  Loss: (0.0862) | Acc: (97.28%) (15067/15488)\n",
      "Epoch: 81 | Batch_idx: 130 |  Loss: (0.0864) | Acc: (97.30%) (16316/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 | Batch_idx: 140 |  Loss: (0.0871) | Acc: (97.26%) (17553/18048)\n",
      "Epoch: 81 | Batch_idx: 150 |  Loss: (0.0866) | Acc: (97.28%) (18802/19328)\n",
      "Epoch: 81 | Batch_idx: 160 |  Loss: (0.0863) | Acc: (97.33%) (20058/20608)\n",
      "Epoch: 81 | Batch_idx: 170 |  Loss: (0.0868) | Acc: (97.30%) (21297/21888)\n",
      "Epoch: 81 | Batch_idx: 180 |  Loss: (0.0868) | Acc: (97.31%) (22544/23168)\n",
      "Epoch: 81 | Batch_idx: 190 |  Loss: (0.0861) | Acc: (97.34%) (23798/24448)\n",
      "Epoch: 81 | Batch_idx: 200 |  Loss: (0.0862) | Acc: (97.32%) (25038/25728)\n",
      "Epoch: 81 | Batch_idx: 210 |  Loss: (0.0858) | Acc: (97.32%) (26285/27008)\n",
      "Epoch: 81 | Batch_idx: 220 |  Loss: (0.0853) | Acc: (97.33%) (27533/28288)\n",
      "Epoch: 81 | Batch_idx: 230 |  Loss: (0.0853) | Acc: (97.33%) (28780/29568)\n",
      "Epoch: 81 | Batch_idx: 240 |  Loss: (0.0851) | Acc: (97.34%) (30027/30848)\n",
      "Epoch: 81 | Batch_idx: 250 |  Loss: (0.0852) | Acc: (97.34%) (31272/32128)\n",
      "Epoch: 81 | Batch_idx: 260 |  Loss: (0.0856) | Acc: (97.33%) (32516/33408)\n",
      "Epoch: 81 | Batch_idx: 270 |  Loss: (0.0858) | Acc: (97.33%) (33762/34688)\n",
      "Epoch: 81 | Batch_idx: 280 |  Loss: (0.0855) | Acc: (97.35%) (35016/35968)\n",
      "Epoch: 81 | Batch_idx: 290 |  Loss: (0.0860) | Acc: (97.34%) (36256/37248)\n",
      "Epoch: 81 | Batch_idx: 300 |  Loss: (0.0860) | Acc: (97.34%) (37502/38528)\n",
      "Epoch: 81 | Batch_idx: 310 |  Loss: (0.0856) | Acc: (97.37%) (38761/39808)\n",
      "Epoch: 81 | Batch_idx: 320 |  Loss: (0.0857) | Acc: (97.35%) (40001/41088)\n",
      "Epoch: 81 | Batch_idx: 330 |  Loss: (0.0865) | Acc: (97.34%) (41241/42368)\n",
      "Epoch: 81 | Batch_idx: 340 |  Loss: (0.0866) | Acc: (97.34%) (42485/43648)\n",
      "Epoch: 81 | Batch_idx: 350 |  Loss: (0.0866) | Acc: (97.34%) (43733/44928)\n",
      "Epoch: 81 | Batch_idx: 360 |  Loss: (0.0866) | Acc: (97.34%) (44977/46208)\n",
      "Epoch: 81 | Batch_idx: 370 |  Loss: (0.0865) | Acc: (97.34%) (46226/47488)\n",
      "Epoch: 81 | Batch_idx: 380 |  Loss: (0.0861) | Acc: (97.36%) (47481/48768)\n",
      "Epoch: 81 | Batch_idx: 390 |  Loss: (0.0863) | Acc: (97.36%) (48681/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3677) | Acc: (88.88%) (8888/10000)\n",
      "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0528) | Acc: (98.44%) (126/128)\n",
      "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0776) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 82 | Batch_idx: 20 |  Loss: (0.0746) | Acc: (97.73%) (2627/2688)\n",
      "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0794) | Acc: (97.53%) (3870/3968)\n",
      "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0795) | Acc: (97.62%) (5123/5248)\n",
      "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0817) | Acc: (97.50%) (6365/6528)\n",
      "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0828) | Acc: (97.52%) (7614/7808)\n",
      "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0837) | Acc: (97.50%) (8861/9088)\n",
      "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0843) | Acc: (97.42%) (10100/10368)\n",
      "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0841) | Acc: (97.44%) (11350/11648)\n",
      "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0839) | Acc: (97.45%) (12598/12928)\n",
      "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0837) | Acc: (97.43%) (13843/14208)\n",
      "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0826) | Acc: (97.46%) (15094/15488)\n",
      "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0828) | Acc: (97.44%) (16339/16768)\n",
      "Epoch: 82 | Batch_idx: 140 |  Loss: (0.0833) | Acc: (97.42%) (17583/18048)\n",
      "Epoch: 82 | Batch_idx: 150 |  Loss: (0.0833) | Acc: (97.43%) (18831/19328)\n",
      "Epoch: 82 | Batch_idx: 160 |  Loss: (0.0827) | Acc: (97.48%) (20088/20608)\n",
      "Epoch: 82 | Batch_idx: 170 |  Loss: (0.0821) | Acc: (97.49%) (21339/21888)\n",
      "Epoch: 82 | Batch_idx: 180 |  Loss: (0.0830) | Acc: (97.44%) (22575/23168)\n",
      "Epoch: 82 | Batch_idx: 190 |  Loss: (0.0827) | Acc: (97.46%) (23826/24448)\n",
      "Epoch: 82 | Batch_idx: 200 |  Loss: (0.0825) | Acc: (97.47%) (25077/25728)\n",
      "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0831) | Acc: (97.46%) (26323/27008)\n",
      "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0833) | Acc: (97.45%) (27568/28288)\n",
      "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0828) | Acc: (97.48%) (28823/29568)\n",
      "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0824) | Acc: (97.50%) (30078/30848)\n",
      "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0818) | Acc: (97.52%) (31332/32128)\n",
      "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0821) | Acc: (97.52%) (32578/33408)\n",
      "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0823) | Acc: (97.50%) (33822/34688)\n",
      "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0820) | Acc: (97.52%) (35076/35968)\n",
      "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0826) | Acc: (97.48%) (36308/37248)\n",
      "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0822) | Acc: (97.50%) (37566/38528)\n",
      "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0823) | Acc: (97.49%) (38809/39808)\n",
      "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0822) | Acc: (97.50%) (40059/41088)\n",
      "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0826) | Acc: (97.49%) (41304/42368)\n",
      "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0830) | Acc: (97.46%) (42541/43648)\n",
      "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0830) | Acc: (97.47%) (43790/44928)\n",
      "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0829) | Acc: (97.47%) (45038/46208)\n",
      "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0829) | Acc: (97.46%) (46284/47488)\n",
      "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0830) | Acc: (97.46%) (47529/48768)\n",
      "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0830) | Acc: (97.46%) (48731/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3672) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 83 | Batch_idx: 0 |  Loss: (0.1050) | Acc: (96.09%) (123/128)\n",
      "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0703) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0782) | Acc: (97.66%) (2625/2688)\n",
      "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0807) | Acc: (97.53%) (3870/3968)\n",
      "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0802) | Acc: (97.62%) (5123/5248)\n",
      "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0791) | Acc: (97.67%) (6376/6528)\n",
      "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0785) | Acc: (97.68%) (7627/7808)\n",
      "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0797) | Acc: (97.58%) (8868/9088)\n",
      "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0774) | Acc: (97.68%) (10127/10368)\n",
      "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0787) | Acc: (97.60%) (11369/11648)\n",
      "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0786) | Acc: (97.60%) (12618/12928)\n",
      "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0784) | Acc: (97.61%) (13869/14208)\n",
      "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0807) | Acc: (97.53%) (15106/15488)\n",
      "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0803) | Acc: (97.57%) (16360/16768)\n",
      "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0805) | Acc: (97.54%) (17604/18048)\n",
      "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0803) | Acc: (97.55%) (18855/19328)\n",
      "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0798) | Acc: (97.58%) (20110/20608)\n",
      "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0804) | Acc: (97.59%) (21360/21888)\n",
      "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0808) | Acc: (97.59%) (22610/23168)\n",
      "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0804) | Acc: (97.58%) (23857/24448)\n",
      "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0804) | Acc: (97.58%) (25106/25728)\n",
      "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0806) | Acc: (97.59%) (26357/27008)\n",
      "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0812) | Acc: (97.55%) (27594/28288)\n",
      "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0816) | Acc: (97.52%) (28836/29568)\n",
      "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0822) | Acc: (97.50%) (30077/30848)\n",
      "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0819) | Acc: (97.53%) (31333/32128)\n",
      "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0818) | Acc: (97.52%) (32580/33408)\n",
      "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0815) | Acc: (97.54%) (33834/34688)\n",
      "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0812) | Acc: (97.53%) (35080/35968)\n",
      "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0811) | Acc: (97.54%) (36331/37248)\n",
      "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0804) | Acc: (97.57%) (37593/38528)\n",
      "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0802) | Acc: (97.58%) (38843/39808)\n",
      "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0799) | Acc: (97.58%) (40094/41088)\n",
      "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0806) | Acc: (97.55%) (41330/42368)\n",
      "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0805) | Acc: (97.55%) (42580/43648)\n",
      "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0808) | Acc: (97.54%) (43825/44928)\n",
      "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0811) | Acc: (97.54%) (45071/46208)\n",
      "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0813) | Acc: (97.54%) (46319/47488)\n",
      "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0813) | Acc: (97.53%) (47564/48768)\n",
      "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0814) | Acc: (97.53%) (48766/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3668) | Acc: (89.02%) (8902/10000)\n",
      "Epoch: 84 | Batch_idx: 0 |  Loss: (0.0557) | Acc: (99.22%) (127/128)\n",
      "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0696) | Acc: (98.08%) (1381/1408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0710) | Acc: (98.14%) (2638/2688)\n",
      "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0771) | Acc: (97.91%) (3885/3968)\n",
      "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0788) | Acc: (97.69%) (5127/5248)\n",
      "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0806) | Acc: (97.52%) (6366/6528)\n",
      "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0816) | Acc: (97.41%) (7606/7808)\n",
      "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0802) | Acc: (97.45%) (8856/9088)\n",
      "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0796) | Acc: (97.45%) (10104/10368)\n",
      "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0803) | Acc: (97.42%) (11348/11648)\n",
      "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0801) | Acc: (97.45%) (12598/12928)\n",
      "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0803) | Acc: (97.43%) (13843/14208)\n",
      "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0803) | Acc: (97.44%) (15091/15488)\n",
      "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0801) | Acc: (97.45%) (16340/16768)\n",
      "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0803) | Acc: (97.47%) (17591/18048)\n",
      "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0798) | Acc: (97.49%) (18843/19328)\n",
      "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0804) | Acc: (97.47%) (20087/20608)\n",
      "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0806) | Acc: (97.43%) (21326/21888)\n",
      "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0799) | Acc: (97.48%) (22584/23168)\n",
      "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0798) | Acc: (97.49%) (23834/24448)\n",
      "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0802) | Acc: (97.48%) (25079/25728)\n",
      "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0805) | Acc: (97.47%) (26325/27008)\n",
      "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0809) | Acc: (97.45%) (27568/28288)\n",
      "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0806) | Acc: (97.50%) (28828/29568)\n",
      "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0805) | Acc: (97.52%) (30082/30848)\n",
      "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0804) | Acc: (97.54%) (31338/32128)\n",
      "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0804) | Acc: (97.54%) (32585/33408)\n",
      "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0801) | Acc: (97.54%) (33833/34688)\n",
      "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0804) | Acc: (97.52%) (35077/35968)\n",
      "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0805) | Acc: (97.51%) (36320/37248)\n",
      "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0804) | Acc: (97.52%) (37574/38528)\n",
      "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0806) | Acc: (97.50%) (38812/39808)\n",
      "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0804) | Acc: (97.51%) (40066/41088)\n",
      "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0804) | Acc: (97.51%) (41313/42368)\n",
      "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0799) | Acc: (97.54%) (42573/43648)\n",
      "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0798) | Acc: (97.54%) (43822/44928)\n",
      "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0797) | Acc: (97.54%) (45073/46208)\n",
      "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0794) | Acc: (97.55%) (46326/47488)\n",
      "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0793) | Acc: (97.55%) (47573/48768)\n",
      "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0794) | Acc: (97.54%) (48769/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3686) | Acc: (89.08%) (8908/10000)\n",
      "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0607) | Acc: (98.44%) (126/128)\n",
      "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0728) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0790) | Acc: (97.77%) (2628/2688)\n",
      "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0801) | Acc: (97.73%) (3878/3968)\n",
      "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0826) | Acc: (97.66%) (5125/5248)\n",
      "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0814) | Acc: (97.73%) (6380/6528)\n",
      "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0811) | Acc: (97.75%) (7632/7808)\n",
      "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0780) | Acc: (97.88%) (8895/9088)\n",
      "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0784) | Acc: (97.82%) (10142/10368)\n",
      "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0776) | Acc: (97.84%) (11396/11648)\n",
      "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0791) | Acc: (97.82%) (12646/12928)\n",
      "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0787) | Acc: (97.82%) (13898/14208)\n",
      "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0795) | Acc: (97.76%) (15141/15488)\n",
      "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0798) | Acc: (97.72%) (16386/16768)\n",
      "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0797) | Acc: (97.70%) (17633/18048)\n",
      "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0802) | Acc: (97.65%) (18874/19328)\n",
      "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0806) | Acc: (97.65%) (20124/20608)\n",
      "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0799) | Acc: (97.67%) (21377/21888)\n",
      "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0801) | Acc: (97.64%) (22622/23168)\n",
      "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0800) | Acc: (97.65%) (23874/24448)\n",
      "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0804) | Acc: (97.61%) (25114/25728)\n",
      "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0797) | Acc: (97.64%) (26370/27008)\n",
      "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0798) | Acc: (97.63%) (27617/28288)\n",
      "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0794) | Acc: (97.63%) (28867/29568)\n",
      "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0797) | Acc: (97.60%) (30108/30848)\n",
      "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0792) | Acc: (97.63%) (31365/32128)\n",
      "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0797) | Acc: (97.60%) (32607/33408)\n",
      "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0793) | Acc: (97.61%) (33858/34688)\n",
      "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0792) | Acc: (97.62%) (35112/35968)\n",
      "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0797) | Acc: (97.59%) (36352/37248)\n",
      "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0800) | Acc: (97.59%) (37599/38528)\n",
      "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0798) | Acc: (97.61%) (38855/39808)\n",
      "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0798) | Acc: (97.60%) (40102/41088)\n",
      "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0797) | Acc: (97.59%) (41348/42368)\n",
      "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0796) | Acc: (97.61%) (42603/43648)\n",
      "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0790) | Acc: (97.63%) (43864/44928)\n",
      "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0789) | Acc: (97.64%) (45119/46208)\n",
      "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0790) | Acc: (97.64%) (46366/47488)\n",
      "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0792) | Acc: (97.63%) (47612/48768)\n",
      "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0791) | Acc: (97.64%) (48819/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3677) | Acc: (89.17%) (8917/10000)\n",
      "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0953) | Acc: (98.44%) (126/128)\n",
      "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0831) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0768) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0740) | Acc: (97.98%) (3888/3968)\n",
      "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0710) | Acc: (98.02%) (5144/5248)\n",
      "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0724) | Acc: (97.96%) (6395/6528)\n",
      "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0717) | Acc: (97.98%) (7650/7808)\n",
      "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0738) | Acc: (97.93%) (8900/9088)\n",
      "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0758) | Acc: (97.83%) (10143/10368)\n",
      "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0763) | Acc: (97.80%) (11392/11648)\n",
      "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0786) | Acc: (97.69%) (12629/12928)\n",
      "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0785) | Acc: (97.70%) (13881/14208)\n",
      "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0780) | Acc: (97.71%) (15134/15488)\n",
      "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0778) | Acc: (97.70%) (16382/16768)\n",
      "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0775) | Acc: (97.72%) (17636/18048)\n",
      "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0783) | Acc: (97.69%) (18881/19328)\n",
      "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0789) | Acc: (97.66%) (20126/20608)\n",
      "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0785) | Acc: (97.68%) (21380/21888)\n",
      "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0785) | Acc: (97.66%) (22627/23168)\n",
      "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0781) | Acc: (97.68%) (23882/24448)\n",
      "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0787) | Acc: (97.66%) (25126/25728)\n",
      "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0789) | Acc: (97.65%) (26374/27008)\n",
      "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0787) | Acc: (97.67%) (27628/28288)\n",
      "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0783) | Acc: (97.66%) (28877/29568)\n",
      "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0784) | Acc: (97.66%) (30125/30848)\n",
      "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0785) | Acc: (97.63%) (31367/32128)\n",
      "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0782) | Acc: (97.65%) (32622/33408)\n",
      "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0784) | Acc: (97.65%) (33873/34688)\n",
      "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0785) | Acc: (97.64%) (35118/35968)\n",
      "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0784) | Acc: (97.65%) (36373/37248)\n",
      "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0786) | Acc: (97.64%) (37617/38528)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0789) | Acc: (97.62%) (38860/39808)\n",
      "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0785) | Acc: (97.63%) (40113/41088)\n",
      "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0785) | Acc: (97.64%) (41369/42368)\n",
      "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0786) | Acc: (97.63%) (42614/43648)\n",
      "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0785) | Acc: (97.63%) (43865/44928)\n",
      "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0785) | Acc: (97.65%) (45122/46208)\n",
      "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0784) | Acc: (97.65%) (46374/47488)\n",
      "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0781) | Acc: (97.67%) (47632/48768)\n",
      "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0781) | Acc: (97.66%) (48831/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3684) | Acc: (89.17%) (8917/10000)\n",
      "Epoch: 87 | Batch_idx: 0 |  Loss: (0.1503) | Acc: (95.31%) (122/128)\n",
      "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0821) | Acc: (97.59%) (1374/1408)\n",
      "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0850) | Acc: (97.21%) (2613/2688)\n",
      "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0802) | Acc: (97.45%) (3867/3968)\n",
      "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0791) | Acc: (97.58%) (5121/5248)\n",
      "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0787) | Acc: (97.63%) (6373/6528)\n",
      "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0795) | Acc: (97.48%) (7611/7808)\n",
      "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0788) | Acc: (97.49%) (8860/9088)\n",
      "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0788) | Acc: (97.47%) (10106/10368)\n",
      "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0786) | Acc: (97.50%) (11357/11648)\n",
      "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0787) | Acc: (97.54%) (12610/12928)\n",
      "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0789) | Acc: (97.51%) (13854/14208)\n",
      "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0802) | Acc: (97.45%) (15093/15488)\n",
      "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0799) | Acc: (97.48%) (16345/16768)\n",
      "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0787) | Acc: (97.51%) (17599/18048)\n",
      "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0788) | Acc: (97.50%) (18844/19328)\n",
      "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0776) | Acc: (97.53%) (20100/20608)\n",
      "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0782) | Acc: (97.53%) (21347/21888)\n",
      "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0783) | Acc: (97.57%) (22605/23168)\n",
      "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0773) | Acc: (97.62%) (23865/24448)\n",
      "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0774) | Acc: (97.62%) (25115/25728)\n",
      "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0779) | Acc: (97.61%) (26362/27008)\n",
      "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0776) | Acc: (97.62%) (27615/28288)\n",
      "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0770) | Acc: (97.64%) (28871/29568)\n",
      "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0771) | Acc: (97.64%) (30121/30848)\n",
      "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0771) | Acc: (97.64%) (31371/32128)\n",
      "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0771) | Acc: (97.64%) (32619/33408)\n",
      "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0770) | Acc: (97.64%) (33869/34688)\n",
      "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0771) | Acc: (97.64%) (35118/35968)\n",
      "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0767) | Acc: (97.67%) (36380/37248)\n",
      "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0771) | Acc: (97.66%) (37626/38528)\n",
      "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0769) | Acc: (97.67%) (38880/39808)\n",
      "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0775) | Acc: (97.64%) (40117/41088)\n",
      "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0775) | Acc: (97.64%) (41369/42368)\n",
      "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0773) | Acc: (97.65%) (42622/43648)\n",
      "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0772) | Acc: (97.66%) (43878/44928)\n",
      "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0770) | Acc: (97.67%) (45133/46208)\n",
      "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0767) | Acc: (97.68%) (46385/47488)\n",
      "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0771) | Acc: (97.65%) (47621/48768)\n",
      "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0773) | Acc: (97.64%) (48821/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3713) | Acc: (89.14%) (8914/10000)\n",
      "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0457) | Acc: (99.22%) (127/128)\n",
      "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0598) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0727) | Acc: (98.10%) (2637/2688)\n",
      "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0754) | Acc: (98.03%) (3890/3968)\n",
      "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0706) | Acc: (98.11%) (5149/5248)\n",
      "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0746) | Acc: (97.90%) (6391/6528)\n",
      "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0735) | Acc: (97.98%) (7650/7808)\n",
      "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0736) | Acc: (97.96%) (8903/9088)\n",
      "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0751) | Acc: (97.93%) (10153/10368)\n",
      "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0751) | Acc: (97.90%) (11403/11648)\n",
      "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0745) | Acc: (97.90%) (12657/12928)\n",
      "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0746) | Acc: (97.88%) (13907/14208)\n",
      "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0741) | Acc: (97.91%) (15165/15488)\n",
      "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0757) | Acc: (97.86%) (16409/16768)\n",
      "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0755) | Acc: (97.86%) (17662/18048)\n",
      "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0750) | Acc: (97.87%) (18916/19328)\n",
      "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0762) | Acc: (97.83%) (20160/20608)\n",
      "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0760) | Acc: (97.83%) (21412/21888)\n",
      "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0762) | Acc: (97.84%) (22668/23168)\n",
      "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0760) | Acc: (97.85%) (23923/24448)\n",
      "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0758) | Acc: (97.84%) (25172/25728)\n",
      "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0757) | Acc: (97.82%) (26419/27008)\n",
      "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0756) | Acc: (97.83%) (27674/28288)\n",
      "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0756) | Acc: (97.82%) (28923/29568)\n",
      "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0752) | Acc: (97.83%) (30178/30848)\n",
      "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0752) | Acc: (97.83%) (31431/32128)\n",
      "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0751) | Acc: (97.82%) (32680/33408)\n",
      "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0752) | Acc: (97.83%) (33934/34688)\n",
      "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0756) | Acc: (97.81%) (35180/35968)\n",
      "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0754) | Acc: (97.81%) (36433/37248)\n",
      "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0756) | Acc: (97.81%) (37684/38528)\n",
      "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0755) | Acc: (97.82%) (38939/39808)\n",
      "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0754) | Acc: (97.81%) (40187/41088)\n",
      "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0750) | Acc: (97.82%) (41443/42368)\n",
      "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0748) | Acc: (97.84%) (42706/43648)\n",
      "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0746) | Acc: (97.85%) (43961/44928)\n",
      "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0746) | Acc: (97.85%) (45215/46208)\n",
      "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0749) | Acc: (97.84%) (46460/47488)\n",
      "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0750) | Acc: (97.84%) (47716/48768)\n",
      "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0750) | Acc: (97.84%) (48922/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3701) | Acc: (89.02%) (8902/10000)\n",
      "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0663) | Acc: (97.66%) (125/128)\n",
      "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0771) | Acc: (97.66%) (1375/1408)\n",
      "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0754) | Acc: (97.66%) (2625/2688)\n",
      "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0747) | Acc: (97.76%) (3879/3968)\n",
      "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0731) | Acc: (97.77%) (5131/5248)\n",
      "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0744) | Acc: (97.79%) (6384/6528)\n",
      "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0755) | Acc: (97.73%) (7631/7808)\n",
      "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0759) | Acc: (97.76%) (8884/9088)\n",
      "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0750) | Acc: (97.80%) (10140/10368)\n",
      "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0739) | Acc: (97.88%) (11401/11648)\n",
      "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0736) | Acc: (97.92%) (12659/12928)\n",
      "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0740) | Acc: (97.89%) (13908/14208)\n",
      "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0746) | Acc: (97.85%) (15155/15488)\n",
      "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0749) | Acc: (97.84%) (16406/16768)\n",
      "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0749) | Acc: (97.83%) (17657/18048)\n",
      "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0740) | Acc: (97.85%) (18913/19328)\n",
      "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0735) | Acc: (97.87%) (20169/20608)\n",
      "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0735) | Acc: (97.86%) (21419/21888)\n",
      "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0734) | Acc: (97.85%) (22670/23168)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0735) | Acc: (97.84%) (23921/24448)\n",
      "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0732) | Acc: (97.86%) (25178/25728)\n",
      "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0733) | Acc: (97.86%) (26430/27008)\n",
      "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0733) | Acc: (97.84%) (27677/28288)\n",
      "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0736) | Acc: (97.82%) (28924/29568)\n",
      "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0739) | Acc: (97.80%) (30169/30848)\n",
      "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0734) | Acc: (97.83%) (31432/32128)\n",
      "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0735) | Acc: (97.84%) (32686/33408)\n",
      "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0729) | Acc: (97.86%) (33944/34688)\n",
      "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0727) | Acc: (97.87%) (35203/35968)\n",
      "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0729) | Acc: (97.86%) (36452/37248)\n",
      "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0729) | Acc: (97.85%) (37701/38528)\n",
      "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0730) | Acc: (97.86%) (38955/39808)\n",
      "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0730) | Acc: (97.85%) (40206/41088)\n",
      "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0729) | Acc: (97.86%) (41461/42368)\n",
      "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0731) | Acc: (97.85%) (42709/43648)\n",
      "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0731) | Acc: (97.85%) (43961/44928)\n",
      "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0734) | Acc: (97.83%) (45204/46208)\n",
      "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0736) | Acc: (97.82%) (46453/47488)\n",
      "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0737) | Acc: (97.82%) (47703/48768)\n",
      "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0739) | Acc: (97.81%) (48903/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3705) | Acc: (89.14%) (8914/10000)\n",
      "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0590) | Acc: (98.44%) (126/128)\n",
      "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0768) | Acc: (97.23%) (1369/1408)\n",
      "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0758) | Acc: (97.47%) (2620/2688)\n",
      "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0742) | Acc: (97.58%) (3872/3968)\n",
      "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0721) | Acc: (97.83%) (5134/5248)\n",
      "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0722) | Acc: (97.84%) (6387/6528)\n",
      "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0716) | Acc: (97.82%) (7638/7808)\n",
      "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0696) | Acc: (97.89%) (8896/9088)\n",
      "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0702) | Acc: (97.85%) (10145/10368)\n",
      "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0705) | Acc: (97.87%) (11400/11648)\n",
      "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0705) | Acc: (97.89%) (12655/12928)\n",
      "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0709) | Acc: (97.86%) (13904/14208)\n",
      "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0712) | Acc: (97.84%) (15154/15488)\n",
      "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0707) | Acc: (97.89%) (16414/16768)\n",
      "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0703) | Acc: (97.91%) (17671/18048)\n",
      "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0708) | Acc: (97.87%) (18917/19328)\n",
      "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0707) | Acc: (97.86%) (20167/20608)\n",
      "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0710) | Acc: (97.84%) (21415/21888)\n",
      "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0700) | Acc: (97.89%) (22679/23168)\n",
      "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0696) | Acc: (97.93%) (23941/24448)\n",
      "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0691) | Acc: (97.95%) (25201/25728)\n",
      "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0694) | Acc: (97.93%) (26449/27008)\n",
      "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0691) | Acc: (97.94%) (27706/28288)\n",
      "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0692) | Acc: (97.94%) (28959/29568)\n",
      "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0695) | Acc: (97.93%) (30210/30848)\n",
      "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0698) | Acc: (97.93%) (31462/32128)\n",
      "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0705) | Acc: (97.89%) (32703/33408)\n",
      "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0706) | Acc: (97.88%) (33954/34688)\n",
      "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0712) | Acc: (97.84%) (35191/35968)\n",
      "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0717) | Acc: (97.83%) (36438/37248)\n",
      "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0720) | Acc: (97.81%) (37685/38528)\n",
      "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0722) | Acc: (97.79%) (38930/39808)\n",
      "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0723) | Acc: (97.80%) (40184/41088)\n",
      "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0722) | Acc: (97.80%) (41438/42368)\n",
      "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0721) | Acc: (97.81%) (42691/43648)\n",
      "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0722) | Acc: (97.79%) (43937/44928)\n",
      "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0722) | Acc: (97.79%) (45188/46208)\n",
      "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0724) | Acc: (97.79%) (46437/47488)\n",
      "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0728) | Acc: (97.79%) (47688/48768)\n",
      "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0725) | Acc: (97.79%) (48897/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3724) | Acc: (89.32%) (8932/10000)\n",
      "Epoch: 91 | Batch_idx: 0 |  Loss: (0.1166) | Acc: (95.31%) (122/128)\n",
      "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0720) | Acc: (97.80%) (1377/1408)\n",
      "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0714) | Acc: (97.81%) (2629/2688)\n",
      "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0759) | Acc: (97.66%) (3875/3968)\n",
      "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0754) | Acc: (97.66%) (5125/5248)\n",
      "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0728) | Acc: (97.72%) (6379/6528)\n",
      "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0723) | Acc: (97.78%) (7635/7808)\n",
      "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0728) | Acc: (97.74%) (8883/9088)\n",
      "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0752) | Acc: (97.69%) (10128/10368)\n",
      "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0726) | Acc: (97.80%) (11392/11648)\n",
      "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0724) | Acc: (97.83%) (12648/12928)\n",
      "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0727) | Acc: (97.88%) (13907/14208)\n",
      "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0719) | Acc: (97.93%) (15167/15488)\n",
      "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0720) | Acc: (97.92%) (16419/16768)\n",
      "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0714) | Acc: (97.93%) (17675/18048)\n",
      "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0713) | Acc: (97.95%) (18932/19328)\n",
      "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0712) | Acc: (97.95%) (20185/20608)\n",
      "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0716) | Acc: (97.93%) (21436/21888)\n",
      "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0715) | Acc: (97.93%) (22689/23168)\n",
      "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0716) | Acc: (97.93%) (23941/24448)\n",
      "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0723) | Acc: (97.89%) (25186/25728)\n",
      "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0714) | Acc: (97.91%) (26443/27008)\n",
      "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0714) | Acc: (97.89%) (27690/28288)\n",
      "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0720) | Acc: (97.84%) (28930/29568)\n",
      "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0724) | Acc: (97.83%) (30180/30848)\n",
      "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0732) | Acc: (97.81%) (31426/32128)\n",
      "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0733) | Acc: (97.81%) (32676/33408)\n",
      "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0733) | Acc: (97.81%) (33927/34688)\n",
      "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0735) | Acc: (97.80%) (35175/35968)\n",
      "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0735) | Acc: (97.79%) (36425/37248)\n",
      "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0738) | Acc: (97.78%) (37671/38528)\n",
      "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0738) | Acc: (97.76%) (38918/39808)\n",
      "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0739) | Acc: (97.77%) (40170/41088)\n",
      "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0738) | Acc: (97.77%) (41425/42368)\n",
      "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0737) | Acc: (97.78%) (42681/43648)\n",
      "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0737) | Acc: (97.77%) (43928/44928)\n",
      "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0740) | Acc: (97.75%) (45168/46208)\n",
      "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0739) | Acc: (97.75%) (46420/47488)\n",
      "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0744) | Acc: (97.73%) (47662/48768)\n",
      "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0740) | Acc: (97.75%) (48874/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3725) | Acc: (89.19%) (8919/10000)\n",
      "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0911) | Acc: (96.88%) (124/128)\n",
      "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0815) | Acc: (97.02%) (1366/1408)\n",
      "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0814) | Acc: (97.36%) (2617/2688)\n",
      "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0797) | Acc: (97.38%) (3864/3968)\n",
      "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0777) | Acc: (97.48%) (5116/5248)\n",
      "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0789) | Acc: (97.41%) (6359/6528)\n",
      "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0788) | Acc: (97.46%) (7610/7808)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0764) | Acc: (97.60%) (8870/9088)\n",
      "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0760) | Acc: (97.64%) (10123/10368)\n",
      "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0757) | Acc: (97.65%) (11374/11648)\n",
      "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0753) | Acc: (97.64%) (12623/12928)\n",
      "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0748) | Acc: (97.64%) (13872/14208)\n",
      "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0745) | Acc: (97.66%) (15126/15488)\n",
      "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0747) | Acc: (97.64%) (16372/16768)\n",
      "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0746) | Acc: (97.63%) (17620/18048)\n",
      "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0737) | Acc: (97.65%) (18874/19328)\n",
      "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0739) | Acc: (97.67%) (20127/20608)\n",
      "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0740) | Acc: (97.67%) (21377/21888)\n",
      "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0734) | Acc: (97.70%) (22635/23168)\n",
      "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0730) | Acc: (97.72%) (23891/24448)\n",
      "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0733) | Acc: (97.72%) (25141/25728)\n",
      "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0740) | Acc: (97.69%) (26383/27008)\n",
      "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0740) | Acc: (97.68%) (27631/28288)\n",
      "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0738) | Acc: (97.67%) (28879/29568)\n",
      "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0734) | Acc: (97.67%) (30130/30848)\n",
      "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0732) | Acc: (97.67%) (31378/32128)\n",
      "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0731) | Acc: (97.68%) (32634/33408)\n",
      "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0731) | Acc: (97.69%) (33886/34688)\n",
      "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0728) | Acc: (97.70%) (35142/35968)\n",
      "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0731) | Acc: (97.68%) (36384/37248)\n",
      "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0734) | Acc: (97.67%) (37630/38528)\n",
      "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0732) | Acc: (97.67%) (38880/39808)\n",
      "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0727) | Acc: (97.70%) (40143/41088)\n",
      "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0729) | Acc: (97.70%) (41392/42368)\n",
      "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0732) | Acc: (97.70%) (42643/43648)\n",
      "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0730) | Acc: (97.70%) (43896/44928)\n",
      "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0727) | Acc: (97.72%) (45154/46208)\n",
      "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0727) | Acc: (97.73%) (46409/47488)\n",
      "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0728) | Acc: (97.71%) (47653/48768)\n",
      "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0729) | Acc: (97.72%) (48860/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3731) | Acc: (89.09%) (8909/10000)\n",
      "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0819) | Acc: (97.66%) (125/128)\n",
      "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0701) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0762) | Acc: (97.81%) (2629/2688)\n",
      "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0796) | Acc: (97.73%) (3878/3968)\n",
      "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0774) | Acc: (97.73%) (5129/5248)\n",
      "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0779) | Acc: (97.72%) (6379/6528)\n",
      "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0771) | Acc: (97.69%) (7628/7808)\n",
      "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0757) | Acc: (97.73%) (8882/9088)\n",
      "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0744) | Acc: (97.80%) (10140/10368)\n",
      "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0743) | Acc: (97.79%) (11390/11648)\n",
      "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0737) | Acc: (97.78%) (12641/12928)\n",
      "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0737) | Acc: (97.76%) (13890/14208)\n",
      "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0736) | Acc: (97.77%) (15143/15488)\n",
      "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0734) | Acc: (97.79%) (16397/16768)\n",
      "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0735) | Acc: (97.79%) (17650/18048)\n",
      "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0726) | Acc: (97.84%) (18911/19328)\n",
      "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0728) | Acc: (97.84%) (20163/20608)\n",
      "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0726) | Acc: (97.86%) (21419/21888)\n",
      "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0721) | Acc: (97.90%) (22681/23168)\n",
      "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0719) | Acc: (97.91%) (23936/24448)\n",
      "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0720) | Acc: (97.91%) (25189/25728)\n",
      "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0721) | Acc: (97.89%) (26437/27008)\n",
      "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0720) | Acc: (97.88%) (27689/28288)\n",
      "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0719) | Acc: (97.88%) (28941/29568)\n",
      "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0722) | Acc: (97.87%) (30190/30848)\n",
      "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0719) | Acc: (97.88%) (31446/32128)\n",
      "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0721) | Acc: (97.87%) (32695/33408)\n",
      "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0722) | Acc: (97.87%) (33948/34688)\n",
      "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0721) | Acc: (97.86%) (35198/35968)\n",
      "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0717) | Acc: (97.88%) (36457/37248)\n",
      "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0719) | Acc: (97.87%) (37708/38528)\n",
      "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0717) | Acc: (97.87%) (38962/39808)\n",
      "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0719) | Acc: (97.87%) (40212/41088)\n",
      "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0721) | Acc: (97.86%) (41463/42368)\n",
      "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0720) | Acc: (97.86%) (42713/43648)\n",
      "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0724) | Acc: (97.85%) (43960/44928)\n",
      "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0721) | Acc: (97.86%) (45218/46208)\n",
      "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0725) | Acc: (97.83%) (46456/47488)\n",
      "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0723) | Acc: (97.84%) (47715/48768)\n",
      "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0720) | Acc: (97.85%) (48923/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3734) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0643) | Acc: (99.22%) (127/128)\n",
      "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0597) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0674) | Acc: (97.95%) (2633/2688)\n",
      "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0662) | Acc: (98.08%) (3892/3968)\n",
      "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0648) | Acc: (98.15%) (5151/5248)\n",
      "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0683) | Acc: (97.93%) (6393/6528)\n",
      "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0690) | Acc: (97.99%) (7651/7808)\n",
      "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0690) | Acc: (98.01%) (8907/9088)\n",
      "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0710) | Acc: (97.97%) (10158/10368)\n",
      "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0718) | Acc: (97.96%) (11410/11648)\n",
      "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0732) | Acc: (97.88%) (12654/12928)\n",
      "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0727) | Acc: (97.87%) (13906/14208)\n",
      "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0727) | Acc: (97.84%) (15153/15488)\n",
      "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0723) | Acc: (97.87%) (16411/16768)\n",
      "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0722) | Acc: (97.83%) (17657/18048)\n",
      "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0710) | Acc: (97.88%) (18918/19328)\n",
      "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0716) | Acc: (97.86%) (20168/20608)\n",
      "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0720) | Acc: (97.84%) (21416/21888)\n",
      "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0726) | Acc: (97.80%) (22659/23168)\n",
      "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0726) | Acc: (97.78%) (23906/24448)\n",
      "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0726) | Acc: (97.78%) (25157/25728)\n",
      "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0723) | Acc: (97.79%) (26410/27008)\n",
      "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0727) | Acc: (97.77%) (27656/28288)\n",
      "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0722) | Acc: (97.79%) (28915/29568)\n",
      "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0723) | Acc: (97.79%) (30166/30848)\n",
      "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0728) | Acc: (97.77%) (31410/32128)\n",
      "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0733) | Acc: (97.74%) (32654/33408)\n",
      "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0733) | Acc: (97.74%) (33905/34688)\n",
      "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0729) | Acc: (97.77%) (35166/35968)\n",
      "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0726) | Acc: (97.79%) (36423/37248)\n",
      "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0723) | Acc: (97.82%) (37687/38528)\n",
      "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0726) | Acc: (97.80%) (38933/39808)\n",
      "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0726) | Acc: (97.81%) (40188/41088)\n",
      "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0725) | Acc: (97.81%) (41442/42368)\n",
      "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0727) | Acc: (97.81%) (42693/43648)\n",
      "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0725) | Acc: (97.82%) (43947/44928)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0723) | Acc: (97.82%) (45200/46208)\n",
      "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0724) | Acc: (97.82%) (46453/47488)\n",
      "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0728) | Acc: (97.80%) (47697/48768)\n",
      "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0726) | Acc: (97.80%) (48902/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3751) | Acc: (89.23%) (8923/10000)\n",
      "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0379) | Acc: (100.00%) (128/128)\n",
      "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0719) | Acc: (97.51%) (1373/1408)\n",
      "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0739) | Acc: (97.58%) (2623/2688)\n",
      "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0718) | Acc: (97.86%) (3883/3968)\n",
      "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0711) | Acc: (97.77%) (5131/5248)\n",
      "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0700) | Acc: (97.89%) (6390/6528)\n",
      "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0695) | Acc: (97.99%) (7651/7808)\n",
      "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0677) | Acc: (98.07%) (8913/9088)\n",
      "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0686) | Acc: (97.99%) (10160/10368)\n",
      "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0689) | Acc: (97.96%) (11410/11648)\n",
      "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0704) | Acc: (97.83%) (12648/12928)\n",
      "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0701) | Acc: (97.83%) (13900/14208)\n",
      "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0686) | Acc: (97.90%) (15162/15488)\n",
      "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0696) | Acc: (97.86%) (16409/16768)\n",
      "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0697) | Acc: (97.86%) (17662/18048)\n",
      "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0696) | Acc: (97.86%) (18915/19328)\n",
      "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0697) | Acc: (97.88%) (20171/20608)\n",
      "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0697) | Acc: (97.88%) (21425/21888)\n",
      "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0701) | Acc: (97.90%) (22681/23168)\n",
      "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0700) | Acc: (97.91%) (23937/24448)\n",
      "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0712) | Acc: (97.87%) (25179/25728)\n",
      "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0713) | Acc: (97.84%) (26425/27008)\n",
      "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0713) | Acc: (97.84%) (27677/28288)\n",
      "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0714) | Acc: (97.84%) (28930/29568)\n",
      "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0714) | Acc: (97.85%) (30184/30848)\n",
      "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0715) | Acc: (97.86%) (31439/32128)\n",
      "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0722) | Acc: (97.82%) (32679/33408)\n",
      "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0718) | Acc: (97.84%) (33938/34688)\n",
      "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0716) | Acc: (97.86%) (35198/35968)\n",
      "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0713) | Acc: (97.88%) (36457/37248)\n",
      "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0712) | Acc: (97.90%) (37718/38528)\n",
      "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0711) | Acc: (97.92%) (38981/39808)\n",
      "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0708) | Acc: (97.93%) (40237/41088)\n",
      "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0706) | Acc: (97.93%) (41492/42368)\n",
      "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0705) | Acc: (97.93%) (42746/43648)\n",
      "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0707) | Acc: (97.93%) (43997/44928)\n",
      "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0706) | Acc: (97.93%) (45252/46208)\n",
      "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0706) | Acc: (97.93%) (46503/47488)\n",
      "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0702) | Acc: (97.94%) (47763/48768)\n",
      "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0701) | Acc: (97.94%) (48971/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3704) | Acc: (89.44%) (8944/10000)\n",
      "Epoch: 96 | Batch_idx: 0 |  Loss: (0.1052) | Acc: (96.09%) (123/128)\n",
      "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0715) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0683) | Acc: (98.18%) (2639/2688)\n",
      "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0680) | Acc: (98.11%) (3893/3968)\n",
      "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0689) | Acc: (98.06%) (5146/5248)\n",
      "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0662) | Acc: (98.10%) (6404/6528)\n",
      "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0674) | Acc: (98.04%) (7655/7808)\n",
      "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0671) | Acc: (98.03%) (8909/9088)\n",
      "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0671) | Acc: (98.03%) (10164/10368)\n",
      "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0671) | Acc: (98.05%) (11421/11648)\n",
      "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0675) | Acc: (98.03%) (12673/12928)\n",
      "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0678) | Acc: (97.98%) (13921/14208)\n",
      "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0680) | Acc: (97.97%) (15174/15488)\n",
      "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0681) | Acc: (97.95%) (16425/16768)\n",
      "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0680) | Acc: (97.95%) (17678/18048)\n",
      "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0685) | Acc: (97.95%) (18932/19328)\n",
      "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0689) | Acc: (97.91%) (20178/20608)\n",
      "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0689) | Acc: (97.94%) (21438/21888)\n",
      "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0693) | Acc: (97.93%) (22689/23168)\n",
      "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0689) | Acc: (97.96%) (23950/24448)\n",
      "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0697) | Acc: (97.92%) (25193/25728)\n",
      "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0696) | Acc: (97.92%) (26447/27008)\n",
      "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0693) | Acc: (97.93%) (27703/28288)\n",
      "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0690) | Acc: (97.94%) (28960/29568)\n",
      "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0689) | Acc: (97.95%) (30217/30848)\n",
      "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0691) | Acc: (97.95%) (31470/32128)\n",
      "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0693) | Acc: (97.94%) (32721/33408)\n",
      "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0691) | Acc: (97.95%) (33978/34688)\n",
      "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0695) | Acc: (97.93%) (35223/35968)\n",
      "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0691) | Acc: (97.94%) (36481/37248)\n",
      "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0693) | Acc: (97.94%) (37735/38528)\n",
      "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0695) | Acc: (97.95%) (38993/39808)\n",
      "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0692) | Acc: (97.96%) (40248/41088)\n",
      "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0692) | Acc: (97.95%) (41501/42368)\n",
      "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0692) | Acc: (97.94%) (42750/43648)\n",
      "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0694) | Acc: (97.93%) (44000/44928)\n",
      "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0691) | Acc: (97.94%) (45257/46208)\n",
      "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0690) | Acc: (97.94%) (46512/47488)\n",
      "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0692) | Acc: (97.92%) (47755/48768)\n",
      "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0697) | Acc: (97.91%) (48956/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3734) | Acc: (89.04%) (8904/10000)\n",
      "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0696) | Acc: (98.44%) (126/128)\n",
      "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0670) | Acc: (97.87%) (1378/1408)\n",
      "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0651) | Acc: (97.95%) (2633/2688)\n",
      "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0658) | Acc: (97.86%) (3883/3968)\n",
      "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0694) | Acc: (97.71%) (5128/5248)\n",
      "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0694) | Acc: (97.86%) (6388/6528)\n",
      "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0690) | Acc: (97.87%) (7642/7808)\n",
      "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0690) | Acc: (97.91%) (8898/9088)\n",
      "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0707) | Acc: (97.90%) (10150/10368)\n",
      "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0707) | Acc: (97.86%) (11399/11648)\n",
      "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0714) | Acc: (97.81%) (12645/12928)\n",
      "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0721) | Acc: (97.73%) (13885/14208)\n",
      "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0709) | Acc: (97.80%) (15147/15488)\n",
      "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0701) | Acc: (97.82%) (16403/16768)\n",
      "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0695) | Acc: (97.87%) (17663/18048)\n",
      "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0692) | Acc: (97.87%) (18916/19328)\n",
      "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0686) | Acc: (97.88%) (20172/20608)\n",
      "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0688) | Acc: (97.87%) (21422/21888)\n",
      "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0686) | Acc: (97.89%) (22678/23168)\n",
      "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0683) | Acc: (97.91%) (23938/24448)\n",
      "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0682) | Acc: (97.92%) (25192/25728)\n",
      "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0677) | Acc: (97.93%) (26450/27008)\n",
      "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0675) | Acc: (97.94%) (27704/28288)\n",
      "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0670) | Acc: (97.95%) (28962/29568)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0669) | Acc: (97.97%) (30222/30848)\n",
      "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0672) | Acc: (97.99%) (31482/32128)\n",
      "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0671) | Acc: (98.00%) (32740/33408)\n",
      "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0669) | Acc: (98.03%) (34003/34688)\n",
      "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0674) | Acc: (98.00%) (35249/35968)\n",
      "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0673) | Acc: (97.99%) (36501/37248)\n",
      "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0671) | Acc: (97.99%) (37754/38528)\n",
      "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0673) | Acc: (98.00%) (39012/39808)\n",
      "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0674) | Acc: (97.99%) (40264/41088)\n",
      "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0671) | Acc: (98.00%) (41522/42368)\n",
      "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0675) | Acc: (97.99%) (42769/43648)\n",
      "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0676) | Acc: (97.98%) (44019/44928)\n",
      "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0673) | Acc: (97.99%) (45279/46208)\n",
      "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0674) | Acc: (97.98%) (46530/47488)\n",
      "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0677) | Acc: (97.98%) (47781/48768)\n",
      "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0678) | Acc: (97.98%) (48992/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3737) | Acc: (89.33%) (8933/10000)\n",
      "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0522) | Acc: (100.00%) (128/128)\n",
      "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0489) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0549) | Acc: (98.51%) (2648/2688)\n",
      "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0548) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0586) | Acc: (98.38%) (5163/5248)\n",
      "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0611) | Acc: (98.33%) (6419/6528)\n",
      "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0617) | Acc: (98.32%) (7677/7808)\n",
      "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0619) | Acc: (98.25%) (8929/9088)\n",
      "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0622) | Acc: (98.28%) (10190/10368)\n",
      "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0624) | Acc: (98.31%) (11451/11648)\n",
      "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0643) | Acc: (98.21%) (12697/12928)\n",
      "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0649) | Acc: (98.18%) (13950/14208)\n",
      "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0647) | Acc: (98.16%) (15203/15488)\n",
      "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0653) | Acc: (98.11%) (16451/16768)\n",
      "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0656) | Acc: (98.10%) (17705/18048)\n",
      "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0661) | Acc: (98.07%) (18955/19328)\n",
      "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0661) | Acc: (98.07%) (20211/20608)\n",
      "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0660) | Acc: (98.09%) (21469/21888)\n",
      "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0669) | Acc: (98.06%) (22719/23168)\n",
      "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0667) | Acc: (98.07%) (23977/24448)\n",
      "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0668) | Acc: (98.07%) (25231/25728)\n",
      "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0670) | Acc: (98.05%) (26482/27008)\n",
      "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0671) | Acc: (98.03%) (27732/28288)\n",
      "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0672) | Acc: (98.04%) (28987/29568)\n",
      "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0673) | Acc: (98.05%) (30246/30848)\n",
      "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0675) | Acc: (98.04%) (31497/32128)\n",
      "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0676) | Acc: (98.02%) (32747/33408)\n",
      "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0671) | Acc: (98.04%) (34009/34688)\n",
      "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0670) | Acc: (98.05%) (35266/35968)\n",
      "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0674) | Acc: (98.04%) (36517/37248)\n",
      "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0674) | Acc: (98.04%) (37774/38528)\n",
      "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0678) | Acc: (98.03%) (39022/39808)\n",
      "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0676) | Acc: (98.04%) (40281/41088)\n",
      "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0677) | Acc: (98.04%) (41537/42368)\n",
      "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0679) | Acc: (98.03%) (42787/43648)\n",
      "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0679) | Acc: (98.03%) (44042/44928)\n",
      "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0680) | Acc: (98.02%) (45294/46208)\n",
      "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0681) | Acc: (98.02%) (46547/47488)\n",
      "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0680) | Acc: (98.03%) (47809/48768)\n",
      "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0681) | Acc: (98.03%) (49014/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3792) | Acc: (89.07%) (8907/10000)\n",
      "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0681) | Acc: (97.66%) (125/128)\n",
      "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0606) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0647) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0640) | Acc: (98.36%) (3903/3968)\n",
      "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0654) | Acc: (98.30%) (5159/5248)\n",
      "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0676) | Acc: (98.16%) (6408/6528)\n",
      "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0672) | Acc: (98.17%) (7665/7808)\n",
      "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0674) | Acc: (98.13%) (8918/9088)\n",
      "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0681) | Acc: (98.09%) (10170/10368)\n",
      "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0666) | Acc: (98.15%) (11432/11648)\n",
      "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0668) | Acc: (98.17%) (12691/12928)\n",
      "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0670) | Acc: (98.16%) (13946/14208)\n",
      "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0687) | Acc: (98.06%) (15188/15488)\n",
      "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0690) | Acc: (98.04%) (16439/16768)\n",
      "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0686) | Acc: (98.05%) (17696/18048)\n",
      "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0684) | Acc: (98.06%) (18953/19328)\n",
      "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0687) | Acc: (98.03%) (20203/20608)\n",
      "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0687) | Acc: (98.04%) (21458/21888)\n",
      "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0688) | Acc: (98.05%) (22717/23168)\n",
      "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0680) | Acc: (98.08%) (23979/24448)\n",
      "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0685) | Acc: (98.06%) (25228/25728)\n",
      "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0687) | Acc: (98.03%) (26476/27008)\n",
      "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0683) | Acc: (98.05%) (27737/28288)\n",
      "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0679) | Acc: (98.07%) (28996/29568)\n",
      "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0675) | Acc: (98.06%) (30251/30848)\n",
      "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0674) | Acc: (98.08%) (31510/32128)\n",
      "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0675) | Acc: (98.06%) (32761/33408)\n",
      "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0676) | Acc: (98.05%) (34013/34688)\n",
      "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0678) | Acc: (98.05%) (35267/35968)\n",
      "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0681) | Acc: (98.04%) (36517/37248)\n",
      "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0681) | Acc: (98.05%) (37775/38528)\n",
      "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0683) | Acc: (98.04%) (39029/39808)\n",
      "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0682) | Acc: (98.05%) (40285/41088)\n",
      "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0680) | Acc: (98.06%) (41546/42368)\n",
      "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0680) | Acc: (98.05%) (42797/43648)\n",
      "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0679) | Acc: (98.06%) (44056/44928)\n",
      "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0679) | Acc: (98.06%) (45312/46208)\n",
      "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0679) | Acc: (98.05%) (46562/47488)\n",
      "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0680) | Acc: (98.04%) (47814/48768)\n",
      "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0683) | Acc: (98.03%) (49013/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3790) | Acc: (89.27%) (8927/10000)\n",
      "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0442) | Acc: (98.44%) (126/128)\n",
      "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0629) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0641) | Acc: (98.03%) (2635/2688)\n",
      "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0685) | Acc: (97.81%) (3881/3968)\n",
      "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0694) | Acc: (97.77%) (5131/5248)\n",
      "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0711) | Acc: (97.70%) (6378/6528)\n",
      "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0722) | Acc: (97.72%) (7630/7808)\n",
      "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0720) | Acc: (97.78%) (8886/9088)\n",
      "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0717) | Acc: (97.82%) (10142/10368)\n",
      "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0702) | Acc: (97.90%) (11403/11648)\n",
      "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0699) | Acc: (97.92%) (12659/12928)\n",
      "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0701) | Acc: (97.90%) (13909/14208)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0694) | Acc: (97.90%) (15163/15488)\n",
      "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0683) | Acc: (97.96%) (16426/16768)\n",
      "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0684) | Acc: (97.96%) (17679/18048)\n",
      "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0684) | Acc: (97.97%) (18936/19328)\n",
      "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0685) | Acc: (97.98%) (20192/20608)\n",
      "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0685) | Acc: (97.96%) (21442/21888)\n",
      "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0680) | Acc: (98.00%) (22704/23168)\n",
      "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0683) | Acc: (97.98%) (23953/24448)\n",
      "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0683) | Acc: (97.97%) (25205/25728)\n",
      "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0677) | Acc: (97.99%) (26465/27008)\n",
      "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0676) | Acc: (98.00%) (27722/28288)\n",
      "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0673) | Acc: (97.99%) (28975/29568)\n",
      "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0672) | Acc: (97.98%) (30225/30848)\n",
      "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0670) | Acc: (98.00%) (31485/32128)\n",
      "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0673) | Acc: (97.99%) (32738/33408)\n",
      "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0674) | Acc: (98.00%) (33993/34688)\n",
      "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0675) | Acc: (97.98%) (35243/35968)\n",
      "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0678) | Acc: (97.98%) (36497/37248)\n",
      "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0680) | Acc: (97.99%) (37753/38528)\n",
      "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0677) | Acc: (98.00%) (39012/39808)\n",
      "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0676) | Acc: (98.01%) (40269/41088)\n",
      "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0675) | Acc: (98.01%) (41524/42368)\n",
      "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0672) | Acc: (98.03%) (42788/43648)\n",
      "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0674) | Acc: (98.02%) (44039/44928)\n",
      "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0674) | Acc: (98.02%) (45292/46208)\n",
      "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0674) | Acc: (98.02%) (46549/47488)\n",
      "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0671) | Acc: (98.03%) (47809/48768)\n",
      "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0669) | Acc: (98.04%) (49021/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3781) | Acc: (89.14%) (8914/10000)\n",
      "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0870) | Acc: (98.44%) (126/128)\n",
      "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0736) | Acc: (97.80%) (1377/1408)\n",
      "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0702) | Acc: (97.88%) (2631/2688)\n",
      "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0662) | Acc: (98.11%) (3893/3968)\n",
      "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0640) | Acc: (98.17%) (5152/5248)\n",
      "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0651) | Acc: (98.10%) (6404/6528)\n",
      "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0647) | Acc: (98.01%) (7653/7808)\n",
      "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0666) | Acc: (97.92%) (8899/9088)\n",
      "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0661) | Acc: (97.96%) (10157/10368)\n",
      "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0663) | Acc: (97.96%) (11410/11648)\n",
      "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0662) | Acc: (97.94%) (12662/12928)\n",
      "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0670) | Acc: (97.92%) (13913/14208)\n",
      "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0663) | Acc: (97.97%) (15174/15488)\n",
      "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0660) | Acc: (97.98%) (16430/16768)\n",
      "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0662) | Acc: (97.98%) (17684/18048)\n",
      "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0658) | Acc: (98.01%) (18943/19328)\n",
      "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0655) | Acc: (98.02%) (20199/20608)\n",
      "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0653) | Acc: (98.04%) (21459/21888)\n",
      "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0650) | Acc: (98.08%) (22723/23168)\n",
      "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0654) | Acc: (98.06%) (23974/24448)\n",
      "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0656) | Acc: (98.06%) (25229/25728)\n",
      "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0654) | Acc: (98.06%) (26483/27008)\n",
      "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0654) | Acc: (98.07%) (27741/28288)\n",
      "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0656) | Acc: (98.06%) (28995/29568)\n",
      "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0657) | Acc: (98.05%) (30245/30848)\n",
      "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0654) | Acc: (98.05%) (31502/32128)\n",
      "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0655) | Acc: (98.06%) (32760/33408)\n",
      "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0659) | Acc: (98.05%) (34013/34688)\n",
      "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0657) | Acc: (98.07%) (35273/35968)\n",
      "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0658) | Acc: (98.06%) (36526/37248)\n",
      "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0655) | Acc: (98.08%) (37789/38528)\n",
      "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0655) | Acc: (98.08%) (39044/39808)\n",
      "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0658) | Acc: (98.07%) (40295/41088)\n",
      "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0655) | Acc: (98.08%) (41554/42368)\n",
      "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0660) | Acc: (98.05%) (42796/43648)\n",
      "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0661) | Acc: (98.05%) (44052/44928)\n",
      "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0663) | Acc: (98.04%) (45302/46208)\n",
      "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0662) | Acc: (98.05%) (46560/47488)\n",
      "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0659) | Acc: (98.06%) (47823/48768)\n",
      "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0658) | Acc: (98.07%) (49037/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3788) | Acc: (89.28%) (8928/10000)\n",
      "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0889) | Acc: (97.66%) (125/128)\n",
      "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0631) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0676) | Acc: (97.95%) (2633/2688)\n",
      "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0664) | Acc: (98.01%) (3889/3968)\n",
      "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0655) | Acc: (98.09%) (5148/5248)\n",
      "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0666) | Acc: (98.04%) (6400/6528)\n",
      "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0653) | Acc: (98.09%) (7659/7808)\n",
      "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0649) | Acc: (98.16%) (8921/9088)\n",
      "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0641) | Acc: (98.18%) (10179/10368)\n",
      "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0641) | Acc: (98.21%) (11439/11648)\n",
      "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0647) | Acc: (98.17%) (12691/12928)\n",
      "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0648) | Acc: (98.15%) (13945/14208)\n",
      "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0654) | Acc: (98.14%) (15200/15488)\n",
      "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0656) | Acc: (98.09%) (16447/16768)\n",
      "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0662) | Acc: (98.04%) (17694/18048)\n",
      "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0659) | Acc: (98.04%) (18949/19328)\n",
      "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0660) | Acc: (98.03%) (20202/20608)\n",
      "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0655) | Acc: (98.07%) (21465/21888)\n",
      "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0652) | Acc: (98.08%) (22723/23168)\n",
      "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0659) | Acc: (98.06%) (23973/24448)\n",
      "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0661) | Acc: (98.05%) (25227/25728)\n",
      "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0656) | Acc: (98.07%) (26486/27008)\n",
      "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0659) | Acc: (98.07%) (27742/28288)\n",
      "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0655) | Acc: (98.09%) (29004/29568)\n",
      "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0658) | Acc: (98.08%) (30257/30848)\n",
      "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0656) | Acc: (98.10%) (31518/32128)\n",
      "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0651) | Acc: (98.13%) (32783/33408)\n",
      "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0652) | Acc: (98.12%) (34037/34688)\n",
      "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0657) | Acc: (98.10%) (35286/35968)\n",
      "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0658) | Acc: (98.10%) (36539/37248)\n",
      "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0657) | Acc: (98.09%) (37794/38528)\n",
      "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0658) | Acc: (98.09%) (39046/39808)\n",
      "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0658) | Acc: (98.09%) (40304/41088)\n",
      "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0662) | Acc: (98.08%) (41555/42368)\n",
      "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0662) | Acc: (98.08%) (42808/43648)\n",
      "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0659) | Acc: (98.09%) (44068/44928)\n",
      "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0657) | Acc: (98.10%) (45332/46208)\n",
      "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0658) | Acc: (98.10%) (46588/47488)\n",
      "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0656) | Acc: (98.11%) (47845/48768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0655) | Acc: (98.11%) (49054/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3833) | Acc: (89.11%) (8911/10000)\n",
      "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0801) | Acc: (96.88%) (124/128)\n",
      "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0593) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0599) | Acc: (98.25%) (2641/2688)\n",
      "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0641) | Acc: (97.96%) (3887/3968)\n",
      "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0640) | Acc: (98.04%) (5145/5248)\n",
      "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0628) | Acc: (98.09%) (6403/6528)\n",
      "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0644) | Acc: (98.09%) (7659/7808)\n",
      "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0639) | Acc: (98.17%) (8922/9088)\n",
      "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0647) | Acc: (98.19%) (10180/10368)\n",
      "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0640) | Acc: (98.20%) (11438/11648)\n",
      "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0651) | Acc: (98.16%) (12690/12928)\n",
      "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0654) | Acc: (98.16%) (13946/14208)\n",
      "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0657) | Acc: (98.11%) (15195/15488)\n",
      "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0651) | Acc: (98.13%) (16455/16768)\n",
      "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0652) | Acc: (98.14%) (17712/18048)\n",
      "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0647) | Acc: (98.19%) (18979/19328)\n",
      "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0648) | Acc: (98.18%) (20232/20608)\n",
      "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0653) | Acc: (98.16%) (21485/21888)\n",
      "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0652) | Acc: (98.15%) (22740/23168)\n",
      "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0649) | Acc: (98.16%) (23998/24448)\n",
      "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0645) | Acc: (98.15%) (25253/25728)\n",
      "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0647) | Acc: (98.17%) (26513/27008)\n",
      "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0650) | Acc: (98.14%) (27763/28288)\n",
      "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0648) | Acc: (98.14%) (29019/29568)\n",
      "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0649) | Acc: (98.14%) (30274/30848)\n",
      "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0649) | Acc: (98.13%) (31526/32128)\n",
      "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0652) | Acc: (98.12%) (32780/33408)\n",
      "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0655) | Acc: (98.10%) (34028/34688)\n",
      "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0657) | Acc: (98.09%) (35281/35968)\n",
      "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0652) | Acc: (98.12%) (36546/37248)\n",
      "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0651) | Acc: (98.11%) (37800/38528)\n",
      "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0650) | Acc: (98.10%) (39053/39808)\n",
      "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0645) | Acc: (98.13%) (40319/41088)\n",
      "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0646) | Acc: (98.12%) (41573/42368)\n",
      "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0650) | Acc: (98.12%) (42828/43648)\n",
      "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0648) | Acc: (98.12%) (44085/44928)\n",
      "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0651) | Acc: (98.10%) (45329/46208)\n",
      "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0652) | Acc: (98.10%) (46584/47488)\n",
      "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0652) | Acc: (98.10%) (47842/48768)\n",
      "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0655) | Acc: (98.09%) (49046/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3838) | Acc: (89.15%) (8915/10000)\n",
      "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0601) | Acc: (97.66%) (125/128)\n",
      "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0629) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0625) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0619) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0634) | Acc: (98.40%) (5164/5248)\n",
      "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0621) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0621) | Acc: (98.40%) (7683/7808)\n",
      "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0611) | Acc: (98.40%) (8943/9088)\n",
      "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0614) | Acc: (98.39%) (10201/10368)\n",
      "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0622) | Acc: (98.36%) (11457/11648)\n",
      "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0627) | Acc: (98.31%) (12709/12928)\n",
      "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0628) | Acc: (98.30%) (13967/14208)\n",
      "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0624) | Acc: (98.32%) (15228/15488)\n",
      "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0640) | Acc: (98.23%) (16472/16768)\n",
      "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0641) | Acc: (98.21%) (17725/18048)\n",
      "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0640) | Acc: (98.19%) (18978/19328)\n",
      "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0642) | Acc: (98.18%) (20232/20608)\n",
      "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0641) | Acc: (98.16%) (21486/21888)\n",
      "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0641) | Acc: (98.17%) (22743/23168)\n",
      "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0642) | Acc: (98.18%) (24004/24448)\n",
      "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0643) | Acc: (98.18%) (25260/25728)\n",
      "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0636) | Acc: (98.22%) (26527/27008)\n",
      "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0636) | Acc: (98.23%) (27788/28288)\n",
      "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0637) | Acc: (98.24%) (29049/29568)\n",
      "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0639) | Acc: (98.20%) (30294/30848)\n",
      "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0635) | Acc: (98.22%) (31557/32128)\n",
      "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0635) | Acc: (98.22%) (32815/33408)\n",
      "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0632) | Acc: (98.25%) (34081/34688)\n",
      "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0635) | Acc: (98.24%) (35335/35968)\n",
      "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0638) | Acc: (98.23%) (36588/37248)\n",
      "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0638) | Acc: (98.22%) (37843/38528)\n",
      "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0640) | Acc: (98.21%) (39097/39808)\n",
      "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0644) | Acc: (98.18%) (40342/41088)\n",
      "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0646) | Acc: (98.18%) (41597/42368)\n",
      "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0646) | Acc: (98.17%) (42850/43648)\n",
      "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0645) | Acc: (98.17%) (44108/44928)\n",
      "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0644) | Acc: (98.18%) (45366/46208)\n",
      "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0644) | Acc: (98.18%) (46623/47488)\n",
      "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0644) | Acc: (98.17%) (47876/48768)\n",
      "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0645) | Acc: (98.16%) (49080/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3809) | Acc: (89.18%) (8918/10000)\n",
      "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0630) | Acc: (98.44%) (126/128)\n",
      "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0677) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0722) | Acc: (97.69%) (2626/2688)\n",
      "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0708) | Acc: (97.76%) (3879/3968)\n",
      "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0695) | Acc: (97.79%) (5132/5248)\n",
      "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0673) | Acc: (97.92%) (6392/6528)\n",
      "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0676) | Acc: (97.93%) (7646/7808)\n",
      "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0664) | Acc: (97.98%) (8904/9088)\n",
      "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0665) | Acc: (97.96%) (10157/10368)\n",
      "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0662) | Acc: (98.03%) (11419/11648)\n",
      "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0674) | Acc: (97.99%) (12668/12928)\n",
      "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0679) | Acc: (97.94%) (13916/14208)\n",
      "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0688) | Acc: (97.92%) (15166/15488)\n",
      "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0686) | Acc: (97.95%) (16424/16768)\n",
      "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0677) | Acc: (97.97%) (17682/18048)\n",
      "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0672) | Acc: (98.00%) (18941/19328)\n",
      "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0673) | Acc: (97.99%) (20193/20608)\n",
      "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0662) | Acc: (98.03%) (21457/21888)\n",
      "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0660) | Acc: (98.02%) (22710/23168)\n",
      "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0661) | Acc: (98.03%) (23966/24448)\n",
      "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0659) | Acc: (98.04%) (25223/25728)\n",
      "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0659) | Acc: (98.02%) (26474/27008)\n",
      "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0657) | Acc: (98.05%) (27735/28288)\n",
      "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0653) | Acc: (98.05%) (28992/29568)\n",
      "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0653) | Acc: (98.05%) (30246/30848)\n",
      "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0653) | Acc: (98.05%) (31500/32128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0654) | Acc: (98.04%) (32752/33408)\n",
      "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0650) | Acc: (98.06%) (34015/34688)\n",
      "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0651) | Acc: (98.05%) (35267/35968)\n",
      "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0649) | Acc: (98.06%) (36524/37248)\n",
      "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0648) | Acc: (98.07%) (37784/38528)\n",
      "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0649) | Acc: (98.06%) (39037/39808)\n",
      "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0649) | Acc: (98.06%) (40291/41088)\n",
      "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0651) | Acc: (98.06%) (41544/42368)\n",
      "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0646) | Acc: (98.07%) (42805/43648)\n",
      "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0644) | Acc: (98.08%) (44064/44928)\n",
      "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0645) | Acc: (98.07%) (45314/46208)\n",
      "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0648) | Acc: (98.04%) (46558/47488)\n",
      "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0647) | Acc: (98.05%) (47817/48768)\n",
      "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0644) | Acc: (98.07%) (49037/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3838) | Acc: (89.31%) (8931/10000)\n",
      "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0786) | Acc: (96.09%) (123/128)\n",
      "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0553) | Acc: (98.58%) (1388/1408)\n",
      "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0590) | Acc: (98.33%) (2643/2688)\n",
      "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0605) | Acc: (98.26%) (3899/3968)\n",
      "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0618) | Acc: (98.17%) (5152/5248)\n",
      "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0657) | Acc: (98.10%) (6404/6528)\n",
      "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0645) | Acc: (98.14%) (7663/7808)\n",
      "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0637) | Acc: (98.21%) (8925/9088)\n",
      "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0635) | Acc: (98.18%) (10179/10368)\n",
      "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0626) | Acc: (98.21%) (11439/11648)\n",
      "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0634) | Acc: (98.17%) (12692/12928)\n",
      "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0635) | Acc: (98.18%) (13949/14208)\n",
      "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0656) | Acc: (98.10%) (15193/15488)\n",
      "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0671) | Acc: (98.03%) (16438/16768)\n",
      "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0670) | Acc: (98.03%) (17692/18048)\n",
      "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0672) | Acc: (98.02%) (18946/19328)\n",
      "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0671) | Acc: (98.01%) (20197/20608)\n",
      "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0679) | Acc: (97.98%) (21446/21888)\n",
      "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0677) | Acc: (97.98%) (22701/23168)\n",
      "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0671) | Acc: (98.01%) (23961/24448)\n",
      "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0670) | Acc: (97.99%) (25212/25728)\n",
      "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0665) | Acc: (98.02%) (26472/27008)\n",
      "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0658) | Acc: (98.03%) (27732/28288)\n",
      "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0653) | Acc: (98.06%) (28995/29568)\n",
      "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0653) | Acc: (98.07%) (30253/30848)\n",
      "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0655) | Acc: (98.08%) (31511/32128)\n",
      "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0655) | Acc: (98.08%) (32767/33408)\n",
      "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0656) | Acc: (98.08%) (34023/34688)\n",
      "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0655) | Acc: (98.09%) (35281/35968)\n",
      "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0657) | Acc: (98.08%) (36532/37248)\n",
      "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0658) | Acc: (98.08%) (37789/38528)\n",
      "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0654) | Acc: (98.10%) (39052/39808)\n",
      "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0653) | Acc: (98.11%) (40310/41088)\n",
      "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0652) | Acc: (98.11%) (41569/42368)\n",
      "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0653) | Acc: (98.11%) (42825/43648)\n",
      "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0657) | Acc: (98.10%) (44076/44928)\n",
      "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0656) | Acc: (98.10%) (45329/46208)\n",
      "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0655) | Acc: (98.10%) (46588/47488)\n",
      "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0656) | Acc: (98.10%) (47842/48768)\n",
      "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0654) | Acc: (98.10%) (49051/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3871) | Acc: (89.03%) (8903/10000)\n",
      "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0574) | Acc: (97.66%) (125/128)\n",
      "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0622) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0619) | Acc: (98.33%) (2643/2688)\n",
      "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0600) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0620) | Acc: (98.23%) (5155/5248)\n",
      "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0626) | Acc: (98.19%) (6410/6528)\n",
      "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0622) | Acc: (98.23%) (7670/7808)\n",
      "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0630) | Acc: (98.21%) (8925/9088)\n",
      "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0620) | Acc: (98.23%) (10185/10368)\n",
      "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0637) | Acc: (98.18%) (11436/11648)\n",
      "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0621) | Acc: (98.28%) (12705/12928)\n",
      "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0617) | Acc: (98.30%) (13966/14208)\n",
      "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0619) | Acc: (98.29%) (15223/15488)\n",
      "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0618) | Acc: (98.28%) (16480/16768)\n",
      "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0619) | Acc: (98.25%) (17732/18048)\n",
      "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0630) | Acc: (98.18%) (18977/19328)\n",
      "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0635) | Acc: (98.16%) (20229/20608)\n",
      "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0630) | Acc: (98.16%) (21485/21888)\n",
      "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0638) | Acc: (98.12%) (22732/23168)\n",
      "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0647) | Acc: (98.08%) (23978/24448)\n",
      "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0646) | Acc: (98.09%) (25236/25728)\n",
      "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0645) | Acc: (98.06%) (26485/27008)\n",
      "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0649) | Acc: (98.03%) (27732/28288)\n",
      "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0650) | Acc: (98.02%) (28984/29568)\n",
      "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0646) | Acc: (98.03%) (30241/30848)\n",
      "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0649) | Acc: (98.02%) (31493/32128)\n",
      "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0648) | Acc: (98.04%) (32752/33408)\n",
      "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0650) | Acc: (98.03%) (34006/34688)\n",
      "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0655) | Acc: (98.02%) (35257/35968)\n",
      "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0661) | Acc: (97.99%) (36498/37248)\n",
      "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0660) | Acc: (97.99%) (37752/38528)\n",
      "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0657) | Acc: (98.01%) (39014/39808)\n",
      "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0656) | Acc: (98.01%) (40269/41088)\n",
      "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0655) | Acc: (98.01%) (41525/42368)\n",
      "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0655) | Acc: (98.01%) (42781/43648)\n",
      "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0656) | Acc: (98.01%) (44034/44928)\n",
      "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0654) | Acc: (98.02%) (45295/46208)\n",
      "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0654) | Acc: (98.02%) (46546/47488)\n",
      "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0654) | Acc: (98.02%) (47803/48768)\n",
      "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0652) | Acc: (98.03%) (49015/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3825) | Acc: (89.21%) (8921/10000)\n",
      "Epoch: 108 | Batch_idx: 0 |  Loss: (0.0635) | Acc: (96.09%) (123/128)\n",
      "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0704) | Acc: (97.30%) (1370/1408)\n",
      "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0701) | Acc: (97.32%) (2616/2688)\n",
      "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0673) | Acc: (97.73%) (3878/3968)\n",
      "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0659) | Acc: (97.88%) (5137/5248)\n",
      "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0632) | Acc: (98.04%) (6400/6528)\n",
      "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0629) | Acc: (98.03%) (7654/7808)\n",
      "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0626) | Acc: (98.07%) (8913/9088)\n",
      "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0619) | Acc: (98.18%) (10179/10368)\n",
      "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0605) | Acc: (98.26%) (11445/11648)\n",
      "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0603) | Acc: (98.28%) (12705/12928)\n",
      "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0621) | Acc: (98.18%) (13949/14208)\n",
      "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0624) | Acc: (98.14%) (15200/15488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0619) | Acc: (98.16%) (16459/16768)\n",
      "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0625) | Acc: (98.13%) (17711/18048)\n",
      "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0621) | Acc: (98.15%) (18971/19328)\n",
      "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0618) | Acc: (98.16%) (20228/20608)\n",
      "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0616) | Acc: (98.15%) (21484/21888)\n",
      "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0616) | Acc: (98.17%) (22745/23168)\n",
      "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0615) | Acc: (98.16%) (23999/24448)\n",
      "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0615) | Acc: (98.18%) (25261/25728)\n",
      "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0615) | Acc: (98.20%) (26522/27008)\n",
      "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0615) | Acc: (98.21%) (27781/28288)\n",
      "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0608) | Acc: (98.25%) (29050/29568)\n",
      "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0609) | Acc: (98.24%) (30306/30848)\n",
      "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0613) | Acc: (98.23%) (31560/32128)\n",
      "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0614) | Acc: (98.23%) (32818/33408)\n",
      "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0616) | Acc: (98.22%) (34070/34688)\n",
      "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0618) | Acc: (98.21%) (35325/35968)\n",
      "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0618) | Acc: (98.21%) (36583/37248)\n",
      "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0619) | Acc: (98.21%) (37839/38528)\n",
      "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0616) | Acc: (98.22%) (39099/39808)\n",
      "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0618) | Acc: (98.21%) (40353/41088)\n",
      "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0616) | Acc: (98.22%) (41614/42368)\n",
      "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0614) | Acc: (98.23%) (42877/43648)\n",
      "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0616) | Acc: (98.24%) (44136/44928)\n",
      "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0617) | Acc: (98.24%) (45394/46208)\n",
      "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0616) | Acc: (98.24%) (46652/47488)\n",
      "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0616) | Acc: (98.24%) (47910/48768)\n",
      "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0616) | Acc: (98.23%) (49115/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3868) | Acc: (89.22%) (8922/10000)\n",
      "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0361) | Acc: (100.00%) (128/128)\n",
      "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0481) | Acc: (99.08%) (1395/1408)\n",
      "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0496) | Acc: (98.96%) (2660/2688)\n",
      "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0545) | Acc: (98.64%) (3914/3968)\n",
      "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0564) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0583) | Acc: (98.41%) (6424/6528)\n",
      "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0586) | Acc: (98.42%) (7685/7808)\n",
      "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0592) | Acc: (98.38%) (8941/9088)\n",
      "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0587) | Acc: (98.39%) (10201/10368)\n",
      "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0595) | Acc: (98.38%) (11459/11648)\n",
      "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0603) | Acc: (98.26%) (12703/12928)\n",
      "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0602) | Acc: (98.26%) (13961/14208)\n",
      "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0612) | Acc: (98.21%) (15211/15488)\n",
      "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0628) | Acc: (98.16%) (16460/16768)\n",
      "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0628) | Acc: (98.14%) (17713/18048)\n",
      "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0627) | Acc: (98.14%) (18968/19328)\n",
      "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0620) | Acc: (98.19%) (20235/20608)\n",
      "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0611) | Acc: (98.25%) (21504/21888)\n",
      "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0620) | Acc: (98.20%) (22750/23168)\n",
      "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0620) | Acc: (98.21%) (24010/24448)\n",
      "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0628) | Acc: (98.18%) (25261/25728)\n",
      "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0627) | Acc: (98.20%) (26521/27008)\n",
      "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0628) | Acc: (98.20%) (27779/28288)\n",
      "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0626) | Acc: (98.21%) (29038/29568)\n",
      "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0629) | Acc: (98.18%) (30286/30848)\n",
      "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0629) | Acc: (98.18%) (31542/32128)\n",
      "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0634) | Acc: (98.15%) (32789/33408)\n",
      "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0634) | Acc: (98.16%) (34049/34688)\n",
      "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0634) | Acc: (98.17%) (35310/35968)\n",
      "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0634) | Acc: (98.16%) (36563/37248)\n",
      "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0632) | Acc: (98.17%) (37824/38528)\n",
      "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0632) | Acc: (98.17%) (39079/39808)\n",
      "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0630) | Acc: (98.18%) (40340/41088)\n",
      "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0629) | Acc: (98.20%) (41604/42368)\n",
      "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0625) | Acc: (98.21%) (42867/43648)\n",
      "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0622) | Acc: (98.23%) (44132/44928)\n",
      "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0622) | Acc: (98.23%) (45389/46208)\n",
      "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0624) | Acc: (98.21%) (46639/47488)\n",
      "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0621) | Acc: (98.22%) (47901/48768)\n",
      "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0626) | Acc: (98.19%) (49095/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3884) | Acc: (89.14%) (8914/10000)\n",
      "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0712) | Acc: (98.44%) (126/128)\n",
      "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0515) | Acc: (99.01%) (1394/1408)\n",
      "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0556) | Acc: (98.62%) (2651/2688)\n",
      "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0547) | Acc: (98.69%) (3916/3968)\n",
      "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0551) | Acc: (98.59%) (5174/5248)\n",
      "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0585) | Acc: (98.48%) (6429/6528)\n",
      "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0588) | Acc: (98.49%) (7690/7808)\n",
      "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0604) | Acc: (98.38%) (8941/9088)\n",
      "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0609) | Acc: (98.29%) (10191/10368)\n",
      "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0606) | Acc: (98.28%) (11448/11648)\n",
      "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0604) | Acc: (98.30%) (12708/12928)\n",
      "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0604) | Acc: (98.29%) (13965/14208)\n",
      "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0604) | Acc: (98.24%) (15216/15488)\n",
      "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0606) | Acc: (98.23%) (16472/16768)\n",
      "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0615) | Acc: (98.19%) (17721/18048)\n",
      "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0619) | Acc: (98.16%) (18972/19328)\n",
      "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0622) | Acc: (98.13%) (20222/20608)\n",
      "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0621) | Acc: (98.13%) (21479/21888)\n",
      "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0617) | Acc: (98.16%) (22741/23168)\n",
      "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0614) | Acc: (98.17%) (24000/24448)\n",
      "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0619) | Acc: (98.15%) (25252/25728)\n",
      "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0618) | Acc: (98.16%) (26510/27008)\n",
      "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0618) | Acc: (98.15%) (27765/28288)\n",
      "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0615) | Acc: (98.18%) (29030/29568)\n",
      "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0615) | Acc: (98.19%) (30291/30848)\n",
      "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0617) | Acc: (98.19%) (31545/32128)\n",
      "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0617) | Acc: (98.17%) (32797/33408)\n",
      "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0620) | Acc: (98.16%) (34049/34688)\n",
      "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0622) | Acc: (98.15%) (35301/35968)\n",
      "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0621) | Acc: (98.14%) (36554/37248)\n",
      "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0620) | Acc: (98.15%) (37814/38528)\n",
      "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0617) | Acc: (98.18%) (39082/39808)\n",
      "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0617) | Acc: (98.16%) (40331/41088)\n",
      "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0616) | Acc: (98.17%) (41592/42368)\n",
      "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0617) | Acc: (98.17%) (42851/43648)\n",
      "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0616) | Acc: (98.18%) (44109/44928)\n",
      "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0615) | Acc: (98.19%) (45373/46208)\n",
      "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0615) | Acc: (98.20%) (46632/47488)\n",
      "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0614) | Acc: (98.21%) (47896/48768)\n",
      "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0614) | Acc: (98.22%) (49109/50000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3853) | Acc: (89.23%) (8923/10000)\n",
      "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0949) | Acc: (96.09%) (123/128)\n",
      "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0581) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0630) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0628) | Acc: (98.19%) (3896/3968)\n",
      "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0647) | Acc: (98.06%) (5146/5248)\n",
      "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0649) | Acc: (98.09%) (6403/6528)\n",
      "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0634) | Acc: (98.18%) (7666/7808)\n",
      "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0621) | Acc: (98.21%) (8925/9088)\n",
      "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0625) | Acc: (98.17%) (10178/10368)\n",
      "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0618) | Acc: (98.21%) (11439/11648)\n",
      "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0610) | Acc: (98.28%) (12706/12928)\n",
      "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0612) | Acc: (98.26%) (13961/14208)\n",
      "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0628) | Acc: (98.18%) (15206/15488)\n",
      "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0626) | Acc: (98.17%) (16461/16768)\n",
      "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0621) | Acc: (98.19%) (17722/18048)\n",
      "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0619) | Acc: (98.20%) (18980/19328)\n",
      "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0624) | Acc: (98.16%) (20228/20608)\n",
      "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0622) | Acc: (98.15%) (21484/21888)\n",
      "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0615) | Acc: (98.20%) (22750/23168)\n",
      "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0620) | Acc: (98.20%) (24008/24448)\n",
      "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0624) | Acc: (98.19%) (25263/25728)\n",
      "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0619) | Acc: (98.22%) (26527/27008)\n",
      "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0623) | Acc: (98.21%) (27781/28288)\n",
      "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0622) | Acc: (98.23%) (29044/29568)\n",
      "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0622) | Acc: (98.22%) (30299/30848)\n",
      "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0616) | Acc: (98.24%) (31564/32128)\n",
      "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0615) | Acc: (98.24%) (32820/33408)\n",
      "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0616) | Acc: (98.23%) (34075/34688)\n",
      "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0616) | Acc: (98.22%) (35328/35968)\n",
      "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0620) | Acc: (98.21%) (36581/37248)\n",
      "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0620) | Acc: (98.21%) (37838/38528)\n",
      "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0616) | Acc: (98.24%) (39106/39808)\n",
      "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0613) | Acc: (98.25%) (40369/41088)\n",
      "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0615) | Acc: (98.22%) (41615/42368)\n",
      "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0615) | Acc: (98.22%) (42870/43648)\n",
      "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0615) | Acc: (98.22%) (44128/44928)\n",
      "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0614) | Acc: (98.22%) (45387/46208)\n",
      "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0614) | Acc: (98.23%) (46647/47488)\n",
      "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0616) | Acc: (98.22%) (47900/48768)\n",
      "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0617) | Acc: (98.22%) (49109/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3887) | Acc: (89.09%) (8909/10000)\n",
      "Epoch: 112 | Batch_idx: 0 |  Loss: (0.0668) | Acc: (98.44%) (126/128)\n",
      "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0639) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0661) | Acc: (98.10%) (2637/2688)\n",
      "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0657) | Acc: (98.16%) (3895/3968)\n",
      "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0626) | Acc: (98.23%) (5155/5248)\n",
      "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0624) | Acc: (98.25%) (6414/6528)\n",
      "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0614) | Acc: (98.30%) (7675/7808)\n",
      "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0619) | Acc: (98.22%) (8926/9088)\n",
      "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0636) | Acc: (98.16%) (10177/10368)\n",
      "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0635) | Acc: (98.12%) (11429/11648)\n",
      "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0630) | Acc: (98.14%) (12688/12928)\n",
      "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0629) | Acc: (98.16%) (13946/14208)\n",
      "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0636) | Acc: (98.14%) (15200/15488)\n",
      "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0637) | Acc: (98.13%) (16455/16768)\n",
      "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0627) | Acc: (98.16%) (17716/18048)\n",
      "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0629) | Acc: (98.13%) (18967/19328)\n",
      "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0628) | Acc: (98.16%) (20229/20608)\n",
      "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0627) | Acc: (98.15%) (21483/21888)\n",
      "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0623) | Acc: (98.17%) (22743/23168)\n",
      "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0622) | Acc: (98.17%) (24001/24448)\n",
      "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0617) | Acc: (98.21%) (25268/25728)\n",
      "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0618) | Acc: (98.20%) (26521/27008)\n",
      "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0613) | Acc: (98.22%) (27785/28288)\n",
      "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0615) | Acc: (98.21%) (29040/29568)\n",
      "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0615) | Acc: (98.21%) (30297/30848)\n",
      "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0614) | Acc: (98.21%) (31554/32128)\n",
      "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0615) | Acc: (98.22%) (32814/33408)\n",
      "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0616) | Acc: (98.22%) (34070/34688)\n",
      "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0617) | Acc: (98.22%) (35327/35968)\n",
      "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0614) | Acc: (98.23%) (36588/37248)\n",
      "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0620) | Acc: (98.22%) (37841/38528)\n",
      "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0618) | Acc: (98.23%) (39102/39808)\n",
      "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0620) | Acc: (98.22%) (40357/41088)\n",
      "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0623) | Acc: (98.21%) (41610/42368)\n",
      "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0623) | Acc: (98.21%) (42865/43648)\n",
      "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0622) | Acc: (98.20%) (44120/44928)\n",
      "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0623) | Acc: (98.20%) (45378/46208)\n",
      "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0622) | Acc: (98.21%) (46637/47488)\n",
      "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0624) | Acc: (98.21%) (47893/48768)\n",
      "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0621) | Acc: (98.22%) (49109/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3863) | Acc: (89.26%) (8926/10000)\n",
      "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0844) | Acc: (97.66%) (125/128)\n",
      "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0577) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0569) | Acc: (98.25%) (2641/2688)\n",
      "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0594) | Acc: (98.21%) (3897/3968)\n",
      "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0592) | Acc: (98.29%) (5158/5248)\n",
      "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0621) | Acc: (98.21%) (6411/6528)\n",
      "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0628) | Acc: (98.18%) (7666/7808)\n",
      "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0620) | Acc: (98.17%) (8922/9088)\n",
      "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0609) | Acc: (98.23%) (10185/10368)\n",
      "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0606) | Acc: (98.27%) (11446/11648)\n",
      "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0608) | Acc: (98.28%) (12705/12928)\n",
      "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0608) | Acc: (98.28%) (13963/14208)\n",
      "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0615) | Acc: (98.24%) (15216/15488)\n",
      "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0610) | Acc: (98.25%) (16474/16768)\n",
      "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0611) | Acc: (98.23%) (17729/18048)\n",
      "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0620) | Acc: (98.20%) (18981/19328)\n",
      "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0618) | Acc: (98.19%) (20235/20608)\n",
      "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0614) | Acc: (98.20%) (21493/21888)\n",
      "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0620) | Acc: (98.16%) (22741/23168)\n",
      "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0620) | Acc: (98.18%) (24002/24448)\n",
      "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0617) | Acc: (98.19%) (25263/25728)\n",
      "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0620) | Acc: (98.17%) (26513/27008)\n",
      "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0626) | Acc: (98.14%) (27762/28288)\n",
      "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0622) | Acc: (98.14%) (29019/29568)\n",
      "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0620) | Acc: (98.15%) (30276/30848)\n",
      "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0625) | Acc: (98.14%) (31531/32128)\n",
      "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0625) | Acc: (98.14%) (32787/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0627) | Acc: (98.14%) (34043/34688)\n",
      "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0625) | Acc: (98.15%) (35301/35968)\n",
      "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0624) | Acc: (98.15%) (36560/37248)\n",
      "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0627) | Acc: (98.13%) (37806/38528)\n",
      "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0626) | Acc: (98.14%) (39069/39808)\n",
      "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0624) | Acc: (98.16%) (40330/41088)\n",
      "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0624) | Acc: (98.15%) (41585/42368)\n",
      "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0624) | Acc: (98.15%) (42840/43648)\n",
      "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0626) | Acc: (98.14%) (44094/44928)\n",
      "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0626) | Acc: (98.14%) (45350/46208)\n",
      "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0626) | Acc: (98.15%) (46611/47488)\n",
      "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0626) | Acc: (98.16%) (47870/48768)\n",
      "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0626) | Acc: (98.15%) (49075/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3858) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0458) | Acc: (98.44%) (126/128)\n",
      "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0604) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0611) | Acc: (98.18%) (2639/2688)\n",
      "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0586) | Acc: (98.29%) (3900/3968)\n",
      "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0569) | Acc: (98.30%) (5159/5248)\n",
      "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0585) | Acc: (98.31%) (6418/6528)\n",
      "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0579) | Acc: (98.37%) (7681/7808)\n",
      "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0593) | Acc: (98.29%) (8933/9088)\n",
      "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0602) | Acc: (98.28%) (10190/10368)\n",
      "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0602) | Acc: (98.30%) (11450/11648)\n",
      "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0600) | Acc: (98.28%) (12706/12928)\n",
      "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0600) | Acc: (98.27%) (13962/14208)\n",
      "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0611) | Acc: (98.18%) (15206/15488)\n",
      "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0616) | Acc: (98.13%) (16455/16768)\n",
      "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0619) | Acc: (98.14%) (17713/18048)\n",
      "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0621) | Acc: (98.11%) (18962/19328)\n",
      "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0615) | Acc: (98.15%) (20226/20608)\n",
      "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0611) | Acc: (98.18%) (21489/21888)\n",
      "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0605) | Acc: (98.20%) (22752/23168)\n",
      "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0605) | Acc: (98.22%) (24014/24448)\n",
      "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0603) | Acc: (98.24%) (25276/25728)\n",
      "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0606) | Acc: (98.22%) (26526/27008)\n",
      "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0606) | Acc: (98.19%) (27777/28288)\n",
      "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0607) | Acc: (98.19%) (29034/29568)\n",
      "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0610) | Acc: (98.18%) (30286/30848)\n",
      "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0609) | Acc: (98.17%) (31539/32128)\n",
      "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0610) | Acc: (98.15%) (32791/33408)\n",
      "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0607) | Acc: (98.16%) (34051/34688)\n",
      "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0605) | Acc: (98.18%) (35314/35968)\n",
      "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0605) | Acc: (98.19%) (36573/37248)\n",
      "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0605) | Acc: (98.19%) (37832/38528)\n",
      "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0606) | Acc: (98.19%) (39087/39808)\n",
      "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0607) | Acc: (98.18%) (40339/41088)\n",
      "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0608) | Acc: (98.17%) (41593/42368)\n",
      "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0609) | Acc: (98.17%) (42848/43648)\n",
      "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0613) | Acc: (98.15%) (44098/44928)\n",
      "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0615) | Acc: (98.15%) (45355/46208)\n",
      "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0613) | Acc: (98.16%) (46615/47488)\n",
      "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0611) | Acc: (98.17%) (47877/48768)\n",
      "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0609) | Acc: (98.18%) (49090/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3852) | Acc: (89.19%) (8919/10000)\n",
      "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0380) | Acc: (99.22%) (127/128)\n",
      "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0529) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0537) | Acc: (98.62%) (2651/2688)\n",
      "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0549) | Acc: (98.59%) (3912/3968)\n",
      "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0556) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0555) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0549) | Acc: (98.54%) (7694/7808)\n",
      "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0572) | Acc: (98.45%) (8947/9088)\n",
      "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0576) | Acc: (98.46%) (10208/10368)\n",
      "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0584) | Acc: (98.45%) (11467/11648)\n",
      "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0592) | Acc: (98.43%) (12725/12928)\n",
      "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0599) | Acc: (98.37%) (13977/14208)\n",
      "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0601) | Acc: (98.39%) (15238/15488)\n",
      "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0607) | Acc: (98.37%) (16494/16768)\n",
      "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0606) | Acc: (98.35%) (17751/18048)\n",
      "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0602) | Acc: (98.37%) (19013/19328)\n",
      "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0600) | Acc: (98.37%) (20272/20608)\n",
      "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0601) | Acc: (98.36%) (21530/21888)\n",
      "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0594) | Acc: (98.41%) (22799/23168)\n",
      "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0596) | Acc: (98.38%) (24051/24448)\n",
      "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0596) | Acc: (98.38%) (25311/25728)\n",
      "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0593) | Acc: (98.40%) (26577/27008)\n",
      "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0592) | Acc: (98.42%) (27840/28288)\n",
      "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0590) | Acc: (98.41%) (29097/29568)\n",
      "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0595) | Acc: (98.38%) (30347/30848)\n",
      "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0594) | Acc: (98.36%) (31602/32128)\n",
      "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0590) | Acc: (98.39%) (32869/33408)\n",
      "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0591) | Acc: (98.39%) (34128/34688)\n",
      "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0594) | Acc: (98.38%) (35384/35968)\n",
      "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0594) | Acc: (98.37%) (36640/37248)\n",
      "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0593) | Acc: (98.37%) (37901/38528)\n",
      "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0593) | Acc: (98.37%) (39158/39808)\n",
      "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0590) | Acc: (98.37%) (40418/41088)\n",
      "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0589) | Acc: (98.37%) (41678/42368)\n",
      "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0588) | Acc: (98.39%) (42944/43648)\n",
      "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0588) | Acc: (98.39%) (44204/44928)\n",
      "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0590) | Acc: (98.39%) (45464/46208)\n",
      "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0592) | Acc: (98.38%) (46719/47488)\n",
      "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0594) | Acc: (98.36%) (47968/48768)\n",
      "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0595) | Acc: (98.35%) (49176/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3922) | Acc: (89.01%) (8901/10000)\n",
      "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0470) | Acc: (98.44%) (126/128)\n",
      "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0553) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0563) | Acc: (98.44%) (2646/2688)\n",
      "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0556) | Acc: (98.59%) (3912/3968)\n",
      "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0577) | Acc: (98.34%) (5161/5248)\n",
      "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0580) | Acc: (98.39%) (6423/6528)\n",
      "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0589) | Acc: (98.36%) (7680/7808)\n",
      "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0595) | Acc: (98.32%) (8935/9088)\n",
      "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0586) | Acc: (98.31%) (10193/10368)\n",
      "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0581) | Acc: (98.34%) (11455/11648)\n",
      "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0583) | Acc: (98.36%) (12716/12928)\n",
      "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0578) | Acc: (98.37%) (13977/14208)\n",
      "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0580) | Acc: (98.38%) (15237/15488)\n",
      "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0576) | Acc: (98.40%) (16500/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0582) | Acc: (98.35%) (17751/18048)\n",
      "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0583) | Acc: (98.35%) (19009/19328)\n",
      "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0577) | Acc: (98.37%) (20272/20608)\n",
      "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0580) | Acc: (98.35%) (21527/21888)\n",
      "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0585) | Acc: (98.31%) (22776/23168)\n",
      "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0585) | Acc: (98.31%) (24034/24448)\n",
      "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0581) | Acc: (98.34%) (25301/25728)\n",
      "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0584) | Acc: (98.34%) (26560/27008)\n",
      "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0584) | Acc: (98.34%) (27818/28288)\n",
      "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0588) | Acc: (98.34%) (29076/29568)\n",
      "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0590) | Acc: (98.31%) (30328/30848)\n",
      "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0590) | Acc: (98.30%) (31583/32128)\n",
      "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0592) | Acc: (98.30%) (32839/33408)\n",
      "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0596) | Acc: (98.28%) (34093/34688)\n",
      "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0596) | Acc: (98.29%) (35354/35968)\n",
      "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0595) | Acc: (98.28%) (36609/37248)\n",
      "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0597) | Acc: (98.28%) (37864/38528)\n",
      "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0595) | Acc: (98.27%) (39120/39808)\n",
      "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0599) | Acc: (98.25%) (40368/41088)\n",
      "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0600) | Acc: (98.24%) (41622/42368)\n",
      "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0601) | Acc: (98.23%) (42875/43648)\n",
      "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0601) | Acc: (98.22%) (44130/44928)\n",
      "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0598) | Acc: (98.24%) (45393/46208)\n",
      "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0597) | Acc: (98.24%) (46654/47488)\n",
      "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0596) | Acc: (98.25%) (47914/48768)\n",
      "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0597) | Acc: (98.24%) (49122/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3883) | Acc: (89.17%) (8917/10000)\n",
      "Epoch: 117 | Batch_idx: 0 |  Loss: (0.1246) | Acc: (96.09%) (123/128)\n",
      "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0719) | Acc: (97.44%) (1372/1408)\n",
      "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0677) | Acc: (97.92%) (2632/2688)\n",
      "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0631) | Acc: (98.19%) (3896/3968)\n",
      "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0594) | Acc: (98.36%) (5162/5248)\n",
      "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0584) | Acc: (98.38%) (6422/6528)\n",
      "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0589) | Acc: (98.39%) (7682/7808)\n",
      "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0595) | Acc: (98.37%) (8940/9088)\n",
      "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0589) | Acc: (98.42%) (10204/10368)\n",
      "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0591) | Acc: (98.37%) (11458/11648)\n",
      "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0594) | Acc: (98.32%) (12711/12928)\n",
      "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0592) | Acc: (98.30%) (13966/14208)\n",
      "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0595) | Acc: (98.30%) (15224/15488)\n",
      "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0608) | Acc: (98.25%) (16474/16768)\n",
      "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0610) | Acc: (98.20%) (17724/18048)\n",
      "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0619) | Acc: (98.17%) (18974/19328)\n",
      "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0620) | Acc: (98.17%) (20230/20608)\n",
      "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0625) | Acc: (98.14%) (21480/21888)\n",
      "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0621) | Acc: (98.15%) (22740/23168)\n",
      "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0617) | Acc: (98.18%) (24004/24448)\n",
      "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0617) | Acc: (98.17%) (25258/25728)\n",
      "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0618) | Acc: (98.17%) (26514/27008)\n",
      "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0621) | Acc: (98.15%) (27765/28288)\n",
      "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0622) | Acc: (98.14%) (29019/29568)\n",
      "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0619) | Acc: (98.17%) (30285/30848)\n",
      "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0616) | Acc: (98.20%) (31549/32128)\n",
      "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0618) | Acc: (98.18%) (32800/33408)\n",
      "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0619) | Acc: (98.16%) (34049/34688)\n",
      "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0619) | Acc: (98.17%) (35309/35968)\n",
      "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0617) | Acc: (98.18%) (36571/37248)\n",
      "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0613) | Acc: (98.20%) (37836/38528)\n",
      "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0612) | Acc: (98.21%) (39097/39808)\n",
      "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0611) | Acc: (98.21%) (40354/41088)\n",
      "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0613) | Acc: (98.20%) (41605/42368)\n",
      "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0613) | Acc: (98.20%) (42861/43648)\n",
      "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0611) | Acc: (98.21%) (44123/44928)\n",
      "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0611) | Acc: (98.21%) (45383/46208)\n",
      "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0609) | Acc: (98.22%) (46641/47488)\n",
      "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0608) | Acc: (98.23%) (47904/48768)\n",
      "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0608) | Acc: (98.22%) (49111/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3890) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0493) | Acc: (98.44%) (126/128)\n",
      "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0539) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0567) | Acc: (98.18%) (2639/2688)\n",
      "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0590) | Acc: (98.06%) (3891/3968)\n",
      "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0587) | Acc: (98.19%) (5153/5248)\n",
      "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0577) | Acc: (98.27%) (6415/6528)\n",
      "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0572) | Acc: (98.30%) (7675/7808)\n",
      "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0555) | Acc: (98.37%) (8940/9088)\n",
      "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0555) | Acc: (98.36%) (10198/10368)\n",
      "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0556) | Acc: (98.35%) (11456/11648)\n",
      "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0560) | Acc: (98.36%) (12716/12928)\n",
      "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0556) | Acc: (98.42%) (13984/14208)\n",
      "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0571) | Acc: (98.37%) (15235/15488)\n",
      "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0574) | Acc: (98.35%) (16491/16768)\n",
      "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0577) | Acc: (98.33%) (17746/18048)\n",
      "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0576) | Acc: (98.32%) (19004/19328)\n",
      "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0577) | Acc: (98.31%) (20259/20608)\n",
      "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0577) | Acc: (98.30%) (21516/21888)\n",
      "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0578) | Acc: (98.29%) (22772/23168)\n",
      "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0571) | Acc: (98.31%) (24036/24448)\n",
      "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0565) | Acc: (98.34%) (25300/25728)\n",
      "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0566) | Acc: (98.35%) (26563/27008)\n",
      "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0564) | Acc: (98.36%) (27825/28288)\n",
      "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0564) | Acc: (98.35%) (29080/29568)\n",
      "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0563) | Acc: (98.33%) (30334/30848)\n",
      "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0566) | Acc: (98.33%) (31591/32128)\n",
      "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0569) | Acc: (98.31%) (32842/33408)\n",
      "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0573) | Acc: (98.28%) (34093/34688)\n",
      "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0577) | Acc: (98.28%) (35349/35968)\n",
      "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0581) | Acc: (98.25%) (36597/37248)\n",
      "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0577) | Acc: (98.28%) (37864/38528)\n",
      "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0576) | Acc: (98.29%) (39127/39808)\n",
      "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0579) | Acc: (98.28%) (40382/41088)\n",
      "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0580) | Acc: (98.28%) (41638/42368)\n",
      "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0579) | Acc: (98.29%) (42901/43648)\n",
      "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0579) | Acc: (98.30%) (44162/44928)\n",
      "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0581) | Acc: (98.29%) (45420/46208)\n",
      "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0584) | Acc: (98.28%) (46670/47488)\n",
      "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0582) | Acc: (98.29%) (47936/48768)\n",
      "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0581) | Acc: (98.29%) (49145/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3930) | Acc: (89.07%) (8907/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0889) | Acc: (98.44%) (126/128)\n",
      "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0579) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0615) | Acc: (98.14%) (2638/2688)\n",
      "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0620) | Acc: (98.14%) (3894/3968)\n",
      "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0628) | Acc: (98.02%) (5144/5248)\n",
      "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0619) | Acc: (98.12%) (6405/6528)\n",
      "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0598) | Acc: (98.25%) (7671/7808)\n",
      "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0603) | Acc: (98.21%) (8925/9088)\n",
      "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0597) | Acc: (98.22%) (10183/10368)\n",
      "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0593) | Acc: (98.23%) (11442/11648)\n",
      "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0596) | Acc: (98.24%) (12701/12928)\n",
      "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0597) | Acc: (98.25%) (13959/14208)\n",
      "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0607) | Acc: (98.19%) (15208/15488)\n",
      "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0605) | Acc: (98.25%) (16474/16768)\n",
      "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0598) | Acc: (98.29%) (17739/18048)\n",
      "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0595) | Acc: (98.30%) (19000/19328)\n",
      "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0595) | Acc: (98.31%) (20259/20608)\n",
      "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0589) | Acc: (98.33%) (21522/21888)\n",
      "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0591) | Acc: (98.32%) (22779/23168)\n",
      "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0594) | Acc: (98.31%) (24036/24448)\n",
      "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0594) | Acc: (98.30%) (25291/25728)\n",
      "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0600) | Acc: (98.26%) (26539/27008)\n",
      "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0593) | Acc: (98.29%) (27803/28288)\n",
      "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0593) | Acc: (98.28%) (29059/29568)\n",
      "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0593) | Acc: (98.27%) (30315/30848)\n",
      "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0591) | Acc: (98.29%) (31580/32128)\n",
      "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0600) | Acc: (98.25%) (32825/33408)\n",
      "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0599) | Acc: (98.26%) (34085/34688)\n",
      "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0597) | Acc: (98.26%) (35342/35968)\n",
      "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0597) | Acc: (98.27%) (36602/37248)\n",
      "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0594) | Acc: (98.27%) (37863/38528)\n",
      "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0591) | Acc: (98.30%) (39130/39808)\n",
      "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0591) | Acc: (98.29%) (40385/41088)\n",
      "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0593) | Acc: (98.28%) (41640/42368)\n",
      "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0594) | Acc: (98.27%) (42894/43648)\n",
      "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0591) | Acc: (98.28%) (44155/44928)\n",
      "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0593) | Acc: (98.27%) (45409/46208)\n",
      "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0594) | Acc: (98.27%) (46665/47488)\n",
      "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0594) | Acc: (98.27%) (47923/48768)\n",
      "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0593) | Acc: (98.27%) (49133/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3907) | Acc: (89.19%) (8919/10000)\n",
      "Epoch: 120 | Batch_idx: 0 |  Loss: (0.1049) | Acc: (96.09%) (123/128)\n",
      "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0572) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0529) | Acc: (98.59%) (2650/2688)\n",
      "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0551) | Acc: (98.54%) (3910/3968)\n",
      "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0553) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0559) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0537) | Acc: (98.48%) (7689/7808)\n",
      "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0529) | Acc: (98.54%) (8955/9088)\n",
      "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0539) | Acc: (98.50%) (10212/10368)\n",
      "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0550) | Acc: (98.45%) (11467/11648)\n",
      "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0548) | Acc: (98.49%) (12733/12928)\n",
      "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0549) | Acc: (98.52%) (13998/14208)\n",
      "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0556) | Acc: (98.51%) (15257/15488)\n",
      "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0562) | Acc: (98.48%) (16513/16768)\n",
      "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0561) | Acc: (98.48%) (17774/18048)\n",
      "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0566) | Acc: (98.44%) (19027/19328)\n",
      "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0577) | Acc: (98.38%) (20275/20608)\n",
      "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0570) | Acc: (98.42%) (21542/21888)\n",
      "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0565) | Acc: (98.42%) (22802/23168)\n",
      "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0560) | Acc: (98.45%) (24068/24448)\n",
      "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0557) | Acc: (98.46%) (25333/25728)\n",
      "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0554) | Acc: (98.48%) (26597/27008)\n",
      "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0557) | Acc: (98.47%) (27856/28288)\n",
      "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0556) | Acc: (98.48%) (29119/29568)\n",
      "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0554) | Acc: (98.48%) (30380/30848)\n",
      "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0555) | Acc: (98.48%) (31639/32128)\n",
      "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0557) | Acc: (98.47%) (32896/33408)\n",
      "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0556) | Acc: (98.48%) (34162/34688)\n",
      "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0558) | Acc: (98.48%) (35422/35968)\n",
      "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0557) | Acc: (98.48%) (36680/37248)\n",
      "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0557) | Acc: (98.49%) (37947/38528)\n",
      "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0560) | Acc: (98.49%) (39206/39808)\n",
      "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0557) | Acc: (98.50%) (40471/41088)\n",
      "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0560) | Acc: (98.48%) (41724/42368)\n",
      "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0558) | Acc: (98.48%) (42986/43648)\n",
      "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0559) | Acc: (98.49%) (44248/44928)\n",
      "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0562) | Acc: (98.47%) (45501/46208)\n",
      "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0559) | Acc: (98.48%) (46765/47488)\n",
      "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0562) | Acc: (98.47%) (48023/48768)\n",
      "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0559) | Acc: (98.48%) (49240/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3857) | Acc: (89.24%) (8924/10000)\n",
      "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0447) | Acc: (98.44%) (126/128)\n",
      "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0616) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0645) | Acc: (98.10%) (2637/2688)\n",
      "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0610) | Acc: (98.26%) (3899/3968)\n",
      "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0594) | Acc: (98.21%) (5154/5248)\n",
      "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0600) | Acc: (98.19%) (6410/6528)\n",
      "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0587) | Acc: (98.31%) (7676/7808)\n",
      "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0594) | Acc: (98.33%) (8936/9088)\n",
      "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0594) | Acc: (98.30%) (10192/10368)\n",
      "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0605) | Acc: (98.25%) (11444/11648)\n",
      "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0605) | Acc: (98.20%) (12695/12928)\n",
      "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0598) | Acc: (98.20%) (13952/14208)\n",
      "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0595) | Acc: (98.22%) (15212/15488)\n",
      "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0597) | Acc: (98.19%) (16464/16768)\n",
      "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0599) | Acc: (98.17%) (17717/18048)\n",
      "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0592) | Acc: (98.20%) (18981/19328)\n",
      "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0585) | Acc: (98.25%) (20247/20608)\n",
      "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0579) | Acc: (98.26%) (21507/21888)\n",
      "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0574) | Acc: (98.30%) (22774/23168)\n",
      "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0577) | Acc: (98.28%) (24028/24448)\n",
      "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0574) | Acc: (98.29%) (25289/25728)\n",
      "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0579) | Acc: (98.27%) (26541/27008)\n",
      "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0578) | Acc: (98.29%) (27804/28288)\n",
      "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0580) | Acc: (98.28%) (29058/29568)\n",
      "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0583) | Acc: (98.27%) (30313/30848)\n",
      "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0584) | Acc: (98.27%) (31571/32128)\n",
      "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0578) | Acc: (98.30%) (32841/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0580) | Acc: (98.30%) (34097/34688)\n",
      "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0580) | Acc: (98.30%) (35357/35968)\n",
      "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0577) | Acc: (98.30%) (36614/37248)\n",
      "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0572) | Acc: (98.32%) (37881/38528)\n",
      "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0573) | Acc: (98.31%) (39136/39808)\n",
      "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0571) | Acc: (98.32%) (40399/41088)\n",
      "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0571) | Acc: (98.33%) (41660/42368)\n",
      "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0569) | Acc: (98.33%) (42919/43648)\n",
      "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0571) | Acc: (98.33%) (44176/44928)\n",
      "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0569) | Acc: (98.33%) (45438/46208)\n",
      "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0569) | Acc: (98.32%) (46692/47488)\n",
      "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0567) | Acc: (98.34%) (47957/48768)\n",
      "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0564) | Acc: (98.36%) (49180/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3876) | Acc: (89.31%) (8931/10000)\n",
      "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0369) | Acc: (100.00%) (128/128)\n",
      "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0607) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0599) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0583) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0568) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0547) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0540) | Acc: (98.51%) (7692/7808)\n",
      "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0542) | Acc: (98.54%) (8955/9088)\n",
      "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0547) | Acc: (98.50%) (10212/10368)\n",
      "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0541) | Acc: (98.55%) (11479/11648)\n",
      "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0541) | Acc: (98.56%) (12742/12928)\n",
      "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0543) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0544) | Acc: (98.53%) (15260/15488)\n",
      "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0542) | Acc: (98.57%) (16528/16768)\n",
      "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0543) | Acc: (98.55%) (17786/18048)\n",
      "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0548) | Acc: (98.52%) (19041/19328)\n",
      "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0547) | Acc: (98.52%) (20304/20608)\n",
      "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0552) | Acc: (98.47%) (21554/21888)\n",
      "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0556) | Acc: (98.45%) (22808/23168)\n",
      "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0558) | Acc: (98.44%) (24066/24448)\n",
      "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0559) | Acc: (98.44%) (25327/25728)\n",
      "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0564) | Acc: (98.42%) (26581/27008)\n",
      "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0562) | Acc: (98.43%) (27844/28288)\n",
      "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0561) | Acc: (98.43%) (29103/29568)\n",
      "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0559) | Acc: (98.44%) (30366/30848)\n",
      "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0562) | Acc: (98.42%) (31620/32128)\n",
      "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0561) | Acc: (98.43%) (32884/33408)\n",
      "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0561) | Acc: (98.44%) (34146/34688)\n",
      "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0562) | Acc: (98.42%) (35401/35968)\n",
      "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0561) | Acc: (98.43%) (36662/37248)\n",
      "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0561) | Acc: (98.43%) (37922/38528)\n",
      "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0561) | Acc: (98.43%) (39185/39808)\n",
      "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0559) | Acc: (98.44%) (40446/41088)\n",
      "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0562) | Acc: (98.42%) (41699/42368)\n",
      "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0559) | Acc: (98.44%) (42967/43648)\n",
      "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0559) | Acc: (98.44%) (44225/44928)\n",
      "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0557) | Acc: (98.45%) (45491/46208)\n",
      "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0555) | Acc: (98.45%) (46753/47488)\n",
      "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0558) | Acc: (98.43%) (48003/48768)\n",
      "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0561) | Acc: (98.42%) (49208/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3861) | Acc: (89.29%) (8929/10000)\n",
      "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0437) | Acc: (98.44%) (126/128)\n",
      "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0497) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0519) | Acc: (98.70%) (2653/2688)\n",
      "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0529) | Acc: (98.69%) (3916/3968)\n",
      "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0526) | Acc: (98.65%) (5177/5248)\n",
      "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0528) | Acc: (98.59%) (6436/6528)\n",
      "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0510) | Acc: (98.64%) (7702/7808)\n",
      "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0535) | Acc: (98.51%) (8953/9088)\n",
      "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0538) | Acc: (98.51%) (10214/10368)\n",
      "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0541) | Acc: (98.51%) (11475/11648)\n",
      "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0545) | Acc: (98.48%) (12731/12928)\n",
      "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0538) | Acc: (98.51%) (13996/14208)\n",
      "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0541) | Acc: (98.51%) (15258/15488)\n",
      "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0537) | Acc: (98.54%) (16523/16768)\n",
      "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0542) | Acc: (98.49%) (17776/18048)\n",
      "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0537) | Acc: (98.53%) (19043/19328)\n",
      "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0532) | Acc: (98.54%) (20308/20608)\n",
      "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0530) | Acc: (98.55%) (21571/21888)\n",
      "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0531) | Acc: (98.56%) (22834/23168)\n",
      "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0533) | Acc: (98.56%) (24095/24448)\n",
      "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0533) | Acc: (98.56%) (25357/25728)\n",
      "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0534) | Acc: (98.55%) (26617/27008)\n",
      "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0534) | Acc: (98.56%) (27880/28288)\n",
      "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0534) | Acc: (98.56%) (29142/29568)\n",
      "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0532) | Acc: (98.55%) (30402/30848)\n",
      "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0530) | Acc: (98.56%) (31664/32128)\n",
      "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0533) | Acc: (98.55%) (32925/33408)\n",
      "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0535) | Acc: (98.54%) (34181/34688)\n",
      "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0541) | Acc: (98.50%) (35429/35968)\n",
      "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0544) | Acc: (98.49%) (36686/37248)\n",
      "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0547) | Acc: (98.49%) (37945/38528)\n",
      "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0547) | Acc: (98.49%) (39208/39808)\n",
      "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0550) | Acc: (98.49%) (40468/41088)\n",
      "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0553) | Acc: (98.47%) (41721/42368)\n",
      "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0553) | Acc: (98.47%) (42979/43648)\n",
      "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0551) | Acc: (98.47%) (44241/44928)\n",
      "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0548) | Acc: (98.49%) (45510/46208)\n",
      "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0548) | Acc: (98.50%) (46775/47488)\n",
      "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0549) | Acc: (98.49%) (48030/48768)\n",
      "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0549) | Acc: (98.48%) (49239/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3875) | Acc: (89.20%) (8920/10000)\n",
      "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0406) | Acc: (98.44%) (126/128)\n",
      "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0610) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0625) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0632) | Acc: (98.03%) (3890/3968)\n",
      "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0623) | Acc: (98.09%) (5148/5248)\n",
      "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0618) | Acc: (98.07%) (6402/6528)\n",
      "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0622) | Acc: (98.10%) (7660/7808)\n",
      "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0617) | Acc: (98.18%) (8923/9088)\n",
      "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0599) | Acc: (98.28%) (10190/10368)\n",
      "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0588) | Acc: (98.35%) (11456/11648)\n",
      "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0593) | Acc: (98.34%) (12713/12928)\n",
      "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0589) | Acc: (98.37%) (13976/14208)\n",
      "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0579) | Acc: (98.42%) (15244/15488)\n",
      "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0582) | Acc: (98.40%) (16500/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0577) | Acc: (98.42%) (17762/18048)\n",
      "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0572) | Acc: (98.44%) (19027/19328)\n",
      "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0566) | Acc: (98.45%) (20289/20608)\n",
      "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0559) | Acc: (98.50%) (21560/21888)\n",
      "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0565) | Acc: (98.47%) (22813/23168)\n",
      "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0562) | Acc: (98.47%) (24074/24448)\n",
      "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0560) | Acc: (98.48%) (25337/25728)\n",
      "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0558) | Acc: (98.47%) (26596/27008)\n",
      "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0558) | Acc: (98.47%) (27856/28288)\n",
      "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0558) | Acc: (98.46%) (29114/29568)\n",
      "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0556) | Acc: (98.48%) (30379/30848)\n",
      "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0558) | Acc: (98.47%) (31636/32128)\n",
      "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0558) | Acc: (98.46%) (32895/33408)\n",
      "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0557) | Acc: (98.47%) (34156/34688)\n",
      "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0554) | Acc: (98.48%) (35422/35968)\n",
      "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0553) | Acc: (98.49%) (36685/37248)\n",
      "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0557) | Acc: (98.47%) (37939/38528)\n",
      "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0556) | Acc: (98.48%) (39202/39808)\n",
      "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0558) | Acc: (98.46%) (40455/41088)\n",
      "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0558) | Acc: (98.45%) (41712/42368)\n",
      "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0553) | Acc: (98.48%) (42984/43648)\n",
      "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0552) | Acc: (98.49%) (44248/44928)\n",
      "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0552) | Acc: (98.49%) (45509/46208)\n",
      "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0552) | Acc: (98.48%) (46768/47488)\n",
      "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0550) | Acc: (98.49%) (48030/48768)\n",
      "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0551) | Acc: (98.49%) (49243/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3847) | Acc: (89.28%) (8928/10000)\n",
      "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0248) | Acc: (100.00%) (128/128)\n",
      "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0603) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0539) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0568) | Acc: (98.21%) (3897/3968)\n",
      "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0566) | Acc: (98.25%) (5156/5248)\n",
      "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0575) | Acc: (98.25%) (6414/6528)\n",
      "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0577) | Acc: (98.21%) (7668/7808)\n",
      "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0560) | Acc: (98.33%) (8936/9088)\n",
      "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0560) | Acc: (98.36%) (10198/10368)\n",
      "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0573) | Acc: (98.31%) (11451/11648)\n",
      "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0572) | Acc: (98.34%) (12713/12928)\n",
      "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0556) | Acc: (98.41%) (13982/14208)\n",
      "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0550) | Acc: (98.43%) (15245/15488)\n",
      "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0552) | Acc: (98.43%) (16504/16768)\n",
      "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0550) | Acc: (98.43%) (17764/18048)\n",
      "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0554) | Acc: (98.40%) (19019/19328)\n",
      "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0559) | Acc: (98.39%) (20277/20608)\n",
      "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0560) | Acc: (98.40%) (21537/21888)\n",
      "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0556) | Acc: (98.41%) (22800/23168)\n",
      "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0556) | Acc: (98.42%) (24061/24448)\n",
      "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0559) | Acc: (98.40%) (25316/25728)\n",
      "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0553) | Acc: (98.42%) (26581/27008)\n",
      "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0552) | Acc: (98.42%) (27841/28288)\n",
      "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0558) | Acc: (98.40%) (29094/29568)\n",
      "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0559) | Acc: (98.40%) (30354/30848)\n",
      "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0554) | Acc: (98.42%) (31621/32128)\n",
      "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0555) | Acc: (98.43%) (32884/33408)\n",
      "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0559) | Acc: (98.40%) (34132/34688)\n",
      "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0561) | Acc: (98.40%) (35391/35968)\n",
      "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0563) | Acc: (98.38%) (36644/37248)\n",
      "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0563) | Acc: (98.38%) (37904/38528)\n",
      "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0560) | Acc: (98.39%) (39167/39808)\n",
      "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0558) | Acc: (98.39%) (40428/41088)\n",
      "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0558) | Acc: (98.39%) (41686/42368)\n",
      "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0558) | Acc: (98.38%) (42942/43648)\n",
      "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0558) | Acc: (98.40%) (44209/44928)\n",
      "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0558) | Acc: (98.41%) (45474/46208)\n",
      "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0560) | Acc: (98.40%) (46729/47488)\n",
      "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0561) | Acc: (98.40%) (47988/48768)\n",
      "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0560) | Acc: (98.40%) (49201/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3893) | Acc: (89.22%) (8922/10000)\n",
      "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0978) | Acc: (96.88%) (124/128)\n",
      "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0521) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0531) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0513) | Acc: (98.66%) (3915/3968)\n",
      "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0513) | Acc: (98.61%) (5175/5248)\n",
      "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0514) | Acc: (98.65%) (6440/6528)\n",
      "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0510) | Acc: (98.64%) (7702/7808)\n",
      "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0498) | Acc: (98.67%) (8967/9088)\n",
      "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0500) | Acc: (98.69%) (10232/10368)\n",
      "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0513) | Acc: (98.64%) (11490/11648)\n",
      "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0520) | Acc: (98.62%) (12749/12928)\n",
      "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0523) | Acc: (98.59%) (14007/14208)\n",
      "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0526) | Acc: (98.59%) (15270/15488)\n",
      "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0523) | Acc: (98.60%) (16534/16768)\n",
      "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0523) | Acc: (98.61%) (17797/18048)\n",
      "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0521) | Acc: (98.61%) (19060/19328)\n",
      "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0521) | Acc: (98.61%) (20322/20608)\n",
      "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0527) | Acc: (98.58%) (21578/21888)\n",
      "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0531) | Acc: (98.57%) (22837/23168)\n",
      "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0529) | Acc: (98.58%) (24102/24448)\n",
      "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0529) | Acc: (98.59%) (25364/25728)\n",
      "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0526) | Acc: (98.60%) (26629/27008)\n",
      "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0526) | Acc: (98.61%) (27895/28288)\n",
      "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0527) | Acc: (98.60%) (29155/29568)\n",
      "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0529) | Acc: (98.60%) (30416/30848)\n",
      "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0529) | Acc: (98.60%) (31679/32128)\n",
      "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0527) | Acc: (98.61%) (32942/33408)\n",
      "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.59%) (34198/34688)\n",
      "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0529) | Acc: (98.59%) (35461/35968)\n",
      "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0533) | Acc: (98.57%) (36716/37248)\n",
      "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0531) | Acc: (98.58%) (37982/38528)\n",
      "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0534) | Acc: (98.57%) (39240/39808)\n",
      "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0536) | Acc: (98.57%) (40500/41088)\n",
      "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0536) | Acc: (98.56%) (41760/42368)\n",
      "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0539) | Acc: (98.56%) (43021/43648)\n",
      "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0540) | Acc: (98.55%) (44275/44928)\n",
      "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0541) | Acc: (98.53%) (45531/46208)\n",
      "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0542) | Acc: (98.53%) (46792/47488)\n",
      "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0543) | Acc: (98.53%) (48053/48768)\n",
      "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0543) | Acc: (98.53%) (49263/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3891) | Acc: (89.19%) (8919/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0257) | Acc: (100.00%) (128/128)\n",
      "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0516) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0560) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0558) | Acc: (98.34%) (3902/3968)\n",
      "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0564) | Acc: (98.25%) (5156/5248)\n",
      "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0555) | Acc: (98.28%) (6416/6528)\n",
      "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0555) | Acc: (98.32%) (7677/7808)\n",
      "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0541) | Acc: (98.43%) (8945/9088)\n",
      "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0545) | Acc: (98.42%) (10204/10368)\n",
      "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0554) | Acc: (98.41%) (11463/11648)\n",
      "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0551) | Acc: (98.43%) (12725/12928)\n",
      "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0548) | Acc: (98.47%) (13990/14208)\n",
      "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0542) | Acc: (98.50%) (15256/15488)\n",
      "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0546) | Acc: (98.53%) (16521/16768)\n",
      "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0538) | Acc: (98.56%) (17789/18048)\n",
      "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0534) | Acc: (98.58%) (19054/19328)\n",
      "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0539) | Acc: (98.54%) (20308/20608)\n",
      "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0537) | Acc: (98.55%) (21571/21888)\n",
      "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0537) | Acc: (98.55%) (22833/23168)\n",
      "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0537) | Acc: (98.54%) (24092/24448)\n",
      "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0536) | Acc: (98.56%) (25357/25728)\n",
      "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0536) | Acc: (98.56%) (26619/27008)\n",
      "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0537) | Acc: (98.55%) (27878/28288)\n",
      "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0537) | Acc: (98.55%) (29139/29568)\n",
      "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0539) | Acc: (98.53%) (30394/30848)\n",
      "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0538) | Acc: (98.53%) (31655/32128)\n",
      "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0542) | Acc: (98.52%) (32912/33408)\n",
      "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0542) | Acc: (98.51%) (34170/34688)\n",
      "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0542) | Acc: (98.51%) (35432/35968)\n",
      "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0540) | Acc: (98.52%) (36695/37248)\n",
      "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0541) | Acc: (98.51%) (37954/38528)\n",
      "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.51%) (39216/39808)\n",
      "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0542) | Acc: (98.50%) (40472/41088)\n",
      "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0542) | Acc: (98.50%) (41732/42368)\n",
      "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0544) | Acc: (98.49%) (42989/43648)\n",
      "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0543) | Acc: (98.50%) (44252/44928)\n",
      "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0546) | Acc: (98.48%) (45506/46208)\n",
      "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0546) | Acc: (98.48%) (46768/47488)\n",
      "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0545) | Acc: (98.49%) (48031/48768)\n",
      "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0543) | Acc: (98.50%) (49251/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3858) | Acc: (89.20%) (8920/10000)\n",
      "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0634) | Acc: (97.66%) (125/128)\n",
      "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0470) | Acc: (98.86%) (1392/1408)\n",
      "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0505) | Acc: (98.74%) (2654/2688)\n",
      "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0505) | Acc: (98.69%) (3916/3968)\n",
      "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0501) | Acc: (98.69%) (5179/5248)\n",
      "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0495) | Acc: (98.76%) (6447/6528)\n",
      "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0504) | Acc: (98.71%) (7707/7808)\n",
      "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0508) | Acc: (98.71%) (8971/9088)\n",
      "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0528) | Acc: (98.60%) (10223/10368)\n",
      "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0553) | Acc: (98.49%) (11472/11648)\n",
      "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0553) | Acc: (98.50%) (12734/12928)\n",
      "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0558) | Acc: (98.49%) (13994/14208)\n",
      "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0554) | Acc: (98.50%) (15256/15488)\n",
      "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0545) | Acc: (98.54%) (16524/16768)\n",
      "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0543) | Acc: (98.58%) (17791/18048)\n",
      "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0541) | Acc: (98.58%) (19053/19328)\n",
      "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0542) | Acc: (98.58%) (20315/20608)\n",
      "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0542) | Acc: (98.59%) (21580/21888)\n",
      "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0546) | Acc: (98.58%) (22838/23168)\n",
      "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0540) | Acc: (98.60%) (24105/24448)\n",
      "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0540) | Acc: (98.59%) (25364/25728)\n",
      "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0544) | Acc: (98.55%) (26616/27008)\n",
      "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0543) | Acc: (98.55%) (27878/28288)\n",
      "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0544) | Acc: (98.55%) (29139/29568)\n",
      "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0543) | Acc: (98.55%) (30402/30848)\n",
      "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0547) | Acc: (98.55%) (31663/32128)\n",
      "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0545) | Acc: (98.55%) (32922/33408)\n",
      "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0547) | Acc: (98.54%) (34183/34688)\n",
      "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0552) | Acc: (98.52%) (35437/35968)\n",
      "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0549) | Acc: (98.53%) (36700/37248)\n",
      "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0549) | Acc: (98.53%) (37963/38528)\n",
      "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0551) | Acc: (98.52%) (39218/39808)\n",
      "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0549) | Acc: (98.53%) (40486/41088)\n",
      "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0549) | Acc: (98.53%) (41746/42368)\n",
      "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0549) | Acc: (98.53%) (43005/43648)\n",
      "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0551) | Acc: (98.52%) (44264/44928)\n",
      "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0551) | Acc: (98.52%) (45525/46208)\n",
      "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0549) | Acc: (98.53%) (46788/47488)\n",
      "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0547) | Acc: (98.54%) (48055/48768)\n",
      "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0547) | Acc: (98.54%) (49269/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3875) | Acc: (89.16%) (8916/10000)\n",
      "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0585) | Acc: (98.44%) (126/128)\n",
      "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0514) | Acc: (98.58%) (1388/1408)\n",
      "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0509) | Acc: (98.59%) (2650/2688)\n",
      "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0519) | Acc: (98.51%) (3909/3968)\n",
      "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0527) | Acc: (98.48%) (5168/5248)\n",
      "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0515) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0523) | Acc: (98.50%) (7691/7808)\n",
      "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0526) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0527) | Acc: (98.51%) (10213/10368)\n",
      "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0522) | Acc: (98.53%) (11477/11648)\n",
      "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0537) | Acc: (98.45%) (12728/12928)\n",
      "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0544) | Acc: (98.44%) (13986/14208)\n",
      "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0543) | Acc: (98.41%) (15241/15488)\n",
      "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0544) | Acc: (98.41%) (16502/16768)\n",
      "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0547) | Acc: (98.40%) (17760/18048)\n",
      "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0549) | Acc: (98.39%) (19016/19328)\n",
      "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0559) | Acc: (98.35%) (20267/20608)\n",
      "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0564) | Acc: (98.33%) (21522/21888)\n",
      "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0562) | Acc: (98.34%) (22783/23168)\n",
      "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0559) | Acc: (98.35%) (24045/24448)\n",
      "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0560) | Acc: (98.35%) (25304/25728)\n",
      "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0559) | Acc: (98.36%) (26564/27008)\n",
      "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0558) | Acc: (98.35%) (27821/28288)\n",
      "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0554) | Acc: (98.38%) (29089/29568)\n",
      "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0555) | Acc: (98.38%) (30347/30848)\n",
      "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0552) | Acc: (98.40%) (31614/32128)\n",
      "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0550) | Acc: (98.41%) (32878/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0548) | Acc: (98.42%) (34139/34688)\n",
      "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0548) | Acc: (98.41%) (35396/35968)\n",
      "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0547) | Acc: (98.43%) (36662/37248)\n",
      "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0547) | Acc: (98.43%) (37923/38528)\n",
      "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0548) | Acc: (98.43%) (39184/39808)\n",
      "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0548) | Acc: (98.44%) (40445/41088)\n",
      "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0547) | Acc: (98.44%) (41707/42368)\n",
      "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0550) | Acc: (98.43%) (42964/43648)\n",
      "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0551) | Acc: (98.43%) (44224/44928)\n",
      "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0550) | Acc: (98.43%) (45483/46208)\n",
      "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0556) | Acc: (98.41%) (46731/47488)\n",
      "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0555) | Acc: (98.41%) (47991/48768)\n",
      "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0554) | Acc: (98.41%) (49204/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3890) | Acc: (89.16%) (8916/10000)\n",
      "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0354) | Acc: (99.22%) (127/128)\n",
      "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0581) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0554) | Acc: (98.33%) (2643/2688)\n",
      "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0539) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0548) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0543) | Acc: (98.48%) (6429/6528)\n",
      "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0527) | Acc: (98.51%) (7692/7808)\n",
      "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0534) | Acc: (98.49%) (8951/9088)\n",
      "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0545) | Acc: (98.46%) (10208/10368)\n",
      "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0556) | Acc: (98.39%) (11461/11648)\n",
      "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0549) | Acc: (98.38%) (12719/12928)\n",
      "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0551) | Acc: (98.36%) (13975/14208)\n",
      "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0555) | Acc: (98.35%) (15232/15488)\n",
      "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0552) | Acc: (98.37%) (16495/16768)\n",
      "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0558) | Acc: (98.34%) (17749/18048)\n",
      "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0551) | Acc: (98.38%) (19015/19328)\n",
      "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0555) | Acc: (98.36%) (20271/20608)\n",
      "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0554) | Acc: (98.38%) (21533/21888)\n",
      "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0553) | Acc: (98.39%) (22795/23168)\n",
      "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0553) | Acc: (98.41%) (24059/24448)\n",
      "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0556) | Acc: (98.39%) (25315/25728)\n",
      "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0555) | Acc: (98.40%) (26575/27008)\n",
      "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0556) | Acc: (98.37%) (27828/28288)\n",
      "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0558) | Acc: (98.37%) (29085/29568)\n",
      "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0560) | Acc: (98.36%) (30343/30848)\n",
      "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0562) | Acc: (98.35%) (31597/32128)\n",
      "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0562) | Acc: (98.35%) (32856/33408)\n",
      "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0557) | Acc: (98.38%) (34126/34688)\n",
      "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0560) | Acc: (98.38%) (35387/35968)\n",
      "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0556) | Acc: (98.40%) (36651/37248)\n",
      "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0554) | Acc: (98.41%) (37915/38528)\n",
      "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0553) | Acc: (98.40%) (39171/39808)\n",
      "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0550) | Acc: (98.42%) (40437/41088)\n",
      "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0552) | Acc: (98.40%) (41690/42368)\n",
      "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0552) | Acc: (98.41%) (42952/43648)\n",
      "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0554) | Acc: (98.40%) (44208/44928)\n",
      "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0554) | Acc: (98.40%) (45469/46208)\n",
      "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0555) | Acc: (98.39%) (46725/47488)\n",
      "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0554) | Acc: (98.40%) (47989/48768)\n",
      "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0554) | Acc: (98.41%) (49204/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3883) | Acc: (89.26%) (8926/10000)\n",
      "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0655) | Acc: (97.66%) (125/128)\n",
      "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0545) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0546) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0539) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0572) | Acc: (98.36%) (5162/5248)\n",
      "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0557) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0555) | Acc: (98.46%) (7688/7808)\n",
      "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0546) | Acc: (98.48%) (8950/9088)\n",
      "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.48%) (10210/10368)\n",
      "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0541) | Acc: (98.47%) (11470/11648)\n",
      "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0543) | Acc: (98.45%) (12728/12928)\n",
      "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0535) | Acc: (98.50%) (13995/14208)\n",
      "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0537) | Acc: (98.53%) (15261/15488)\n",
      "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0533) | Acc: (98.54%) (16524/16768)\n",
      "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0536) | Acc: (98.50%) (17777/18048)\n",
      "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0537) | Acc: (98.46%) (19031/19328)\n",
      "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0542) | Acc: (98.43%) (20284/20608)\n",
      "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0542) | Acc: (98.45%) (21549/21888)\n",
      "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0545) | Acc: (98.46%) (22812/23168)\n",
      "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0543) | Acc: (98.47%) (24073/24448)\n",
      "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0546) | Acc: (98.47%) (25334/25728)\n",
      "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0549) | Acc: (98.46%) (26592/27008)\n",
      "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0545) | Acc: (98.48%) (27858/28288)\n",
      "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0543) | Acc: (98.48%) (29118/29568)\n",
      "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0542) | Acc: (98.48%) (30379/30848)\n",
      "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0542) | Acc: (98.48%) (31640/32128)\n",
      "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0547) | Acc: (98.46%) (32894/33408)\n",
      "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0551) | Acc: (98.45%) (34152/34688)\n",
      "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0549) | Acc: (98.46%) (35414/35968)\n",
      "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0547) | Acc: (98.48%) (36681/37248)\n",
      "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0545) | Acc: (98.48%) (37943/38528)\n",
      "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0543) | Acc: (98.51%) (39213/39808)\n",
      "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0541) | Acc: (98.52%) (40479/41088)\n",
      "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0542) | Acc: (98.52%) (41739/42368)\n",
      "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0541) | Acc: (98.52%) (43000/43648)\n",
      "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0541) | Acc: (98.52%) (44261/44928)\n",
      "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0539) | Acc: (98.53%) (45529/46208)\n",
      "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0540) | Acc: (98.53%) (46790/47488)\n",
      "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0541) | Acc: (98.52%) (48047/48768)\n",
      "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0540) | Acc: (98.53%) (49267/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3886) | Acc: (89.18%) (8918/10000)\n",
      "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0414) | Acc: (99.22%) (127/128)\n",
      "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0532) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0631) | Acc: (98.03%) (2635/2688)\n",
      "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0611) | Acc: (98.24%) (3898/3968)\n",
      "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0557) | Acc: (98.49%) (5169/5248)\n",
      "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0562) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0553) | Acc: (98.55%) (7695/7808)\n",
      "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0550) | Acc: (98.57%) (8958/9088)\n",
      "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0552) | Acc: (98.56%) (10219/10368)\n",
      "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0536) | Acc: (98.61%) (11486/11648)\n",
      "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0541) | Acc: (98.54%) (12739/12928)\n",
      "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0537) | Acc: (98.56%) (14004/14208)\n",
      "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0544) | Acc: (98.54%) (15262/15488)\n",
      "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0541) | Acc: (98.54%) (16524/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0534) | Acc: (98.59%) (17794/18048)\n",
      "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0529) | Acc: (98.60%) (19057/19328)\n",
      "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0534) | Acc: (98.58%) (20315/20608)\n",
      "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0529) | Acc: (98.60%) (21582/21888)\n",
      "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0532) | Acc: (98.57%) (22837/23168)\n",
      "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0533) | Acc: (98.56%) (24097/24448)\n",
      "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0532) | Acc: (98.57%) (25359/25728)\n",
      "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0535) | Acc: (98.56%) (26619/27008)\n",
      "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0534) | Acc: (98.56%) (27880/28288)\n",
      "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0531) | Acc: (98.57%) (29145/29568)\n",
      "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0529) | Acc: (98.57%) (30406/30848)\n",
      "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0531) | Acc: (98.55%) (31663/32128)\n",
      "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0532) | Acc: (98.54%) (32920/33408)\n",
      "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0534) | Acc: (98.53%) (34177/34688)\n",
      "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0532) | Acc: (98.53%) (35441/35968)\n",
      "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0532) | Acc: (98.55%) (36708/37248)\n",
      "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0533) | Acc: (98.55%) (37969/38528)\n",
      "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.54%) (39227/39808)\n",
      "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0541) | Acc: (98.52%) (40478/41088)\n",
      "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0540) | Acc: (98.50%) (41733/42368)\n",
      "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0537) | Acc: (98.51%) (42996/43648)\n",
      "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0537) | Acc: (98.52%) (44261/44928)\n",
      "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0536) | Acc: (98.52%) (45524/46208)\n",
      "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0536) | Acc: (98.52%) (46785/47488)\n",
      "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0536) | Acc: (98.53%) (48051/48768)\n",
      "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0536) | Acc: (98.53%) (49267/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3882) | Acc: (89.23%) (8923/10000)\n",
      "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0459) | Acc: (98.44%) (126/128)\n",
      "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0554) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0514) | Acc: (98.70%) (2653/2688)\n",
      "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0516) | Acc: (98.77%) (3919/3968)\n",
      "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0519) | Acc: (98.74%) (5182/5248)\n",
      "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0517) | Acc: (98.71%) (6444/6528)\n",
      "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0513) | Acc: (98.73%) (7709/7808)\n",
      "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0517) | Acc: (98.62%) (8963/9088)\n",
      "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0512) | Acc: (98.63%) (10226/10368)\n",
      "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0517) | Acc: (98.62%) (11487/11648)\n",
      "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0530) | Acc: (98.56%) (12742/12928)\n",
      "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0531) | Acc: (98.55%) (14002/14208)\n",
      "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0530) | Acc: (98.57%) (15267/15488)\n",
      "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0529) | Acc: (98.57%) (16528/16768)\n",
      "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0530) | Acc: (98.56%) (17788/18048)\n",
      "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0534) | Acc: (98.54%) (19045/19328)\n",
      "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0534) | Acc: (98.52%) (20303/20608)\n",
      "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0541) | Acc: (98.48%) (21555/21888)\n",
      "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0540) | Acc: (98.48%) (22816/23168)\n",
      "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0537) | Acc: (98.52%) (24086/24448)\n",
      "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0538) | Acc: (98.51%) (25344/25728)\n",
      "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0539) | Acc: (98.49%) (26601/27008)\n",
      "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0543) | Acc: (98.47%) (27854/28288)\n",
      "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0543) | Acc: (98.47%) (29117/29568)\n",
      "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0541) | Acc: (98.49%) (30383/30848)\n",
      "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0543) | Acc: (98.47%) (31636/32128)\n",
      "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0545) | Acc: (98.46%) (32893/33408)\n",
      "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0545) | Acc: (98.47%) (34158/34688)\n",
      "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0543) | Acc: (98.48%) (35420/35968)\n",
      "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0543) | Acc: (98.48%) (36681/37248)\n",
      "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0545) | Acc: (98.46%) (37934/38528)\n",
      "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.48%) (39203/39808)\n",
      "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0540) | Acc: (98.48%) (40463/41088)\n",
      "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0543) | Acc: (98.47%) (41719/42368)\n",
      "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0541) | Acc: (98.48%) (42985/43648)\n",
      "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0539) | Acc: (98.50%) (44252/44928)\n",
      "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0536) | Acc: (98.52%) (45522/46208)\n",
      "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0536) | Acc: (98.52%) (46783/47488)\n",
      "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0535) | Acc: (98.53%) (48050/48768)\n",
      "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0532) | Acc: (98.54%) (49270/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3875) | Acc: (89.27%) (8927/10000)\n",
      "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0425) | Acc: (99.22%) (127/128)\n",
      "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0575) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0582) | Acc: (98.33%) (2643/2688)\n",
      "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0561) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0555) | Acc: (98.49%) (5169/5248)\n",
      "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0531) | Acc: (98.61%) (6437/6528)\n",
      "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0542) | Acc: (98.59%) (7698/7808)\n",
      "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0545) | Acc: (98.48%) (8950/9088)\n",
      "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.50%) (10212/10368)\n",
      "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0536) | Acc: (98.52%) (11476/11648)\n",
      "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0531) | Acc: (98.54%) (12739/12928)\n",
      "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0533) | Acc: (98.51%) (13996/14208)\n",
      "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0534) | Acc: (98.51%) (15257/15488)\n",
      "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0532) | Acc: (98.53%) (16521/16768)\n",
      "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0538) | Acc: (98.48%) (17774/18048)\n",
      "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0535) | Acc: (98.47%) (19033/19328)\n",
      "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0538) | Acc: (98.46%) (20290/20608)\n",
      "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0539) | Acc: (98.46%) (21552/21888)\n",
      "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0545) | Acc: (98.44%) (22807/23168)\n",
      "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0548) | Acc: (98.41%) (24059/24448)\n",
      "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0547) | Acc: (98.41%) (25319/25728)\n",
      "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0547) | Acc: (98.41%) (26579/27008)\n",
      "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0547) | Acc: (98.41%) (27838/28288)\n",
      "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0547) | Acc: (98.42%) (29101/29568)\n",
      "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0548) | Acc: (98.41%) (30359/30848)\n",
      "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0551) | Acc: (98.42%) (31620/32128)\n",
      "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0550) | Acc: (98.44%) (32887/33408)\n",
      "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0547) | Acc: (98.46%) (34155/34688)\n",
      "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0548) | Acc: (98.46%) (35413/35968)\n",
      "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0550) | Acc: (98.46%) (36673/37248)\n",
      "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0552) | Acc: (98.45%) (37930/38528)\n",
      "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0553) | Acc: (98.45%) (39190/39808)\n",
      "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0551) | Acc: (98.47%) (40458/41088)\n",
      "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0552) | Acc: (98.45%) (41711/42368)\n",
      "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0557) | Acc: (98.42%) (42960/43648)\n",
      "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0558) | Acc: (98.42%) (44216/44928)\n",
      "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0557) | Acc: (98.41%) (45475/46208)\n",
      "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0555) | Acc: (98.42%) (46737/47488)\n",
      "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0556) | Acc: (98.42%) (47996/48768)\n",
      "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0556) | Acc: (98.42%) (49209/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3904) | Acc: (89.13%) (8913/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0506) | Acc: (97.66%) (125/128)\n",
      "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0512) | Acc: (99.01%) (1394/1408)\n",
      "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0510) | Acc: (99.00%) (2661/2688)\n",
      "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0546) | Acc: (98.74%) (3918/3968)\n",
      "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0535) | Acc: (98.80%) (5185/5248)\n",
      "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0539) | Acc: (98.70%) (6443/6528)\n",
      "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0545) | Acc: (98.66%) (7703/7808)\n",
      "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0556) | Acc: (98.61%) (8962/9088)\n",
      "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0565) | Acc: (98.57%) (10220/10368)\n",
      "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0563) | Acc: (98.54%) (11478/11648)\n",
      "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0558) | Acc: (98.54%) (12739/12928)\n",
      "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0563) | Acc: (98.50%) (13995/14208)\n",
      "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0571) | Acc: (98.47%) (15251/15488)\n",
      "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0569) | Acc: (98.45%) (16508/16768)\n",
      "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0569) | Acc: (98.43%) (17764/18048)\n",
      "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0569) | Acc: (98.44%) (19026/19328)\n",
      "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0568) | Acc: (98.44%) (20286/20608)\n",
      "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0560) | Acc: (98.48%) (21555/21888)\n",
      "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0552) | Acc: (98.51%) (22823/23168)\n",
      "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0550) | Acc: (98.50%) (24082/24448)\n",
      "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0547) | Acc: (98.50%) (25341/25728)\n",
      "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0547) | Acc: (98.49%) (26600/27008)\n",
      "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0548) | Acc: (98.50%) (27863/28288)\n",
      "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0546) | Acc: (98.51%) (29127/29568)\n",
      "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0546) | Acc: (98.51%) (30388/30848)\n",
      "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0547) | Acc: (98.51%) (31650/32128)\n",
      "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0545) | Acc: (98.52%) (32914/33408)\n",
      "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0545) | Acc: (98.51%) (34170/34688)\n",
      "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0550) | Acc: (98.48%) (35422/35968)\n",
      "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0551) | Acc: (98.47%) (36679/37248)\n",
      "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0550) | Acc: (98.47%) (37938/38528)\n",
      "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0553) | Acc: (98.45%) (39190/39808)\n",
      "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0552) | Acc: (98.44%) (40448/41088)\n",
      "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0551) | Acc: (98.45%) (41710/42368)\n",
      "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0555) | Acc: (98.42%) (42957/43648)\n",
      "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0552) | Acc: (98.43%) (44223/44928)\n",
      "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0552) | Acc: (98.44%) (45485/46208)\n",
      "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0550) | Acc: (98.45%) (46751/47488)\n",
      "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0549) | Acc: (98.45%) (48013/48768)\n",
      "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0550) | Acc: (98.45%) (49227/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3888) | Acc: (89.21%) (8921/10000)\n",
      "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0775) | Acc: (98.44%) (126/128)\n",
      "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0604) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0576) | Acc: (98.55%) (2649/2688)\n",
      "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0601) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0601) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0598) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0592) | Acc: (98.36%) (7680/7808)\n",
      "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0601) | Acc: (98.31%) (8934/9088)\n",
      "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0577) | Acc: (98.41%) (10203/10368)\n",
      "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0565) | Acc: (98.45%) (11467/11648)\n",
      "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0561) | Acc: (98.45%) (12728/12928)\n",
      "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0558) | Acc: (98.47%) (13991/14208)\n",
      "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0563) | Acc: (98.46%) (15249/15488)\n",
      "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0562) | Acc: (98.46%) (16510/16768)\n",
      "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0558) | Acc: (98.47%) (17772/18048)\n",
      "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0556) | Acc: (98.48%) (19035/19328)\n",
      "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0555) | Acc: (98.50%) (20298/20608)\n",
      "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0558) | Acc: (98.47%) (21553/21888)\n",
      "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0555) | Acc: (98.48%) (22816/23168)\n",
      "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0550) | Acc: (98.51%) (24084/24448)\n",
      "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0557) | Acc: (98.49%) (25340/25728)\n",
      "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0553) | Acc: (98.51%) (26605/27008)\n",
      "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0546) | Acc: (98.52%) (27870/28288)\n",
      "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0546) | Acc: (98.51%) (29126/29568)\n",
      "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0543) | Acc: (98.51%) (30387/30848)\n",
      "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0541) | Acc: (98.51%) (31648/32128)\n",
      "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0545) | Acc: (98.49%) (32904/33408)\n",
      "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0545) | Acc: (98.50%) (34166/34688)\n",
      "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0544) | Acc: (98.50%) (35427/35968)\n",
      "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0542) | Acc: (98.50%) (36691/37248)\n",
      "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.50%) (37951/38528)\n",
      "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.51%) (39214/39808)\n",
      "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.50%) (40470/41088)\n",
      "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0537) | Acc: (98.51%) (41735/42368)\n",
      "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0540) | Acc: (98.49%) (42991/43648)\n",
      "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0540) | Acc: (98.49%) (44249/44928)\n",
      "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0540) | Acc: (98.50%) (45514/46208)\n",
      "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0541) | Acc: (98.49%) (46772/47488)\n",
      "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0539) | Acc: (98.50%) (48038/48768)\n",
      "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0539) | Acc: (98.50%) (49249/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3882) | Acc: (89.16%) (8916/10000)\n",
      "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0615) | Acc: (96.88%) (124/128)\n",
      "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0519) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0544) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0537) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0524) | Acc: (98.63%) (5176/5248)\n",
      "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0527) | Acc: (98.61%) (6437/6528)\n",
      "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0526) | Acc: (98.60%) (7699/7808)\n",
      "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0537) | Acc: (98.48%) (8950/9088)\n",
      "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0538) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0545) | Acc: (98.48%) (11471/11648)\n",
      "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0543) | Acc: (98.50%) (12734/12928)\n",
      "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0548) | Acc: (98.53%) (13999/14208)\n",
      "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0547) | Acc: (98.51%) (15257/15488)\n",
      "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0553) | Acc: (98.48%) (16513/16768)\n",
      "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0564) | Acc: (98.45%) (17768/18048)\n",
      "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0559) | Acc: (98.47%) (19032/19328)\n",
      "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0557) | Acc: (98.48%) (20294/20608)\n",
      "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0557) | Acc: (98.48%) (21555/21888)\n",
      "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0555) | Acc: (98.46%) (22811/23168)\n",
      "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0556) | Acc: (98.46%) (24071/24448)\n",
      "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0555) | Acc: (98.47%) (25334/25728)\n",
      "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0556) | Acc: (98.47%) (26594/27008)\n",
      "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0558) | Acc: (98.46%) (27852/28288)\n",
      "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0554) | Acc: (98.48%) (29118/29568)\n",
      "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0554) | Acc: (98.48%) (30380/30848)\n",
      "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0562) | Acc: (98.44%) (31628/32128)\n",
      "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0559) | Acc: (98.46%) (32894/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0558) | Acc: (98.47%) (34157/34688)\n",
      "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0557) | Acc: (98.47%) (35417/35968)\n",
      "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0556) | Acc: (98.48%) (36681/37248)\n",
      "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0556) | Acc: (98.48%) (37943/38528)\n",
      "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0556) | Acc: (98.48%) (39204/39808)\n",
      "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0553) | Acc: (98.49%) (40466/41088)\n",
      "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0553) | Acc: (98.48%) (41725/42368)\n",
      "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0552) | Acc: (98.48%) (42983/43648)\n",
      "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0551) | Acc: (98.49%) (44249/44928)\n",
      "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0552) | Acc: (98.49%) (45508/46208)\n",
      "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0553) | Acc: (98.49%) (46773/47488)\n",
      "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0552) | Acc: (98.48%) (48029/48768)\n",
      "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0553) | Acc: (98.47%) (49237/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3869) | Acc: (89.26%) (8926/10000)\n",
      "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0674) | Acc: (98.44%) (126/128)\n",
      "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0515) | Acc: (98.79%) (1391/1408)\n",
      "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0518) | Acc: (98.62%) (2651/2688)\n",
      "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0535) | Acc: (98.56%) (3911/3968)\n",
      "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0525) | Acc: (98.57%) (5173/5248)\n",
      "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0517) | Acc: (98.58%) (6435/6528)\n",
      "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0513) | Acc: (98.60%) (7699/7808)\n",
      "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0527) | Acc: (98.50%) (8952/9088)\n",
      "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0549) | Acc: (98.40%) (10202/10368)\n",
      "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0552) | Acc: (98.36%) (11457/11648)\n",
      "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0539) | Acc: (98.43%) (12725/12928)\n",
      "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0538) | Acc: (98.42%) (13984/14208)\n",
      "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0540) | Acc: (98.44%) (15246/15488)\n",
      "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0540) | Acc: (98.42%) (16503/16768)\n",
      "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0540) | Acc: (98.43%) (17764/18048)\n",
      "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0536) | Acc: (98.43%) (19025/19328)\n",
      "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0537) | Acc: (98.44%) (20287/20608)\n",
      "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0535) | Acc: (98.43%) (21545/21888)\n",
      "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0539) | Acc: (98.41%) (22799/23168)\n",
      "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0540) | Acc: (98.41%) (24060/24448)\n",
      "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0535) | Acc: (98.43%) (25323/25728)\n",
      "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0536) | Acc: (98.43%) (26584/27008)\n",
      "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0541) | Acc: (98.42%) (27842/28288)\n",
      "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0540) | Acc: (98.43%) (29103/29568)\n",
      "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0536) | Acc: (98.46%) (30373/30848)\n",
      "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0536) | Acc: (98.46%) (31632/32128)\n",
      "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0541) | Acc: (98.44%) (32887/33408)\n",
      "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0540) | Acc: (98.44%) (34148/34688)\n",
      "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0541) | Acc: (98.43%) (35402/35968)\n",
      "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0539) | Acc: (98.45%) (36669/37248)\n",
      "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.45%) (37931/38528)\n",
      "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.44%) (39186/39808)\n",
      "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0542) | Acc: (98.44%) (40447/41088)\n",
      "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0543) | Acc: (98.43%) (41704/42368)\n",
      "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0545) | Acc: (98.44%) (42965/43648)\n",
      "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0544) | Acc: (98.44%) (44226/44928)\n",
      "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0542) | Acc: (98.44%) (45489/46208)\n",
      "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0541) | Acc: (98.45%) (46753/47488)\n",
      "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0543) | Acc: (98.44%) (48008/48768)\n",
      "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0545) | Acc: (98.44%) (49219/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3873) | Acc: (89.21%) (8921/10000)\n",
      "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0800) | Acc: (97.66%) (125/128)\n",
      "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0528) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0512) | Acc: (98.81%) (2656/2688)\n",
      "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0494) | Acc: (98.82%) (3921/3968)\n",
      "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0507) | Acc: (98.72%) (5181/5248)\n",
      "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0509) | Acc: (98.68%) (6442/6528)\n",
      "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0507) | Acc: (98.73%) (7709/7808)\n",
      "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0519) | Acc: (98.65%) (8965/9088)\n",
      "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0518) | Acc: (98.63%) (10226/10368)\n",
      "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0523) | Acc: (98.58%) (11483/11648)\n",
      "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0540) | Acc: (98.49%) (12733/12928)\n",
      "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0533) | Acc: (98.51%) (13997/14208)\n",
      "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0531) | Acc: (98.55%) (15264/15488)\n",
      "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0542) | Acc: (98.52%) (16520/16768)\n",
      "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0542) | Acc: (98.53%) (17783/18048)\n",
      "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0554) | Acc: (98.49%) (19036/19328)\n",
      "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0552) | Acc: (98.51%) (20300/20608)\n",
      "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0556) | Acc: (98.48%) (21555/21888)\n",
      "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0552) | Acc: (98.50%) (22820/23168)\n",
      "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0558) | Acc: (98.47%) (24074/24448)\n",
      "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0555) | Acc: (98.49%) (25340/25728)\n",
      "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0557) | Acc: (98.47%) (26596/27008)\n",
      "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0554) | Acc: (98.47%) (27855/28288)\n",
      "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0556) | Acc: (98.45%) (29111/29568)\n",
      "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0558) | Acc: (98.45%) (30369/30848)\n",
      "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0555) | Acc: (98.46%) (31632/32128)\n",
      "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0553) | Acc: (98.47%) (32898/33408)\n",
      "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0551) | Acc: (98.47%) (34159/34688)\n",
      "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0554) | Acc: (98.47%) (35416/35968)\n",
      "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0553) | Acc: (98.47%) (36677/37248)\n",
      "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0552) | Acc: (98.47%) (37939/38528)\n",
      "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0554) | Acc: (98.46%) (39195/39808)\n",
      "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0553) | Acc: (98.45%) (40451/41088)\n",
      "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0552) | Acc: (98.45%) (41711/42368)\n",
      "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0555) | Acc: (98.44%) (42967/43648)\n",
      "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0552) | Acc: (98.46%) (44234/44928)\n",
      "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0552) | Acc: (98.45%) (45492/46208)\n",
      "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0553) | Acc: (98.44%) (46749/47488)\n",
      "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0551) | Acc: (98.45%) (48011/48768)\n",
      "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0551) | Acc: (98.44%) (49220/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3878) | Acc: (89.14%) (8914/10000)\n",
      "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0554) | Acc: (99.22%) (127/128)\n",
      "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0488) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0507) | Acc: (98.59%) (2650/2688)\n",
      "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0503) | Acc: (98.66%) (3915/3968)\n",
      "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0515) | Acc: (98.59%) (5174/5248)\n",
      "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0513) | Acc: (98.65%) (6440/6528)\n",
      "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0513) | Acc: (98.67%) (7704/7808)\n",
      "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0526) | Acc: (98.61%) (8962/9088)\n",
      "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0546) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0547) | Acc: (98.47%) (11470/11648)\n",
      "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0552) | Acc: (98.46%) (12729/12928)\n",
      "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0552) | Acc: (98.45%) (13988/14208)\n",
      "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0551) | Acc: (98.44%) (15247/15488)\n",
      "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0557) | Acc: (98.42%) (16503/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0556) | Acc: (98.42%) (17763/18048)\n",
      "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0550) | Acc: (98.44%) (19026/19328)\n",
      "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0543) | Acc: (98.46%) (20290/20608)\n",
      "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0549) | Acc: (98.45%) (21549/21888)\n",
      "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0548) | Acc: (98.46%) (22811/23168)\n",
      "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0549) | Acc: (98.45%) (24068/24448)\n",
      "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0552) | Acc: (98.46%) (25331/25728)\n",
      "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0547) | Acc: (98.50%) (26602/27008)\n",
      "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0551) | Acc: (98.48%) (27858/28288)\n",
      "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0549) | Acc: (98.47%) (29117/29568)\n",
      "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0550) | Acc: (98.47%) (30376/30848)\n",
      "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0554) | Acc: (98.46%) (31632/32128)\n",
      "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0554) | Acc: (98.46%) (32894/33408)\n",
      "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0553) | Acc: (98.47%) (34157/34688)\n",
      "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0554) | Acc: (98.47%) (35418/35968)\n",
      "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0554) | Acc: (98.47%) (36679/37248)\n",
      "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0554) | Acc: (98.48%) (37941/38528)\n",
      "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0551) | Acc: (98.49%) (39208/39808)\n",
      "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0551) | Acc: (98.51%) (40474/41088)\n",
      "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0551) | Acc: (98.50%) (41732/42368)\n",
      "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0549) | Acc: (98.51%) (42997/43648)\n",
      "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0546) | Acc: (98.52%) (44263/44928)\n",
      "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0545) | Acc: (98.51%) (45518/46208)\n",
      "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0545) | Acc: (98.51%) (46781/47488)\n",
      "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0544) | Acc: (98.51%) (48040/48768)\n",
      "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0544) | Acc: (98.50%) (49251/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3892) | Acc: (89.22%) (8922/10000)\n",
      "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0360) | Acc: (100.00%) (128/128)\n",
      "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0530) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0510) | Acc: (98.51%) (2648/2688)\n",
      "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0521) | Acc: (98.54%) (3910/3968)\n",
      "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0543) | Acc: (98.48%) (5168/5248)\n",
      "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0548) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0555) | Acc: (98.45%) (7687/7808)\n",
      "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0551) | Acc: (98.46%) (8948/9088)\n",
      "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0554) | Acc: (98.45%) (10207/10368)\n",
      "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0553) | Acc: (98.45%) (11467/11648)\n",
      "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0564) | Acc: (98.42%) (12724/12928)\n",
      "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0558) | Acc: (98.48%) (13992/14208)\n",
      "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0558) | Acc: (98.43%) (15245/15488)\n",
      "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0554) | Acc: (98.44%) (16507/16768)\n",
      "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0556) | Acc: (98.44%) (17766/18048)\n",
      "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0555) | Acc: (98.45%) (19029/19328)\n",
      "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0554) | Acc: (98.47%) (20292/20608)\n",
      "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0548) | Acc: (98.49%) (21557/21888)\n",
      "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0549) | Acc: (98.47%) (22814/23168)\n",
      "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0552) | Acc: (98.45%) (24068/24448)\n",
      "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0551) | Acc: (98.46%) (25331/25728)\n",
      "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0551) | Acc: (98.44%) (26588/27008)\n",
      "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0548) | Acc: (98.47%) (27854/28288)\n",
      "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0545) | Acc: (98.46%) (29114/29568)\n",
      "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0541) | Acc: (98.49%) (30382/30848)\n",
      "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0538) | Acc: (98.50%) (31646/32128)\n",
      "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0537) | Acc: (98.52%) (32913/33408)\n",
      "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0539) | Acc: (98.49%) (34165/34688)\n",
      "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0535) | Acc: (98.51%) (35433/35968)\n",
      "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0535) | Acc: (98.51%) (36692/37248)\n",
      "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0538) | Acc: (98.52%) (37956/38528)\n",
      "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.50%) (39211/39808)\n",
      "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.49%) (40468/41088)\n",
      "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0543) | Acc: (98.47%) (41721/42368)\n",
      "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0543) | Acc: (98.46%) (42978/43648)\n",
      "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0541) | Acc: (98.48%) (44247/44928)\n",
      "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0541) | Acc: (98.48%) (45507/46208)\n",
      "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0541) | Acc: (98.49%) (46769/47488)\n",
      "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0544) | Acc: (98.47%) (48024/48768)\n",
      "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0544) | Acc: (98.47%) (49234/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3863) | Acc: (89.24%) (8924/10000)\n",
      "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0555) | Acc: (97.66%) (125/128)\n",
      "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0409) | Acc: (98.93%) (1393/1408)\n",
      "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0527) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0528) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0555) | Acc: (98.38%) (5163/5248)\n",
      "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0567) | Acc: (98.31%) (6418/6528)\n",
      "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0564) | Acc: (98.37%) (7681/7808)\n",
      "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0563) | Acc: (98.40%) (8943/9088)\n",
      "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0565) | Acc: (98.44%) (10206/10368)\n",
      "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0557) | Acc: (98.47%) (11470/11648)\n",
      "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0551) | Acc: (98.50%) (12734/12928)\n",
      "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0543) | Acc: (98.51%) (13997/14208)\n",
      "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0541) | Acc: (98.52%) (15259/15488)\n",
      "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0541) | Acc: (98.52%) (16519/16768)\n",
      "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0542) | Acc: (98.52%) (17780/18048)\n",
      "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0541) | Acc: (98.52%) (19042/19328)\n",
      "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0539) | Acc: (98.51%) (20301/20608)\n",
      "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0538) | Acc: (98.51%) (21561/21888)\n",
      "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0534) | Acc: (98.52%) (22826/23168)\n",
      "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0531) | Acc: (98.52%) (24086/24448)\n",
      "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0533) | Acc: (98.49%) (25340/25728)\n",
      "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0532) | Acc: (98.50%) (26602/27008)\n",
      "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0532) | Acc: (98.49%) (27860/28288)\n",
      "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0530) | Acc: (98.49%) (29121/29568)\n",
      "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0529) | Acc: (98.49%) (30383/30848)\n",
      "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0527) | Acc: (98.52%) (31652/32128)\n",
      "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0528) | Acc: (98.52%) (32913/33408)\n",
      "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.52%) (34175/34688)\n",
      "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0528) | Acc: (98.53%) (35439/35968)\n",
      "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0527) | Acc: (98.53%) (36702/37248)\n",
      "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0534) | Acc: (98.50%) (37950/38528)\n",
      "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0534) | Acc: (98.51%) (39213/39808)\n",
      "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0529) | Acc: (98.53%) (40484/41088)\n",
      "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0529) | Acc: (98.53%) (41744/42368)\n",
      "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0530) | Acc: (98.52%) (43004/43648)\n",
      "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0531) | Acc: (98.52%) (44262/44928)\n",
      "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0530) | Acc: (98.52%) (45524/46208)\n",
      "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0528) | Acc: (98.53%) (46789/47488)\n",
      "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.52%) (48048/48768)\n",
      "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0528) | Acc: (98.52%) (49261/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3879) | Acc: (89.24%) (8924/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0473) | Acc: (98.44%) (126/128)\n",
      "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0510) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0573) | Acc: (98.51%) (2648/2688)\n",
      "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0580) | Acc: (98.39%) (3904/3968)\n",
      "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0567) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0579) | Acc: (98.36%) (6421/6528)\n",
      "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0574) | Acc: (98.37%) (7681/7808)\n",
      "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0564) | Acc: (98.45%) (8947/9088)\n",
      "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0572) | Acc: (98.37%) (10199/10368)\n",
      "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0559) | Acc: (98.41%) (11463/11648)\n",
      "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0562) | Acc: (98.42%) (12724/12928)\n",
      "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0559) | Acc: (98.44%) (13987/14208)\n",
      "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0552) | Acc: (98.48%) (15253/15488)\n",
      "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0564) | Acc: (98.43%) (16505/16768)\n",
      "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0554) | Acc: (98.47%) (17772/18048)\n",
      "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0551) | Acc: (98.49%) (19036/19328)\n",
      "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0549) | Acc: (98.48%) (20295/20608)\n",
      "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0551) | Acc: (98.46%) (21551/21888)\n",
      "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0549) | Acc: (98.47%) (22813/23168)\n",
      "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0555) | Acc: (98.45%) (24070/24448)\n",
      "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0555) | Acc: (98.45%) (25330/25728)\n",
      "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0557) | Acc: (98.45%) (26589/27008)\n",
      "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0557) | Acc: (98.45%) (27849/28288)\n",
      "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0554) | Acc: (98.47%) (29116/29568)\n",
      "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0557) | Acc: (98.46%) (30372/30848)\n",
      "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0554) | Acc: (98.46%) (31634/32128)\n",
      "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0554) | Acc: (98.46%) (32892/33408)\n",
      "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0552) | Acc: (98.47%) (34156/34688)\n",
      "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0552) | Acc: (98.47%) (35417/35968)\n",
      "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0553) | Acc: (98.47%) (36677/37248)\n",
      "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0552) | Acc: (98.46%) (37936/38528)\n",
      "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0553) | Acc: (98.46%) (39193/39808)\n",
      "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0553) | Acc: (98.46%) (40455/41088)\n",
      "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0554) | Acc: (98.46%) (41717/42368)\n",
      "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0552) | Acc: (98.47%) (42982/43648)\n",
      "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0549) | Acc: (98.49%) (44251/44928)\n",
      "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0548) | Acc: (98.51%) (45518/46208)\n",
      "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0547) | Acc: (98.52%) (46783/47488)\n",
      "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0549) | Acc: (98.49%) (48033/48768)\n",
      "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0547) | Acc: (98.50%) (49250/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3866) | Acc: (89.27%) (8927/10000)\n",
      "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0704) | Acc: (97.66%) (125/128)\n",
      "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0492) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0548) | Acc: (98.21%) (2640/2688)\n",
      "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0515) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0529) | Acc: (98.42%) (5165/5248)\n",
      "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0529) | Acc: (98.41%) (6424/6528)\n",
      "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0533) | Acc: (98.46%) (7688/7808)\n",
      "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0528) | Acc: (98.49%) (8951/9088)\n",
      "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0558) | Acc: (98.42%) (11464/11648)\n",
      "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0546) | Acc: (98.51%) (12736/12928)\n",
      "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0544) | Acc: (98.54%) (14000/14208)\n",
      "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0548) | Acc: (98.53%) (15260/15488)\n",
      "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0545) | Acc: (98.52%) (16519/16768)\n",
      "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0549) | Acc: (98.48%) (17773/18048)\n",
      "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0545) | Acc: (98.50%) (19039/19328)\n",
      "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0544) | Acc: (98.51%) (20300/20608)\n",
      "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0545) | Acc: (98.50%) (21559/21888)\n",
      "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0538) | Acc: (98.53%) (22827/23168)\n",
      "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0537) | Acc: (98.53%) (24089/24448)\n",
      "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0532) | Acc: (98.57%) (25359/25728)\n",
      "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0533) | Acc: (98.54%) (26613/27008)\n",
      "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0532) | Acc: (98.53%) (27872/28288)\n",
      "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0535) | Acc: (98.51%) (29126/29568)\n",
      "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0540) | Acc: (98.47%) (30377/30848)\n",
      "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0544) | Acc: (98.44%) (31627/32128)\n",
      "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0542) | Acc: (98.45%) (32890/33408)\n",
      "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0542) | Acc: (98.46%) (34154/34688)\n",
      "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0542) | Acc: (98.46%) (35413/35968)\n",
      "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0545) | Acc: (98.45%) (36670/37248)\n",
      "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0543) | Acc: (98.46%) (37936/38528)\n",
      "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0544) | Acc: (98.47%) (39199/39808)\n",
      "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0546) | Acc: (98.47%) (40458/41088)\n",
      "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0547) | Acc: (98.47%) (41720/42368)\n",
      "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0548) | Acc: (98.46%) (42978/43648)\n",
      "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0547) | Acc: (98.47%) (44240/44928)\n",
      "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0545) | Acc: (98.46%) (45496/46208)\n",
      "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0546) | Acc: (98.45%) (46753/47488)\n",
      "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0547) | Acc: (98.44%) (48009/48768)\n",
      "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0547) | Acc: (98.45%) (49226/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3896) | Acc: (89.23%) (8923/10000)\n",
      "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0434) | Acc: (98.44%) (126/128)\n",
      "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0521) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0594) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0569) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0536) | Acc: (98.57%) (5173/5248)\n",
      "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0553) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0543) | Acc: (98.55%) (7695/7808)\n",
      "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0544) | Acc: (98.54%) (8955/9088)\n",
      "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0547) | Acc: (98.52%) (10215/10368)\n",
      "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0534) | Acc: (98.56%) (11480/11648)\n",
      "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0537) | Acc: (98.54%) (12739/12928)\n",
      "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0531) | Acc: (98.56%) (14004/14208)\n",
      "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0538) | Acc: (98.57%) (15266/15488)\n",
      "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0534) | Acc: (98.56%) (16526/16768)\n",
      "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0528) | Acc: (98.59%) (17793/18048)\n",
      "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0531) | Acc: (98.58%) (19053/19328)\n",
      "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0536) | Acc: (98.58%) (20315/20608)\n",
      "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0533) | Acc: (98.59%) (21579/21888)\n",
      "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0528) | Acc: (98.60%) (22844/23168)\n",
      "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0530) | Acc: (98.56%) (24096/24448)\n",
      "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0532) | Acc: (98.56%) (25358/25728)\n",
      "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0531) | Acc: (98.56%) (26618/27008)\n",
      "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0536) | Acc: (98.54%) (27876/28288)\n",
      "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0537) | Acc: (98.54%) (29136/29568)\n",
      "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0538) | Acc: (98.54%) (30398/30848)\n",
      "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0542) | Acc: (98.53%) (31655/32128)\n",
      "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0539) | Acc: (98.52%) (32914/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0540) | Acc: (98.51%) (34170/34688)\n",
      "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0540) | Acc: (98.52%) (35435/35968)\n",
      "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0538) | Acc: (98.54%) (36703/37248)\n",
      "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0537) | Acc: (98.55%) (37970/38528)\n",
      "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.56%) (39236/39808)\n",
      "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.56%) (40496/41088)\n",
      "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0537) | Acc: (98.57%) (41764/42368)\n",
      "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0536) | Acc: (98.58%) (43027/43648)\n",
      "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0535) | Acc: (98.57%) (44285/44928)\n",
      "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0534) | Acc: (98.57%) (45549/46208)\n",
      "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0533) | Acc: (98.57%) (46811/47488)\n",
      "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0532) | Acc: (98.57%) (48072/48768)\n",
      "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0532) | Acc: (98.58%) (49289/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3890) | Acc: (89.20%) (8920/10000)\n",
      "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0394) | Acc: (100.00%) (128/128)\n",
      "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0612) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0567) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0561) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0572) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0565) | Acc: (98.35%) (6420/6528)\n",
      "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0547) | Acc: (98.44%) (7686/7808)\n",
      "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0539) | Acc: (98.54%) (8955/9088)\n",
      "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0533) | Acc: (98.55%) (10218/10368)\n",
      "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0536) | Acc: (98.51%) (11475/11648)\n",
      "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0538) | Acc: (98.52%) (12737/12928)\n",
      "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0535) | Acc: (98.56%) (14003/14208)\n",
      "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0535) | Acc: (98.57%) (15266/15488)\n",
      "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0541) | Acc: (98.55%) (16525/16768)\n",
      "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0541) | Acc: (98.57%) (17790/18048)\n",
      "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0543) | Acc: (98.55%) (19048/19328)\n",
      "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0545) | Acc: (98.54%) (20307/20608)\n",
      "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0548) | Acc: (98.53%) (21567/21888)\n",
      "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0547) | Acc: (98.54%) (22830/23168)\n",
      "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0547) | Acc: (98.53%) (24088/24448)\n",
      "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0550) | Acc: (98.53%) (25350/25728)\n",
      "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0552) | Acc: (98.52%) (26607/27008)\n",
      "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0548) | Acc: (98.52%) (27868/28288)\n",
      "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0545) | Acc: (98.53%) (29132/29568)\n",
      "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0541) | Acc: (98.53%) (30395/30848)\n",
      "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0544) | Acc: (98.52%) (31652/32128)\n",
      "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0546) | Acc: (98.51%) (32909/33408)\n",
      "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0545) | Acc: (98.52%) (34173/34688)\n",
      "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0540) | Acc: (98.54%) (35444/35968)\n",
      "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0544) | Acc: (98.52%) (36695/37248)\n",
      "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0543) | Acc: (98.53%) (37960/38528)\n",
      "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0539) | Acc: (98.53%) (39224/39808)\n",
      "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.52%) (40481/41088)\n",
      "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0537) | Acc: (98.53%) (41746/42368)\n",
      "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0534) | Acc: (98.54%) (43012/43648)\n",
      "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0535) | Acc: (98.53%) (44269/44928)\n",
      "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0535) | Acc: (98.53%) (45527/46208)\n",
      "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0535) | Acc: (98.52%) (46784/47488)\n",
      "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0534) | Acc: (98.52%) (48044/48768)\n",
      "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0535) | Acc: (98.51%) (49256/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3886) | Acc: (89.23%) (8923/10000)\n",
      "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0587) | Acc: (97.66%) (125/128)\n",
      "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0433) | Acc: (98.93%) (1393/1408)\n",
      "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0463) | Acc: (98.81%) (2656/2688)\n",
      "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0502) | Acc: (98.66%) (3915/3968)\n",
      "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0486) | Acc: (98.78%) (5184/5248)\n",
      "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0513) | Acc: (98.64%) (6439/6528)\n",
      "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0521) | Acc: (98.54%) (7694/7808)\n",
      "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0521) | Acc: (98.60%) (8961/9088)\n",
      "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0529) | Acc: (98.60%) (10223/10368)\n",
      "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0525) | Acc: (98.59%) (11484/11648)\n",
      "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0524) | Acc: (98.65%) (12753/12928)\n",
      "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0524) | Acc: (98.60%) (14009/14208)\n",
      "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0519) | Acc: (98.62%) (15274/15488)\n",
      "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0523) | Acc: (98.59%) (16532/16768)\n",
      "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0521) | Acc: (98.61%) (17797/18048)\n",
      "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0517) | Acc: (98.62%) (19061/19328)\n",
      "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0519) | Acc: (98.60%) (20319/20608)\n",
      "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0517) | Acc: (98.61%) (21584/21888)\n",
      "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0516) | Acc: (98.61%) (22847/23168)\n",
      "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0519) | Acc: (98.59%) (24103/24448)\n",
      "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0523) | Acc: (98.57%) (25361/25728)\n",
      "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0521) | Acc: (98.58%) (26625/27008)\n",
      "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0521) | Acc: (98.58%) (27887/28288)\n",
      "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0517) | Acc: (98.59%) (29152/29568)\n",
      "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0518) | Acc: (98.57%) (30408/30848)\n",
      "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0517) | Acc: (98.58%) (31672/32128)\n",
      "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0518) | Acc: (98.57%) (32931/33408)\n",
      "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0517) | Acc: (98.58%) (34194/34688)\n",
      "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0521) | Acc: (98.55%) (35448/35968)\n",
      "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0523) | Acc: (98.55%) (36707/37248)\n",
      "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0527) | Acc: (98.52%) (37957/38528)\n",
      "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0527) | Acc: (98.52%) (39219/39808)\n",
      "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0530) | Acc: (98.52%) (40478/41088)\n",
      "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0532) | Acc: (98.50%) (41731/42368)\n",
      "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0534) | Acc: (98.48%) (42984/43648)\n",
      "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0534) | Acc: (98.47%) (44242/44928)\n",
      "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0535) | Acc: (98.48%) (45505/46208)\n",
      "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0535) | Acc: (98.48%) (46766/47488)\n",
      "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0531) | Acc: (98.49%) (48032/48768)\n",
      "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0536) | Acc: (98.48%) (49242/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3888) | Acc: (89.32%) (8932/10000)\n",
      "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0833) | Acc: (97.66%) (125/128)\n",
      "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0513) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0503) | Acc: (98.88%) (2658/2688)\n",
      "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0501) | Acc: (98.87%) (3923/3968)\n",
      "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0488) | Acc: (98.88%) (5189/5248)\n",
      "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0530) | Acc: (98.70%) (6443/6528)\n",
      "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0518) | Acc: (98.72%) (7708/7808)\n",
      "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0523) | Acc: (98.68%) (8968/9088)\n",
      "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0528) | Acc: (98.66%) (10229/10368)\n",
      "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0534) | Acc: (98.63%) (11489/11648)\n",
      "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0533) | Acc: (98.62%) (12750/12928)\n",
      "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0539) | Acc: (98.57%) (14005/14208)\n",
      "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0546) | Acc: (98.54%) (15262/15488)\n",
      "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0556) | Acc: (98.52%) (16519/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0554) | Acc: (98.50%) (17778/18048)\n",
      "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0554) | Acc: (98.49%) (19036/19328)\n",
      "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0556) | Acc: (98.48%) (20294/20608)\n",
      "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0557) | Acc: (98.47%) (21553/21888)\n",
      "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0560) | Acc: (98.44%) (22806/23168)\n",
      "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0558) | Acc: (98.45%) (24070/24448)\n",
      "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0555) | Acc: (98.46%) (25333/25728)\n",
      "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0558) | Acc: (98.44%) (26587/27008)\n",
      "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0555) | Acc: (98.47%) (27854/28288)\n",
      "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0556) | Acc: (98.47%) (29116/29568)\n",
      "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0553) | Acc: (98.49%) (30383/30848)\n",
      "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0549) | Acc: (98.51%) (31648/32128)\n",
      "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0550) | Acc: (98.49%) (32905/33408)\n",
      "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0551) | Acc: (98.48%) (34160/34688)\n",
      "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0550) | Acc: (98.47%) (35419/35968)\n",
      "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0548) | Acc: (98.49%) (36686/37248)\n",
      "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0548) | Acc: (98.49%) (37946/38528)\n",
      "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0550) | Acc: (98.48%) (39204/39808)\n",
      "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0551) | Acc: (98.50%) (40470/41088)\n",
      "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0548) | Acc: (98.50%) (41733/42368)\n",
      "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0545) | Acc: (98.51%) (42999/43648)\n",
      "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0543) | Acc: (98.51%) (44259/44928)\n",
      "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0542) | Acc: (98.52%) (45523/46208)\n",
      "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0541) | Acc: (98.52%) (46786/47488)\n",
      "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0541) | Acc: (98.52%) (48045/48768)\n",
      "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0540) | Acc: (98.51%) (49256/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3875) | Acc: (89.21%) (8921/10000)\n",
      "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0481) | Acc: (100.00%) (128/128)\n",
      "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0481) | Acc: (98.79%) (1391/1408)\n",
      "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0489) | Acc: (98.51%) (2648/2688)\n",
      "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0508) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0513) | Acc: (98.53%) (5171/5248)\n",
      "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0522) | Acc: (98.59%) (6436/6528)\n",
      "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0514) | Acc: (98.66%) (7703/7808)\n",
      "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0517) | Acc: (98.60%) (8961/9088)\n",
      "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0526) | Acc: (98.54%) (10217/10368)\n",
      "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0523) | Acc: (98.56%) (11480/11648)\n",
      "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0520) | Acc: (98.56%) (12742/12928)\n",
      "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0521) | Acc: (98.57%) (14005/14208)\n",
      "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0523) | Acc: (98.58%) (15268/15488)\n",
      "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0530) | Acc: (98.54%) (16524/16768)\n",
      "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0525) | Acc: (98.55%) (17787/18048)\n",
      "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0527) | Acc: (98.54%) (19045/19328)\n",
      "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0528) | Acc: (98.55%) (20310/20608)\n",
      "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0532) | Acc: (98.52%) (21565/21888)\n",
      "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0534) | Acc: (98.51%) (22822/23168)\n",
      "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0537) | Acc: (98.51%) (24083/24448)\n",
      "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0539) | Acc: (98.50%) (25342/25728)\n",
      "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0537) | Acc: (98.49%) (26600/27008)\n",
      "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0535) | Acc: (98.49%) (27860/28288)\n",
      "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0542) | Acc: (98.45%) (29110/29568)\n",
      "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0542) | Acc: (98.47%) (30377/30848)\n",
      "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0538) | Acc: (98.50%) (31647/32128)\n",
      "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0539) | Acc: (98.50%) (32907/33408)\n",
      "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0542) | Acc: (98.50%) (34167/34688)\n",
      "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0543) | Acc: (98.49%) (35424/35968)\n",
      "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0542) | Acc: (98.49%) (36685/37248)\n",
      "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0538) | Acc: (98.51%) (37954/38528)\n",
      "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0539) | Acc: (98.52%) (39217/39808)\n",
      "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0538) | Acc: (98.53%) (40484/41088)\n",
      "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0537) | Acc: (98.52%) (41743/42368)\n",
      "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0534) | Acc: (98.54%) (43011/43648)\n",
      "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0538) | Acc: (98.52%) (44262/44928)\n",
      "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0538) | Acc: (98.52%) (45526/46208)\n",
      "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0538) | Acc: (98.52%) (46786/47488)\n",
      "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0539) | Acc: (98.52%) (48047/48768)\n",
      "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0540) | Acc: (98.52%) (49260/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3888) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0408) | Acc: (100.00%) (128/128)\n",
      "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0572) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0576) | Acc: (98.66%) (2652/2688)\n",
      "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0565) | Acc: (98.56%) (3911/3968)\n",
      "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0552) | Acc: (98.63%) (5176/5248)\n",
      "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0547) | Acc: (98.64%) (6439/6528)\n",
      "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0539) | Acc: (98.63%) (7701/7808)\n",
      "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0544) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0542) | Acc: (98.54%) (10217/10368)\n",
      "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0529) | Acc: (98.62%) (11487/11648)\n",
      "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0526) | Acc: (98.57%) (12743/12928)\n",
      "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0525) | Acc: (98.59%) (14007/14208)\n",
      "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0522) | Acc: (98.57%) (15266/15488)\n",
      "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0516) | Acc: (98.59%) (16531/16768)\n",
      "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0515) | Acc: (98.61%) (17797/18048)\n",
      "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0524) | Acc: (98.59%) (19055/19328)\n",
      "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0521) | Acc: (98.60%) (20320/20608)\n",
      "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0520) | Acc: (98.60%) (21581/21888)\n",
      "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0520) | Acc: (98.60%) (22844/23168)\n",
      "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0527) | Acc: (98.57%) (24099/24448)\n",
      "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0521) | Acc: (98.60%) (25368/25728)\n",
      "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0521) | Acc: (98.60%) (26631/27008)\n",
      "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0524) | Acc: (98.60%) (27892/28288)\n",
      "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0525) | Acc: (98.58%) (29149/29568)\n",
      "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0525) | Acc: (98.59%) (30413/30848)\n",
      "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0526) | Acc: (98.59%) (31676/32128)\n",
      "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0527) | Acc: (98.58%) (32932/33408)\n",
      "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0527) | Acc: (98.58%) (34195/34688)\n",
      "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0530) | Acc: (98.57%) (35454/35968)\n",
      "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0527) | Acc: (98.59%) (36722/37248)\n",
      "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0527) | Acc: (98.59%) (37984/38528)\n",
      "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0527) | Acc: (98.59%) (39245/39808)\n",
      "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0527) | Acc: (98.59%) (40507/41088)\n",
      "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0530) | Acc: (98.58%) (41767/42368)\n",
      "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0529) | Acc: (98.59%) (43031/43648)\n",
      "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0528) | Acc: (98.59%) (44296/44928)\n",
      "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0530) | Acc: (98.59%) (45555/46208)\n",
      "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0530) | Acc: (98.58%) (46814/47488)\n",
      "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0534) | Acc: (98.56%) (48066/48768)\n",
      "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0533) | Acc: (98.56%) (49280/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3890) | Acc: (89.22%) (8922/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0454) | Acc: (100.00%) (128/128)\n",
      "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0554) | Acc: (98.86%) (1392/1408)\n",
      "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0545) | Acc: (98.62%) (2651/2688)\n",
      "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0566) | Acc: (98.59%) (3912/3968)\n",
      "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0548) | Acc: (98.57%) (5173/5248)\n",
      "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0550) | Acc: (98.58%) (6435/6528)\n",
      "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0531) | Acc: (98.66%) (7703/7808)\n",
      "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0537) | Acc: (98.65%) (8965/9088)\n",
      "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0533) | Acc: (98.66%) (10229/10368)\n",
      "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0532) | Acc: (98.63%) (11489/11648)\n",
      "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0545) | Acc: (98.58%) (12745/12928)\n",
      "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0537) | Acc: (98.57%) (14005/14208)\n",
      "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0530) | Acc: (98.63%) (15276/15488)\n",
      "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0529) | Acc: (98.66%) (16544/16768)\n",
      "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0527) | Acc: (98.66%) (17806/18048)\n",
      "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0527) | Acc: (98.65%) (19067/19328)\n",
      "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0531) | Acc: (98.66%) (20331/20608)\n",
      "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0532) | Acc: (98.63%) (21588/21888)\n",
      "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0535) | Acc: (98.61%) (22845/23168)\n",
      "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0533) | Acc: (98.61%) (24107/24448)\n",
      "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0538) | Acc: (98.59%) (25364/25728)\n",
      "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0540) | Acc: (98.58%) (26625/27008)\n",
      "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0541) | Acc: (98.58%) (27886/28288)\n",
      "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0541) | Acc: (98.58%) (29149/29568)\n",
      "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0538) | Acc: (98.58%) (30411/30848)\n",
      "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0534) | Acc: (98.61%) (31680/32128)\n",
      "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0537) | Acc: (98.58%) (32935/33408)\n",
      "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0534) | Acc: (98.59%) (34198/34688)\n",
      "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0534) | Acc: (98.58%) (35456/35968)\n",
      "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0536) | Acc: (98.59%) (36721/37248)\n",
      "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.58%) (37979/38528)\n",
      "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.57%) (39240/39808)\n",
      "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0538) | Acc: (98.58%) (40504/41088)\n",
      "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0534) | Acc: (98.61%) (41777/42368)\n",
      "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0532) | Acc: (98.62%) (43044/43648)\n",
      "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0533) | Acc: (98.62%) (44309/44928)\n",
      "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0533) | Acc: (98.61%) (45565/46208)\n",
      "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0536) | Acc: (98.60%) (46822/47488)\n",
      "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0535) | Acc: (98.61%) (48091/48768)\n",
      "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0536) | Acc: (98.61%) (49307/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3902) | Acc: (89.19%) (8919/10000)\n",
      "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0630) | Acc: (97.66%) (125/128)\n",
      "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0613) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0552) | Acc: (98.33%) (2643/2688)\n",
      "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0556) | Acc: (98.26%) (3899/3968)\n",
      "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0553) | Acc: (98.30%) (5159/5248)\n",
      "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0535) | Acc: (98.44%) (6426/6528)\n",
      "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0538) | Acc: (98.40%) (7683/7808)\n",
      "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0552) | Acc: (98.29%) (8933/9088)\n",
      "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.34%) (10196/10368)\n",
      "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0551) | Acc: (98.32%) (11452/11648)\n",
      "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0549) | Acc: (98.34%) (12714/12928)\n",
      "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0547) | Acc: (98.36%) (13975/14208)\n",
      "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0547) | Acc: (98.39%) (15238/15488)\n",
      "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0546) | Acc: (98.41%) (16501/16768)\n",
      "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0542) | Acc: (98.40%) (17759/18048)\n",
      "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0549) | Acc: (98.37%) (19013/19328)\n",
      "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0547) | Acc: (98.39%) (20276/20608)\n",
      "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0549) | Acc: (98.39%) (21536/21888)\n",
      "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0554) | Acc: (98.38%) (22793/23168)\n",
      "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0550) | Acc: (98.41%) (24059/24448)\n",
      "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0557) | Acc: (98.41%) (25318/25728)\n",
      "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0555) | Acc: (98.41%) (26578/27008)\n",
      "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0553) | Acc: (98.41%) (27838/28288)\n",
      "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0552) | Acc: (98.42%) (29102/29568)\n",
      "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0553) | Acc: (98.41%) (30358/30848)\n",
      "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0551) | Acc: (98.43%) (31624/32128)\n",
      "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0550) | Acc: (98.43%) (32883/33408)\n",
      "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0547) | Acc: (98.45%) (34149/34688)\n",
      "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0547) | Acc: (98.43%) (35405/35968)\n",
      "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0543) | Acc: (98.44%) (36668/37248)\n",
      "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0541) | Acc: (98.45%) (37932/38528)\n",
      "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0546) | Acc: (98.43%) (39184/39808)\n",
      "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0545) | Acc: (98.44%) (40445/41088)\n",
      "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0546) | Acc: (98.43%) (41701/42368)\n",
      "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0550) | Acc: (98.41%) (42953/43648)\n",
      "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0551) | Acc: (98.40%) (44211/44928)\n",
      "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0556) | Acc: (98.38%) (45459/46208)\n",
      "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0555) | Acc: (98.38%) (46718/47488)\n",
      "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0555) | Acc: (98.39%) (47982/48768)\n",
      "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0555) | Acc: (98.39%) (49196/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3898) | Acc: (89.13%) (8913/10000)\n",
      "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0438) | Acc: (99.22%) (127/128)\n",
      "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0498) | Acc: (99.08%) (1395/1408)\n",
      "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0510) | Acc: (98.85%) (2657/2688)\n",
      "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0516) | Acc: (98.74%) (3918/3968)\n",
      "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0523) | Acc: (98.67%) (5178/5248)\n",
      "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0499) | Acc: (98.76%) (6447/6528)\n",
      "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0517) | Acc: (98.66%) (7703/7808)\n",
      "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0525) | Acc: (98.59%) (8960/9088)\n",
      "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0519) | Acc: (98.59%) (10222/10368)\n",
      "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0521) | Acc: (98.59%) (11484/11648)\n",
      "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0521) | Acc: (98.61%) (12748/12928)\n",
      "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0514) | Acc: (98.66%) (14017/14208)\n",
      "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0512) | Acc: (98.66%) (15281/15488)\n",
      "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0512) | Acc: (98.65%) (16542/16768)\n",
      "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0511) | Acc: (98.64%) (17803/18048)\n",
      "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0514) | Acc: (98.63%) (19063/19328)\n",
      "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0517) | Acc: (98.60%) (20320/20608)\n",
      "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0519) | Acc: (98.62%) (21585/21888)\n",
      "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0517) | Acc: (98.63%) (22850/23168)\n",
      "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0520) | Acc: (98.61%) (24109/24448)\n",
      "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0520) | Acc: (98.62%) (25373/25728)\n",
      "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0520) | Acc: (98.63%) (26638/27008)\n",
      "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0519) | Acc: (98.63%) (27901/28288)\n",
      "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0519) | Acc: (98.63%) (29162/29568)\n",
      "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0527) | Acc: (98.61%) (30418/30848)\n",
      "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0530) | Acc: (98.57%) (31670/32128)\n",
      "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0530) | Acc: (98.55%) (32925/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0532) | Acc: (98.53%) (34179/34688)\n",
      "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0528) | Acc: (98.55%) (35446/35968)\n",
      "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0530) | Acc: (98.54%) (36703/37248)\n",
      "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0531) | Acc: (98.53%) (37961/38528)\n",
      "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0534) | Acc: (98.52%) (39218/39808)\n",
      "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0534) | Acc: (98.52%) (40479/41088)\n",
      "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0534) | Acc: (98.51%) (41737/42368)\n",
      "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0532) | Acc: (98.52%) (43003/43648)\n",
      "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0532) | Acc: (98.52%) (44264/44928)\n",
      "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0531) | Acc: (98.53%) (45527/46208)\n",
      "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0532) | Acc: (98.52%) (46785/47488)\n",
      "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.53%) (48052/48768)\n",
      "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0534) | Acc: (98.51%) (49254/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3894) | Acc: (89.26%) (8926/10000)\n",
      "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0774) | Acc: (98.44%) (126/128)\n",
      "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0596) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0599) | Acc: (98.21%) (2640/2688)\n",
      "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0553) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0556) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0544) | Acc: (98.64%) (6439/6528)\n",
      "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0540) | Acc: (98.71%) (7707/7808)\n",
      "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0549) | Acc: (98.66%) (8966/9088)\n",
      "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0549) | Acc: (98.66%) (10229/10368)\n",
      "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0544) | Acc: (98.65%) (11491/11648)\n",
      "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0564) | Acc: (98.57%) (12743/12928)\n",
      "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0565) | Acc: (98.53%) (13999/14208)\n",
      "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0552) | Acc: (98.57%) (15267/15488)\n",
      "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0560) | Acc: (98.53%) (16521/16768)\n",
      "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0558) | Acc: (98.51%) (17779/18048)\n",
      "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0553) | Acc: (98.53%) (19043/19328)\n",
      "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0550) | Acc: (98.55%) (20310/20608)\n",
      "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0544) | Acc: (98.57%) (21575/21888)\n",
      "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0541) | Acc: (98.57%) (22837/23168)\n",
      "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0542) | Acc: (98.56%) (24097/24448)\n",
      "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0548) | Acc: (98.54%) (25352/25728)\n",
      "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0552) | Acc: (98.53%) (26610/27008)\n",
      "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0552) | Acc: (98.53%) (27872/28288)\n",
      "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0549) | Acc: (98.53%) (29133/29568)\n",
      "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0548) | Acc: (98.52%) (30390/30848)\n",
      "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0549) | Acc: (98.52%) (31654/32128)\n",
      "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0545) | Acc: (98.54%) (32919/33408)\n",
      "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0543) | Acc: (98.55%) (34185/34688)\n",
      "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0543) | Acc: (98.54%) (35444/35968)\n",
      "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0542) | Acc: (98.54%) (36706/37248)\n",
      "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0540) | Acc: (98.55%) (37968/38528)\n",
      "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0544) | Acc: (98.52%) (39220/39808)\n",
      "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0545) | Acc: (98.51%) (40477/41088)\n",
      "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0545) | Acc: (98.51%) (41737/42368)\n",
      "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0545) | Acc: (98.50%) (42994/43648)\n",
      "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0547) | Acc: (98.50%) (44254/44928)\n",
      "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0547) | Acc: (98.49%) (45512/46208)\n",
      "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0546) | Acc: (98.50%) (46775/47488)\n",
      "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0548) | Acc: (98.50%) (48036/48768)\n",
      "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0549) | Acc: (98.49%) (49247/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3895) | Acc: (89.20%) (8920/10000)\n",
      "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0652) | Acc: (97.66%) (125/128)\n",
      "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0594) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0521) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0519) | Acc: (98.51%) (3909/3968)\n",
      "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0538) | Acc: (98.42%) (5165/5248)\n",
      "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0538) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0564) | Acc: (98.31%) (7676/7808)\n",
      "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0575) | Acc: (98.24%) (8928/9088)\n",
      "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0568) | Acc: (98.23%) (10185/10368)\n",
      "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0564) | Acc: (98.25%) (11444/11648)\n",
      "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0560) | Acc: (98.29%) (12707/12928)\n",
      "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0566) | Acc: (98.28%) (13964/14208)\n",
      "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0560) | Acc: (98.28%) (15221/15488)\n",
      "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0560) | Acc: (98.29%) (16482/16768)\n",
      "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0565) | Acc: (98.25%) (17733/18048)\n",
      "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0562) | Acc: (98.28%) (18995/19328)\n",
      "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0561) | Acc: (98.28%) (20254/20608)\n",
      "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0559) | Acc: (98.29%) (21514/21888)\n",
      "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0556) | Acc: (98.32%) (22778/23168)\n",
      "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0553) | Acc: (98.36%) (24047/24448)\n",
      "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0548) | Acc: (98.39%) (25314/25728)\n",
      "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0548) | Acc: (98.39%) (26573/27008)\n",
      "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0547) | Acc: (98.38%) (27831/28288)\n",
      "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0548) | Acc: (98.38%) (29089/29568)\n",
      "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0549) | Acc: (98.37%) (30346/30848)\n",
      "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0555) | Acc: (98.36%) (31602/32128)\n",
      "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0551) | Acc: (98.40%) (32872/33408)\n",
      "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0553) | Acc: (98.39%) (34130/34688)\n",
      "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0551) | Acc: (98.40%) (35392/35968)\n",
      "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0551) | Acc: (98.40%) (36652/37248)\n",
      "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0551) | Acc: (98.40%) (37912/38528)\n",
      "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0550) | Acc: (98.41%) (39174/39808)\n",
      "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0548) | Acc: (98.42%) (40438/41088)\n",
      "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0545) | Acc: (98.43%) (41703/42368)\n",
      "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0551) | Acc: (98.41%) (42952/43648)\n",
      "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0551) | Acc: (98.41%) (44213/44928)\n",
      "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0550) | Acc: (98.42%) (45476/46208)\n",
      "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0550) | Acc: (98.42%) (46736/47488)\n",
      "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0550) | Acc: (98.42%) (47996/48768)\n",
      "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0551) | Acc: (98.42%) (49210/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3910) | Acc: (89.18%) (8918/10000)\n",
      "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0862) | Acc: (98.44%) (126/128)\n",
      "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0564) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0543) | Acc: (98.59%) (2650/2688)\n",
      "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0552) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0528) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0514) | Acc: (98.53%) (6432/6528)\n",
      "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0539) | Acc: (98.49%) (7690/7808)\n",
      "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0529) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0539) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0542) | Acc: (98.40%) (11462/11648)\n",
      "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0539) | Acc: (98.43%) (12725/12928)\n",
      "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0537) | Acc: (98.44%) (13987/14208)\n",
      "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0544) | Acc: (98.42%) (15244/15488)\n",
      "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0533) | Acc: (98.48%) (16513/16768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0528) | Acc: (98.49%) (17776/18048)\n",
      "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0534) | Acc: (98.47%) (19033/19328)\n",
      "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0533) | Acc: (98.46%) (20290/20608)\n",
      "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0531) | Acc: (98.48%) (21555/21888)\n",
      "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0528) | Acc: (98.51%) (22822/23168)\n",
      "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0530) | Acc: (98.51%) (24083/24448)\n",
      "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0531) | Acc: (98.51%) (25344/25728)\n",
      "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0530) | Acc: (98.53%) (26611/27008)\n",
      "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0527) | Acc: (98.54%) (27876/28288)\n",
      "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0532) | Acc: (98.52%) (29129/29568)\n",
      "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0533) | Acc: (98.51%) (30389/30848)\n",
      "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0538) | Acc: (98.49%) (31642/32128)\n",
      "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0537) | Acc: (98.49%) (32904/33408)\n",
      "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0543) | Acc: (98.48%) (34161/34688)\n",
      "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0545) | Acc: (98.46%) (35415/35968)\n",
      "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0543) | Acc: (98.46%) (36676/37248)\n",
      "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.48%) (37942/38528)\n",
      "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.48%) (39203/39808)\n",
      "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0540) | Acc: (98.48%) (40462/41088)\n",
      "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0542) | Acc: (98.46%) (41715/42368)\n",
      "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0542) | Acc: (98.47%) (42981/43648)\n",
      "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0542) | Acc: (98.48%) (44244/44928)\n",
      "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0545) | Acc: (98.47%) (45500/46208)\n",
      "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0547) | Acc: (98.46%) (46756/47488)\n",
      "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0550) | Acc: (98.44%) (48005/48768)\n",
      "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0547) | Acc: (98.45%) (49224/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3888) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0871) | Acc: (96.09%) (123/128)\n",
      "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0622) | Acc: (97.87%) (1378/1408)\n",
      "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0559) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0552) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0540) | Acc: (98.53%) (5171/5248)\n",
      "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0532) | Acc: (98.61%) (6437/6528)\n",
      "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0536) | Acc: (98.57%) (7696/7808)\n",
      "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0543) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0540) | Acc: (98.55%) (10218/10368)\n",
      "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0542) | Acc: (98.57%) (11482/11648)\n",
      "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0542) | Acc: (98.58%) (12744/12928)\n",
      "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0542) | Acc: (98.54%) (14000/14208)\n",
      "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0541) | Acc: (98.53%) (15261/15488)\n",
      "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0542) | Acc: (98.54%) (16524/16768)\n",
      "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0545) | Acc: (98.51%) (17779/18048)\n",
      "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0536) | Acc: (98.54%) (19045/19328)\n",
      "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0545) | Acc: (98.48%) (20294/20608)\n",
      "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0553) | Acc: (98.41%) (21541/21888)\n",
      "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0553) | Acc: (98.41%) (22800/23168)\n",
      "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0546) | Acc: (98.44%) (24066/24448)\n",
      "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0547) | Acc: (98.42%) (25321/25728)\n",
      "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0543) | Acc: (98.44%) (26587/27008)\n",
      "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0541) | Acc: (98.46%) (27853/28288)\n",
      "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0536) | Acc: (98.48%) (29118/29568)\n",
      "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0539) | Acc: (98.45%) (30371/30848)\n",
      "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0536) | Acc: (98.46%) (31633/32128)\n",
      "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0536) | Acc: (98.45%) (32890/33408)\n",
      "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0536) | Acc: (98.46%) (34153/34688)\n",
      "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0536) | Acc: (98.46%) (35414/35968)\n",
      "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0537) | Acc: (98.45%) (36670/37248)\n",
      "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0538) | Acc: (98.44%) (37927/38528)\n",
      "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0540) | Acc: (98.44%) (39187/39808)\n",
      "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0537) | Acc: (98.46%) (40456/41088)\n",
      "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0534) | Acc: (98.48%) (41725/42368)\n",
      "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0532) | Acc: (98.50%) (42993/43648)\n",
      "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0530) | Acc: (98.51%) (44258/44928)\n",
      "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0530) | Acc: (98.51%) (45518/46208)\n",
      "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0531) | Acc: (98.50%) (46776/47488)\n",
      "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0531) | Acc: (98.50%) (48038/48768)\n",
      "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0528) | Acc: (98.51%) (49257/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3895) | Acc: (89.28%) (8928/10000)\n",
      "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0362) | Acc: (99.22%) (127/128)\n",
      "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0414) | Acc: (99.01%) (1394/1408)\n",
      "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0442) | Acc: (98.81%) (2656/2688)\n",
      "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0473) | Acc: (98.66%) (3915/3968)\n",
      "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0463) | Acc: (98.76%) (5183/5248)\n",
      "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0460) | Acc: (98.81%) (6450/6528)\n",
      "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0480) | Acc: (98.71%) (7707/7808)\n",
      "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0496) | Acc: (98.65%) (8965/9088)\n",
      "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0509) | Acc: (98.68%) (10231/10368)\n",
      "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0507) | Acc: (98.65%) (11491/11648)\n",
      "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0506) | Acc: (98.65%) (12753/12928)\n",
      "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0505) | Acc: (98.65%) (14016/14208)\n",
      "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0508) | Acc: (98.64%) (15277/15488)\n",
      "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0509) | Acc: (98.64%) (16540/16768)\n",
      "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0522) | Acc: (98.60%) (17795/18048)\n",
      "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0516) | Acc: (98.63%) (19063/19328)\n",
      "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0525) | Acc: (98.59%) (20317/20608)\n",
      "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0520) | Acc: (98.62%) (21586/21888)\n",
      "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0520) | Acc: (98.62%) (22849/23168)\n",
      "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0527) | Acc: (98.58%) (24101/24448)\n",
      "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0525) | Acc: (98.58%) (25362/25728)\n",
      "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0527) | Acc: (98.58%) (26624/27008)\n",
      "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0528) | Acc: (98.55%) (27877/28288)\n",
      "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0529) | Acc: (98.55%) (29138/29568)\n",
      "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0530) | Acc: (98.55%) (30401/30848)\n",
      "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0531) | Acc: (98.56%) (31666/32128)\n",
      "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0533) | Acc: (98.57%) (32931/33408)\n",
      "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0533) | Acc: (98.57%) (34191/34688)\n",
      "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0536) | Acc: (98.54%) (35444/35968)\n",
      "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0540) | Acc: (98.53%) (36702/37248)\n",
      "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0537) | Acc: (98.54%) (37967/38528)\n",
      "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0538) | Acc: (98.55%) (39229/39808)\n",
      "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0536) | Acc: (98.54%) (40490/41088)\n",
      "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0534) | Acc: (98.55%) (41754/42368)\n",
      "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0535) | Acc: (98.55%) (43013/43648)\n",
      "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0534) | Acc: (98.55%) (44276/44928)\n",
      "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0532) | Acc: (98.56%) (45541/46208)\n",
      "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0531) | Acc: (98.56%) (46806/47488)\n",
      "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0534) | Acc: (98.56%) (48066/48768)\n",
      "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0536) | Acc: (98.54%) (49271/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3891) | Acc: (89.27%) (8927/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0733) | Acc: (97.66%) (125/128)\n",
      "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0521) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0527) | Acc: (98.74%) (2654/2688)\n",
      "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0496) | Acc: (98.94%) (3926/3968)\n",
      "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0506) | Acc: (98.74%) (5182/5248)\n",
      "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0511) | Acc: (98.70%) (6443/6528)\n",
      "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0514) | Acc: (98.66%) (7703/7808)\n",
      "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0521) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0520) | Acc: (98.62%) (10225/10368)\n",
      "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0526) | Acc: (98.59%) (11484/11648)\n",
      "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0532) | Acc: (98.55%) (12740/12928)\n",
      "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0528) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0533) | Acc: (98.52%) (15259/15488)\n",
      "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0526) | Acc: (98.56%) (16526/16768)\n",
      "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0525) | Acc: (98.58%) (17791/18048)\n",
      "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0526) | Acc: (98.59%) (19056/19328)\n",
      "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0526) | Acc: (98.58%) (20315/20608)\n",
      "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0528) | Acc: (98.59%) (21579/21888)\n",
      "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0530) | Acc: (98.58%) (22839/23168)\n",
      "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0539) | Acc: (98.54%) (24092/24448)\n",
      "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0542) | Acc: (98.53%) (25351/25728)\n",
      "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0544) | Acc: (98.52%) (26608/27008)\n",
      "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0542) | Acc: (98.53%) (27872/28288)\n",
      "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0542) | Acc: (98.52%) (29131/29568)\n",
      "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0540) | Acc: (98.52%) (30392/30848)\n",
      "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0539) | Acc: (98.52%) (31654/32128)\n",
      "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0544) | Acc: (98.50%) (32907/33408)\n",
      "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0542) | Acc: (98.50%) (34168/34688)\n",
      "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0541) | Acc: (98.52%) (35434/35968)\n",
      "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0538) | Acc: (98.52%) (36697/37248)\n",
      "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0537) | Acc: (98.53%) (37960/38528)\n",
      "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.50%) (39211/39808)\n",
      "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0542) | Acc: (98.50%) (40472/41088)\n",
      "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0541) | Acc: (98.49%) (41729/42368)\n",
      "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0539) | Acc: (98.50%) (42992/43648)\n",
      "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0538) | Acc: (98.51%) (44257/44928)\n",
      "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0535) | Acc: (98.52%) (45525/46208)\n",
      "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0532) | Acc: (98.54%) (46793/47488)\n",
      "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0531) | Acc: (98.54%) (48055/48768)\n",
      "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0529) | Acc: (98.55%) (49275/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3899) | Acc: (89.24%) (8924/10000)\n",
      "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0338) | Acc: (99.22%) (127/128)\n",
      "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0467) | Acc: (98.79%) (1391/1408)\n",
      "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0509) | Acc: (98.55%) (2649/2688)\n",
      "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0513) | Acc: (98.54%) (3910/3968)\n",
      "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0532) | Acc: (98.49%) (5169/5248)\n",
      "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0532) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0523) | Acc: (98.53%) (7693/7808)\n",
      "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0538) | Acc: (98.44%) (8946/9088)\n",
      "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0537) | Acc: (98.49%) (10211/10368)\n",
      "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0534) | Acc: (98.51%) (11474/11648)\n",
      "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0536) | Acc: (98.50%) (12734/12928)\n",
      "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0538) | Acc: (98.52%) (13998/14208)\n",
      "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0536) | Acc: (98.52%) (15259/15488)\n",
      "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0532) | Acc: (98.53%) (16522/16768)\n",
      "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0530) | Acc: (98.54%) (17784/18048)\n",
      "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0531) | Acc: (98.54%) (19045/19328)\n",
      "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0529) | Acc: (98.54%) (20308/20608)\n",
      "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0527) | Acc: (98.54%) (21568/21888)\n",
      "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0522) | Acc: (98.55%) (22831/23168)\n",
      "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0521) | Acc: (98.56%) (24095/24448)\n",
      "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0516) | Acc: (98.58%) (25362/25728)\n",
      "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0516) | Acc: (98.58%) (26625/27008)\n",
      "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0519) | Acc: (98.56%) (27881/28288)\n",
      "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0519) | Acc: (98.57%) (29144/29568)\n",
      "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0521) | Acc: (98.54%) (30397/30848)\n",
      "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0522) | Acc: (98.54%) (31660/32128)\n",
      "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0525) | Acc: (98.53%) (32918/33408)\n",
      "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0524) | Acc: (98.53%) (34179/34688)\n",
      "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0525) | Acc: (98.53%) (35438/35968)\n",
      "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0523) | Acc: (98.54%) (36703/37248)\n",
      "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0522) | Acc: (98.53%) (37963/38528)\n",
      "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0522) | Acc: (98.54%) (39225/39808)\n",
      "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0519) | Acc: (98.54%) (40488/41088)\n",
      "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0521) | Acc: (98.53%) (41746/42368)\n",
      "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0524) | Acc: (98.51%) (42998/43648)\n",
      "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0524) | Acc: (98.52%) (44261/44928)\n",
      "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0525) | Acc: (98.52%) (45522/46208)\n",
      "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0525) | Acc: (98.52%) (46784/47488)\n",
      "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.49%) (48033/48768)\n",
      "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0528) | Acc: (98.49%) (49245/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3894) | Acc: (89.23%) (8923/10000)\n",
      "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0349) | Acc: (99.22%) (127/128)\n",
      "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0541) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0536) | Acc: (98.70%) (2653/2688)\n",
      "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0548) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0554) | Acc: (98.38%) (5163/5248)\n",
      "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0550) | Acc: (98.45%) (6427/6528)\n",
      "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0533) | Acc: (98.55%) (7695/7808)\n",
      "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0533) | Acc: (98.55%) (8956/9088)\n",
      "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0530) | Acc: (98.54%) (10217/10368)\n",
      "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0530) | Acc: (98.57%) (11481/11648)\n",
      "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0534) | Acc: (98.51%) (12736/12928)\n",
      "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0527) | Acc: (98.56%) (14003/14208)\n",
      "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0526) | Acc: (98.54%) (15262/15488)\n",
      "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0534) | Acc: (98.50%) (16517/16768)\n",
      "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0536) | Acc: (98.46%) (17770/18048)\n",
      "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0534) | Acc: (98.46%) (19031/19328)\n",
      "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0531) | Acc: (98.50%) (20299/20608)\n",
      "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0524) | Acc: (98.53%) (21566/21888)\n",
      "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0522) | Acc: (98.54%) (22830/23168)\n",
      "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0522) | Acc: (98.54%) (24092/24448)\n",
      "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0526) | Acc: (98.53%) (25349/25728)\n",
      "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0524) | Acc: (98.55%) (26617/27008)\n",
      "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0526) | Acc: (98.55%) (27878/28288)\n",
      "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0527) | Acc: (98.54%) (29136/29568)\n",
      "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0526) | Acc: (98.54%) (30399/30848)\n",
      "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0527) | Acc: (98.55%) (31663/32128)\n",
      "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0525) | Acc: (98.56%) (32926/33408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0528) | Acc: (98.54%) (34183/34688)\n",
      "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0525) | Acc: (98.55%) (35448/35968)\n",
      "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0524) | Acc: (98.58%) (36719/37248)\n",
      "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0524) | Acc: (98.58%) (37980/38528)\n",
      "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0522) | Acc: (98.58%) (39242/39808)\n",
      "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0523) | Acc: (98.57%) (40500/41088)\n",
      "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0523) | Acc: (98.57%) (41763/42368)\n",
      "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0528) | Acc: (98.56%) (43018/43648)\n",
      "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0527) | Acc: (98.57%) (44285/44928)\n",
      "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0529) | Acc: (98.57%) (45547/46208)\n",
      "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0529) | Acc: (98.57%) (46811/47488)\n",
      "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0531) | Acc: (98.56%) (48065/48768)\n",
      "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0531) | Acc: (98.56%) (49280/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3895) | Acc: (89.25%) (8925/10000)\n",
      "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0406) | Acc: (99.22%) (127/128)\n",
      "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0488) | Acc: (98.79%) (1391/1408)\n",
      "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0481) | Acc: (98.88%) (2658/2688)\n",
      "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0495) | Acc: (98.74%) (3918/3968)\n",
      "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0525) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0520) | Acc: (98.54%) (6433/6528)\n",
      "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0519) | Acc: (98.62%) (7700/7808)\n",
      "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0527) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0532) | Acc: (98.55%) (10218/10368)\n",
      "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0523) | Acc: (98.59%) (11484/11648)\n",
      "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0520) | Acc: (98.61%) (12748/12928)\n",
      "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0517) | Acc: (98.63%) (14013/14208)\n",
      "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0529) | Acc: (98.55%) (15264/15488)\n",
      "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0523) | Acc: (98.57%) (16528/16768)\n",
      "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0520) | Acc: (98.60%) (17796/18048)\n",
      "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0522) | Acc: (98.60%) (19058/19328)\n",
      "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0523) | Acc: (98.59%) (20318/20608)\n",
      "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0529) | Acc: (98.55%) (21571/21888)\n",
      "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0540) | Acc: (98.48%) (22815/23168)\n",
      "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0538) | Acc: (98.48%) (24076/24448)\n",
      "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0534) | Acc: (98.50%) (25341/25728)\n",
      "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0530) | Acc: (98.52%) (26608/27008)\n",
      "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0528) | Acc: (98.52%) (27868/28288)\n",
      "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0527) | Acc: (98.52%) (29129/29568)\n",
      "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0534) | Acc: (98.49%) (30382/30848)\n",
      "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0535) | Acc: (98.48%) (31641/32128)\n",
      "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0537) | Acc: (98.49%) (32903/33408)\n",
      "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0534) | Acc: (98.50%) (34168/34688)\n",
      "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0539) | Acc: (98.48%) (35422/35968)\n",
      "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0538) | Acc: (98.49%) (36685/37248)\n",
      "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0537) | Acc: (98.49%) (37947/38528)\n",
      "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0533) | Acc: (98.52%) (39218/39808)\n",
      "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0534) | Acc: (98.51%) (40477/41088)\n",
      "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0535) | Acc: (98.51%) (41738/42368)\n",
      "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0537) | Acc: (98.50%) (42995/43648)\n",
      "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0536) | Acc: (98.51%) (44258/44928)\n",
      "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0534) | Acc: (98.50%) (45515/46208)\n",
      "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0534) | Acc: (98.50%) (46778/47488)\n",
      "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0536) | Acc: (98.49%) (48033/48768)\n",
      "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0535) | Acc: (98.51%) (49253/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3909) | Acc: (89.19%) (8919/10000)\n",
      "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0147) | Acc: (100.00%) (128/128)\n",
      "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0536) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0574) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0564) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0544) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0520) | Acc: (98.58%) (6435/6528)\n",
      "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0519) | Acc: (98.63%) (7701/7808)\n",
      "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0534) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0526) | Acc: (98.60%) (10223/10368)\n",
      "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0528) | Acc: (98.58%) (11483/11648)\n",
      "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0540) | Acc: (98.55%) (12740/12928)\n",
      "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0543) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0535) | Acc: (98.57%) (15266/15488)\n",
      "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0529) | Acc: (98.59%) (16531/16768)\n",
      "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0528) | Acc: (98.60%) (17796/18048)\n",
      "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0520) | Acc: (98.62%) (19062/19328)\n",
      "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0523) | Acc: (98.60%) (20319/20608)\n",
      "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0521) | Acc: (98.62%) (21586/21888)\n",
      "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0524) | Acc: (98.62%) (22848/23168)\n",
      "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0529) | Acc: (98.60%) (24106/24448)\n",
      "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0522) | Acc: (98.63%) (25375/25728)\n",
      "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0518) | Acc: (98.63%) (26638/27008)\n",
      "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0524) | Acc: (98.62%) (27897/28288)\n",
      "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0522) | Acc: (98.63%) (29164/29568)\n",
      "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0522) | Acc: (98.63%) (30426/30848)\n",
      "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0524) | Acc: (98.61%) (31683/32128)\n",
      "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0525) | Acc: (98.61%) (32944/33408)\n",
      "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0526) | Acc: (98.60%) (34204/34688)\n",
      "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0529) | Acc: (98.60%) (35465/35968)\n",
      "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0528) | Acc: (98.60%) (36727/37248)\n",
      "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0528) | Acc: (98.60%) (37989/38528)\n",
      "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0525) | Acc: (98.61%) (39253/39808)\n",
      "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0527) | Acc: (98.60%) (40514/41088)\n",
      "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0529) | Acc: (98.59%) (41771/42368)\n",
      "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0530) | Acc: (98.59%) (43032/43648)\n",
      "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0528) | Acc: (98.59%) (44294/44928)\n",
      "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0527) | Acc: (98.58%) (45551/46208)\n",
      "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0527) | Acc: (98.57%) (46808/47488)\n",
      "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0525) | Acc: (98.59%) (48078/48768)\n",
      "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0527) | Acc: (98.57%) (49287/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3886) | Acc: (89.32%) (8932/10000)\n",
      "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0266) | Acc: (100.00%) (128/128)\n",
      "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0419) | Acc: (99.01%) (1394/1408)\n",
      "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0460) | Acc: (98.77%) (2655/2688)\n",
      "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0495) | Acc: (98.61%) (3913/3968)\n",
      "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0501) | Acc: (98.69%) (5179/5248)\n",
      "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0536) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0537) | Acc: (98.45%) (7687/7808)\n",
      "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0538) | Acc: (98.45%) (8947/9088)\n",
      "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0534) | Acc: (98.46%) (10208/10368)\n",
      "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0525) | Acc: (98.47%) (11470/11648)\n",
      "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0527) | Acc: (98.43%) (12725/12928)\n",
      "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0534) | Acc: (98.41%) (13982/14208)\n",
      "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0541) | Acc: (98.40%) (15240/15488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0552) | Acc: (98.34%) (16489/16768)\n",
      "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0549) | Acc: (98.38%) (17756/18048)\n",
      "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0545) | Acc: (98.40%) (19019/19328)\n",
      "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0543) | Acc: (98.39%) (20277/20608)\n",
      "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0541) | Acc: (98.41%) (21540/21888)\n",
      "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0542) | Acc: (98.42%) (22801/23168)\n",
      "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0540) | Acc: (98.43%) (24065/24448)\n",
      "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0543) | Acc: (98.43%) (25323/25728)\n",
      "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0544) | Acc: (98.42%) (26582/27008)\n",
      "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0543) | Acc: (98.43%) (27843/28288)\n",
      "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0542) | Acc: (98.45%) (29109/29568)\n",
      "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0541) | Acc: (98.46%) (30374/30848)\n",
      "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0538) | Acc: (98.48%) (31639/32128)\n",
      "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0532) | Acc: (98.50%) (32906/33408)\n",
      "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0530) | Acc: (98.51%) (34170/34688)\n",
      "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0531) | Acc: (98.51%) (35431/35968)\n",
      "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0532) | Acc: (98.50%) (36689/37248)\n",
      "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0536) | Acc: (98.50%) (37949/38528)\n",
      "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0535) | Acc: (98.51%) (39214/39808)\n",
      "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0533) | Acc: (98.52%) (40479/41088)\n",
      "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0531) | Acc: (98.52%) (41743/42368)\n",
      "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0529) | Acc: (98.53%) (43008/43648)\n",
      "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0530) | Acc: (98.53%) (44268/44928)\n",
      "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0529) | Acc: (98.55%) (45537/46208)\n",
      "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0529) | Acc: (98.55%) (46801/47488)\n",
      "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0530) | Acc: (98.54%) (48055/48768)\n",
      "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0532) | Acc: (98.53%) (49266/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3933) | Acc: (89.16%) (8916/10000)\n",
      "0 hours 36 mins 21 secs for training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 165):\n",
    "\n",
    "    if epoch < 80:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 120:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
